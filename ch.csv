文章标题,抽象的
MultiResUNet：重新思考用于多模态生物医学图像分割的 U-Net 架构,近年来，深度学习在医学图像分割方面取得了突破。在这方面，U-Net 一直是医学影像界最流行的架构。尽管在分割多模态医学图像方面具有出色的整体性能，但通过对一些具有挑战性的数据集的广泛实验，我们证明了经典的 U-Net 架构似乎在某些方面缺乏。因此，我们提出了一些修改，以改进已经最先进的 U-Net 模型。在这些修改之后，我们开发了一种新颖的架构 MultiResUNet，作为 U-Net 架构的潜在继任者。我们已经在大量多模态医学图像上测试并比较了 MultiResUNet 与经典 U-Net。尽管在理想图像的情况下只注意到了轻微的改进，但对于具有挑战性的图像，性能却取得了显着的进步。我们在五个不同的数据集上评估了我们的模型，每个数据集都有自己独特的挑战，并分别获得了 10.15%、5.07%、2.63%、1.41% 和 0.62% 的性能相对提升。我们还讨论并强调了 MultiResUNet 在质量上优于经典 U-Net 的一些方面，这些方面并未真正反映在定量测量中。 (C) 2019 Elsevier Ltd. 保留所有权利。
nnU-Net：一种基于深度学习的生物医学图像分割的自配置方法,nnU-Net 是一种基于深度学习的图像分割方法，可自动配置自身以完成各种生物和医学图像分割任务。 nnU-Net 作为开箱即用的工具提供最先进的性能。生物医学成像是科学发现的驱动力和医疗保健的核心组成部分，并受到深度学习领域的刺激。虽然语义分割算法可以在许多应用中进行图像分析和量化，但各自专业解决方案的设计并非易事，并且高度依赖于数据集属性和硬件条件。我们开发了 nnU-Net，这是一种基于深度学习的分割方法，可以自动配置自身，包括任何新任务的预处理、网络架构、训练和后处理。此过程中的关键设计选择被建模为一组固定参数、相互依赖的规则和经验决策。在没有人工干预的情况下，nnU-Net 超越了大多数现有方法，包括针对国际生物医学分割竞赛中使用的 23 个公共数据集的高度专业化解决方案。我们将 nnU-Net 作为开箱即用的工具公开提供，无需专家知识或超出标准网络培训的计算资源，即可为广大受众提供最先进的分割。
CYP1A2 基因型多态性影响咖啡因对受过训练的男性厌氧性能的影响,"目的是研究 CYP1A2 -163C > A 多态性对接受过训练的男性补充急性咖啡因 (CAF) 对无氧能力的影响。 16 名训练有素的男性（年龄：21.6 +/- 7.1 岁；身高：179.7 +/- 5.6 厘米；体重：72.15 +/- 6.8 公斤）参与了一项随机、双盲、安慰剂 (PLA) 控制的交叉设计。参与者以随机顺序补充 CAF（6 mg/kg 体重）和等容 PLA（麦芽糊精）并间隔 7 天，然后进行 30 秒无氧循环测试以确定峰值、平均和最小功率输出, 和疲劳指数。提取基因组脱氧核糖核酸以识别每个参与者的 CYP1A2 基因型。六名参与者表达AA纯合子，十名表达C等位基因。通过基因型相互作用对峰值功率输出进行治疗（p = .041，eta 2 = .265，观察功率 = 0.552），仅表达 AA 基因型的患者在补充 CAF 后与 PLA 相比有所改善（CAF：693 +/- 108瓦与 PLA：655 +/- 97 瓦；p = .039），而在表达 C 等位基因的那些治疗之间没有发现差异（CAF：614 +/- 92 瓦与 PLA：659 +/- 144 瓦； p = .135）。平均或最小功率输出或疲劳指数没有其他交互作用或主要影响 (p > .05)。总之，与 PLA 相比，仅 AA 基因型参与者摄入 6 mg/kg CAF 可提高峰值功率输出；然而，CYP1A2 的表达不影响平均或最小功率输出或疲劳指数。"
用于视觉识别的深度高分辨率表示学习,高分辨率表示对于位置敏感的视觉问题至关重要，例如人体姿态估计、语义分割和对象检测。现有的最先进的框架首先通过一个子网络将输入图像编码为低分辨率表示，该子网络通过串联连接高分辨率到低分辨率的卷积（例如，ResNet、VGGNet）形成，然后恢复高分辨率- 来自编码的低分辨率表示的分辨率表示。相反，我们提出的网络，称为高分辨率网络（HRNet），在整个过程中保持高分辨率表示。有两个关键特征：（i）并行连接从高分辨率到低分辨率的卷积流，以及（ii）跨分辨率重复交换信息。好处是生成的表示在语义上更丰富，在空间上更精确。我们展示了所提出的 HRNet 在广泛的应用中的优越性，包括人体姿态估计、语义分割和对象检测，这表明 HRNet 是计算机视觉问题的更强大的主干。所有代码都可以在 https://github.com/HRNet 上找到。
3D 点云的深度学习：调查,点云学习最近因其在计算机视觉、自动驾驶和机器人技术等许多领域的广泛应用而受到越来越多的关注。作为人工智能的主导技术，深度学习已成功用于解决各种二维视觉问题。然而，由于使用深度神经网络处理点云所面临的独特挑战，点云的深度学习仍处于起步阶段。最近，点云的深度学习变得更加蓬勃发展，提出了许多方法来解决该领域的不同问题。为了激发未来的研究，本文全面回顾了点云深度学习方法的最新进展。它涵盖了三个主要任务，包括 3D 形状分类、3D 对象检测和跟踪以及 3D 点云分割。它还展示了几个公开可用的数据集的比较结果，以及有见地的观察和启发未来的研究方向。
UNet plus plus：重新设计跳过连接以利用图像分割中的多尺度特征,最先进的医学图像分割模型是 U-Net 和全卷积网络 (FCN) 的变体。尽管它们取得了成功，但这些模型有两个局限性：（1）它们的最佳深度是先验未知的，需要广泛的架构搜索或不同深度模型的低效集成； (2) 它们的跳跃连接强加了一种不必要的限制性融合方案，仅在编码器和解码器子网络的相同尺度特征图上强制聚合。为了克服这两个限制，我们提出了 UNet++，一种用于语义和实例分割的新神经架构，通过 (1) 使用不同深度的 U-Net 的有效集合来减轻未知网络深度，这些 U-Net 部分共享编码器和共同学习同时使用深度监督； (2) 重新设计跳跃连接以聚合解码器子网络中不同语义尺度的特征，从而实现高度灵活的特征融合方案； (3) 设计一种剪枝方案来加快 UNet++ 的推理速度。我们使用六种不同的医学图像分割数据集评估了 UNet++，涵盖了计算机断层扫描 (CT)、磁共振成像 (MRI) 和电子显微镜 (EM) 等多种成像模式，并证明 (1) UNet++ 始终优于基线模型用于跨不同数据集和主干架构的语义分割任务； （2）UNet++提高了不同大小对象的分割质量——对固定深度U-Net的改进； （3）Mask RCNN++（Mask R-CNN with UNet++ design）在实例分割任务上优于原始Mask R-CNN； (4) 修剪后的 UNet++ 模型实现了显着的加速，同时仅表现出适度的性能下降。我们的实现和预训练模型可在 https://github.com/MrGiovanni/UNetPlusPlus 获得。
GOT-10k：野外通用对象跟踪的大型高多样性基准,"我们在这里介绍一个大型跟踪数据库，该数据库提供了前所未有的广泛覆盖范围内的常见运动物体，称为 GOT-10k。具体来说，GOT-10k 建立在 WordNet 结构 [1] 的主干之上，它填充了超过 560 类移动物体和 87 种运动模式中的大多数，其幅度比最近的类似规模的对应物要宽 [19]、[20] ，[23]，[26]。通过发布大型高多样性数据库，我们旨在为与类别无关的通用短期跟踪器的开发提供统一的培训和评估平台。 GOT-10k 的特点和本文的贡献总结如下。 (1) GOT-10k 提供超过 10,000 个视频片段和超过 150 万个手动标记的边界框，实现深度跟踪器的统一训练和稳定评估。 (2) GOT-10k 是迄今为止第一个使用 WordNet 的语义层次来引导类种群的视频轨迹数据集，它确保了对各种运动物体的全面且相对无偏的覆盖。 (3) GOT-10k 首次引入了用于跟踪器评估的 one-shot 协议，其中训练和测试类是零重叠的。该协议避免了对熟悉对象的有偏见的评估结果，并促进了跟踪器开发的泛化。 (4) GOT-10k 提供额外的标签，例如运动类别和对象可见比率，促进运动感知和遮挡感知跟踪器的开发。 (5) 我们在 GOT-10k 上对 39 种典型的跟踪算法及其变体进行了广泛的跟踪实验，并在本文中分析了它们的结果。 (6) 最后，我们为跟踪社区开发了一个综合平台，提供功能齐全的评估工具包、在线评估服务器和响应式排行榜。 GOT-10k 测试数据的注释是保密的，以避免在其上调整参数。"
使用受激拉曼组织学和深度神经网络进行近实时术中脑肿瘤诊断,"术中诊断对于在癌症手术期间提供安全有效的护理至关重要 (1)。现有的基于处理组织的苏木精和伊红染色的术中诊断工作流程是时间、资源和劳动密集型的 (2,3)。此外，术中组织学图像的解释依赖于收缩的、分布不均的病理工作人员 (4)。在本研究中，我们报告了一个并行工作流程，该工作流程结合了受激拉曼组织学 (SRH) (5-7)、一种无标记光学成像方法和深度卷积神经网络 (CNN)，以近乎实时地预测床边的诊断以自动化的方式。具体来说，我们的 CNN 训练了超过 250 万张 SRH 图像，可以在 150 秒内预测手术室中的脑肿瘤诊断，比传统技术快一个数量级（例如，20-30 分钟）（2）。在一项多中心、前瞻性临床试验（n = 278）中，我们证明基于 CNN 的 SRH 图像诊断不劣于基于病理学家的传统组织学图像解释（总体准确率，94.6% 对 93.9%）。我们的 CNN 学习了可识别的组织学特征表示的层次结构，以对脑肿瘤的主要组织病理学类别进行分类。此外，我们实施了一种语义分割方法来识别 SRH 图像中肿瘤浸润的诊断区域。这些结果证明了如何简化术中癌症诊断，为组织诊断创造一条独立于传统病理学实验室的补充途径。一项前瞻性、多中心、病例对照临床试验评估了人工智能为患者提供准确床边诊断的潜力患有脑肿瘤。"
ResUNet-a：遥感数据语义分割的深度学习框架,高分辨率航空影像的场景理解对于各种遥感应用中的自动监测任务具有重要意义。由于感兴趣对象的像素值的类内和类间差异较大，这仍然是一项具有挑战性的任务。近年来，深度卷积神经网络已开始用于遥感应用，并展示了对象像素级分类的最先进性能。在这里，我们为单时间极高分辨率航空图像的语义分割任务提出了一个可靠的高性能结果框架。我们的框架由一个新的深度学习架构 ResUNet-a 和一个基于 Dice 损失的新损失函数组成。 ResUNet-a 使用 UNet 编码器/解码器主干，结合残差连接、atrous 卷积、金字塔场景解析池和多任务推理。 ResUNet-a 依次推断对象的边界、分割掩码的距离变换、分割掩码和输入的彩色重建。每个任务都以先前任务的推理为条件，从而在各种任务之间建立条件关系，正如通过架构的计算图描述的那样。我们分析了几种用于语义分割的广义骰子损失的性能，并为对象的语义分割引入了一种新的变体损失函数，该函数具有出色的收敛性，即使在存在高度不平衡的类的情况下也表现良好。我们的建模框架的性能在 ISPRS 2D Potsdam 数据集上进行评估。结果显示，我们的最佳模型在所有类别中的平均 F1 分数为 92.9%，具有最先进的性能。
用于地理大数据应用的 Google 地球引擎：荟萃分析和系统评价,Google Earth Engine (GEE) 是一个基于云的地理空间处理平台，用于大规模环境监测和分析。免费使用的 GEE 平台通过浏览器 Web 应用程序提供对 (1) PB 的公开遥感图像和其他即用型产品的访问； (2) 使用谷歌计算基础设施的高速并行处理和机器学习算法； (3) 应用程序编程接口 (API) 库，其开发环境支持 JavaScript 和 Python 等流行的编码语言。这些核心功能使用户能够以强大的方式发现、分析和可视化地理空间大数据，而无需访问超级计算机或专业的编码专业知识。 GEE的发展为遥感和地理空间数据科学领域带来了极大的热情和参与。然而，自 GEE 推出十年后，它对遥感和地理空间科学的影响仍未得到仔细探索。因此，需要对 GEE 进行系统回顾，以便为读者提供 GEE 现状和总体趋势的总体情况。为此，决定对最近经过同行评审的 GEE 文章进行荟萃分析调查，重点关注几个特征，包括数据、传感器类型、研究区域、空间分辨率、应用、策略和分析方法。对 2010 年至 2019 年 10 月期间在 146 种不同期刊上发表的共 349 篇同行评议文章进行了审核。出版物和地理分布趋势显示了在区域和全球范围内环境分析的广泛应用。 90% 的研究使用了遥感数据集，而 10% 的文章使用了现成的产品进行分析。具有中等空间分辨率的光学卫星图像，特别是存档超过 40 年的 Landsat 数据，已被广泛使用。线性回归和随机森林是最常用的卫星图像处理算法。在即用型产品中，27% 的植被、作物、土地覆盖制图和干旱监测研究使用了标准化差异植被指数 (NDVI)。这项研究的结果证实，GEE 已经并将继续在涉及地理大数据过程的全球挑战方面取得实质性进展。
UNET 3+：用于医学图像分割的全尺寸连接 UNET,最近，人们对基于深度学习的语义分割越来越感兴趣。 UNet 是一种具有编码器-解码器架构的深度学习网络，广泛用于医学图像分割。结合多尺度特征是准确分割的重要因素之一。 UNet++ 是通过设计具有嵌套和密集跳过连接的架构而开发为修改后的 Unet。但是，它没有从全尺度探索足够的信息，还有很大的改进空间。在本文中，我们提出了一种新颖的 UNet 3+，它利用了全面的跳过连接和深度监督。全尺寸跳跃连接将低级细节与来自不同尺度特征图的高级语义结合起来；而深度监督则从全尺寸聚合特征图中学习层次表示。所提出的方法特别有利于以不同尺度出现的器官。除了提高精度外，所提出的 UNet 3+ 还可以减少网络参数以提高计算效率。我们进一步提出了一种混合损失函数并设计了一个分类引导模块来增强器官边界并减少非器官图像中的过度分割，从而产生更准确的分割结果。在两个数据集上证明了所提出方法的有效性。
自动驾驶的深度多模态目标检测和语义分割：数据集、方法和挑战,自动驾驶感知的最新进展是由深度学习驱动的。为了实现稳健和准确的场景理解，自动驾驶汽车通常配备不同的传感器（例如摄像头、激光雷达、雷达），并且可以融合多种传感模式以利用它们的互补特性。在这种情况下，针对深度多模态感知问题提出了许多方法。然而，网络架构设计没有通用的指导方针，关于融合什么、何时融合以及如何融合的问题仍然悬而未决。本综述试图系统地总结方法并讨论自动驾驶中深度多模态目标检测和语义分割的挑战。为此，我们首先概述了测试车辆上的车载传感器、开放数据集以及用于自动驾驶研究中目标检测和语义分割的背景信息。然后，我们总结了融合方法并讨论了挑战和未解决的问题。在附录中，我们提供了总结主题和方法的表格。我们还提供了一个交互式在线平台来浏览每个参考：https://boschresearch.github.io/multimodalperception/。
用于路面裂缝检测的特征金字塔和分层增强网络,路面裂缝检测是确保道路安全的一项关键任务。手动裂纹检测非常耗时。因此，需要一种自动道路裂缝检测方法来推动这一进展。然而，由于裂缝的强度不均匀性和背景的复杂性，它仍然是一项具有挑战性的任务，例如，与周围路面的低对比度和可能具有相似强度的阴影。受计算机视觉深度学习最新进展的启发，我们提出了一种新的网络架构，称为特征金字塔和分层增强网络（FPHBN），用于路面裂缝检测。所提出的网络以特征金字塔的方式将上下文信息集成到用于裂缝检测的低级特征中，并通过在训练期间以分层方式嵌套样本重新加权来平衡简单样本和困难样本对损失的贡献。此外，我们提出了一种新的裂纹检测测量方法，称为平均交叉联合（AIU）。为了证明所提出方法的优越性和普遍性，我们在五个裂缝数据集上对其进行了评估，并将其与最先进的裂缝检测、边缘检测和语义分割方法进行了比较。大量实验表明，所提出的方法在准确性和普遍性方面优于这些方法。代码和数据可以在 https://github.com/fyangneil/pavement-crack-detection 中找到。
不变属性配置文件：用于高光谱图像分类的空间频率联合特征提取器,到目前为止，已经开发了大量先进的技术来增强和提取高光谱图像处理和分析中的空间语义信息。然而，局部语义变化，如场景组成、物体之间的相对位置、光照引起的光谱变化、大气效应和材料混合，在空间信息建模中很少被研究。因此，从空间不同的场景或位置识别相同的材料可能很困难。在本文中，我们提出了一种解决此问题的解决方案，方法是使用称为不变属性配置文件 (IAP) 的方法从空间和频域的高光谱图像 (HSI) 中局部提取不变特征。 IAP 通过利用 HSI 上的各向同性滤波器组或卷积核以及笛卡尔坐标系中的空间聚合技术（例如，超像素分割）来提取空间不变特征。此外，他们通过在傅立叶极坐标中构建的定向梯度的连续直方图来模拟不变的行为（例如，移位、旋转）。这产生了用于 HSI 分类的空间频率不变特征的组合表示。在三个有前途的高光谱数据集（Houston2013 和 Houston2018）上进行了广泛的实验，以证明所提出的 IAP 方法与几种最先进的剖面相关技术相比的优越性和有效性。代码可从以下网站获得：<uri>https://sites.google.com/view/danfeng-hong/data-code</uri>。
语义分割的对象-上下文表示,在本文中，我们研究了语义分割中的上下文聚合问题。由于像素的标签是像素所属对象的类别，我们提出了一种简单而有效的方法，即对象上下文表示，通过利用相应对象类别的表示来表征像素。首先，我们在真实分割的监督下学习对象区域。其次，我们通过聚合位于对象区域中的像素的表示来计算对象区域表示。最后，我们计算每个像素和每个对象区域之间的关系，并使用对象上下文表示增强每个像素的表示，该表示是所有对象区域表示的加权聚合。我们凭经验证明我们的方法在各种基准测试中实现了具有竞争力的性能：Cityscapes、ADE20K、LIP、PASCAL-Context 和 COCO-Stuff。我们的提交 ldquoHRNet + OCR + SegFixrdquo 在 ECCV 2020 提交截止日期前在 Cityscapes 排行榜上获得第一名。代码位于：https://git.io/openseg 和 https://git.io/HRNet.OCR。
自然图像和医学图像的深度语义分割：综述,语义图像分割任务包括将图像的每个像素分类为一个实例，其中每个实例对应一个类。该任务是场景理解概念的一部分，或者更好地解释图像的全局上下文。在医学图像分析领域，图像分割可用于图像引导干预、放射治疗或改进的放射诊断。在这篇综述中，我们将领先的基于深度学习的医学和非医学图像分割解决方案分为六大类：深度架构、基于数据合成、基于损失函数、序列模型、弱监督和多任务方法，以及对每个组的贡献进行全面审查。此外，对于每个组，我们分析了这些组的每个变体，并讨论了当前方法的局限性，并提出了语义图像分割的潜在未来研究方向。
SOLO：按位置分割对象,我们提出了一种新的、非常简单的实例分割方法。与许多其他密集预测任务（例如语义分割）相比，任意数量的实例使实例分割更具挑战性。为了预测每个实例的掩码，主流方法要么遵循 ldquodetect-then-segmentrdquo 策略（例如，Mask R-CNN），要么先预测嵌入向量，然后使用聚类技术将像素分组到单个实例中。我们通过引入 ldquoinstance categoriesrdquo 的概念，从全新的角度看待实例分割的任务，它根据实例的位置和大小为实例中的每个像素分配类别，从而很好地将实例分割转换为单次分类可解决的问题。我们展示了一个更简单灵活的实例分割框架，具有强大的性能，与 Mask R-CNN 实现了同等的准确性，并且在准确性上优于最近的单次实例分割器。我们希望这个简单而强大的框架可以作为除实例分割之外的许多实例级识别任务的基准。代码可在 https://git.io/AdelaiDet 获得。
深度学习在自动驾驶汽车控制中的应用调查,由于环境高度复杂且无法在部署后可能遇到的各种场景中测试系统，因此为自动驾驶汽车设计能够在所有驾驶场景中提供足够性能的控制器具有挑战性。然而，深度学习方法不仅在为复杂的非线性控制问题提供出色的性能，而且在将先前学习的规则推广到新场景方面都显示出了巨大的希望。由于这些原因，将深度学习用于车辆控制变得越来越流行。尽管在这一领域取得了重要进展，但这些工作尚未得到充分总结。本文调查了文献中报道的旨在通过深度学习方法控制车辆的广泛研究工作。尽管控制和感知之间存在重叠，但本文的重点是车辆控制，而不是更广泛的感知问题，包括语义分割和对象检测等任务。本文通过比较分析确定了可用深度学习方法的优势和局限性，并讨论了计算、架构选择、目标规范、泛化、验证和确认以及安全性方面的研究挑战。总体而言，这项调查为与智能交通系统相关的快速发展的领域带来了及时和热门的信息。
用于高分辨率双时相遥感图像变化检测的深度监督图像融合网络,高分辨率遥感图像中的变化检测对于了解地表变化至关重要。由于传统的变化检测方法不适合考虑高分辨率图像中传达的精细图像细节和复杂纹理特征带来的挑战，因此提出了许多基于深度学习的变化检测方法来提高变化检测性能。尽管最先进的基于深度特征的方法优于所有其他基于深度学习的变化检测方法，但现有的基于深度特征的方法中的网络大多是从最初为单图像语义分割提出的架构修改而来的。转移这些网络进行变化检测任务仍然存在一些关键问题。在本文中，我们提出了一种深度监督图像融合网络（IFN），用于高分辨率双时相遥感图像的变化检测。具体来说，首先通过完全卷积的双流架构提取具有高度代表性的双时图像深度特征。然后，将提取的深度特征输入深度监督的差异判别网络（DDN）进行变化检测。为了提高输出变化图中对象的边界完整性和内部紧凑性，通过注意力模块将原始图像的多层深度特征与图像差异特征融合，用于变化图重建。通过直接向网络中的中间层引入变化图损失来进一步增强 DDN，并以端到端的方式训练整个网络。干扰素应用于一个公开可用的数据集，以及一个具有挑战性的数据集，该数据集由来自谷歌地球的多源双时相图像组成，覆盖中国不同城市。视觉解释和定量评估都证实，与最先进的方法相比，IFN 通过返回具有完整边界和高内部紧凑性的变化区域，优于文献中的四种基准方法。
基于图像块匹配和密集卷积网络的无覆盖实时图像信息隐藏,信息安全最近成为公众关注的重点问题。为了从根本上抵制图像信息隐藏领域的解密和分析，显着提高秘密信息的安全性，本文提出了一种基于深度学习的无覆盖信息隐藏方法。深度学习可以根据需求选择合适的载体，实现图像数据的实时隐藏，CNN提取的高层语义特征比低层特征更准确。该方法不需要使用指定图像来嵌入秘密数据，而是传输一组实时隐写图像，这些图像与给定的秘密图像共享一个或几个视觉上相似的块。在这种方法中，根据特定要求对在线搜索的一组实时图像进行分割。然后，使用 DenseNet 提取每个相似块的高级语义特征。同时，通过 DCT 生成具有特征序列、DC 和位置的鲁棒哈希序列。构建基于哈希序列的倒排索引结构，有效实现图像实时匹配。在发送端，通过特征检索匹配并发送隐秘图像。在接收端，通过接收到的隐秘图像提取相似块并根据位置信息拼接图像块，可以恢复秘密图像。实验结果表明，与现有的一些无覆盖图像信息隐藏相比，该方法在没有任何修改痕迹的情况下具有更好的鲁棒性，具有更高的检索精度和容量。
使用深度神经网络从连续驾驶场景中进行稳健的车道检测,驾驶场景中的车道检测是自动驾驶汽车和高级驾驶辅助系统的重要模块。近年来，已经提出了许多复杂的车道检测方法。然而，大多数方法都侧重于从一张图像中检测车道，并且在处理一些极其恶劣的情况（如阴影重、标记退化严重、车辆严重遮挡等）时往往会导致性能不理想。事实上，车道是道路上的连续线结构。因此，在当前帧中无法准确检测到的车道可能会通过合并先前帧的信息来推断出来。为此，我们通过使用连续驾驶场景的多帧来研究车道检测，并通过结合卷积神经网络（CNN）和循环神经网络（RNN）提出了一种混合深度架构。具体来说，每一帧的信息被一个CNN块抽象出来，然后将多个连续帧的CNN特征，具有时间序列的特性，输入RNN块进行特征学习和车道预测。在两个大规模数据集上进行的大量实验表明，所提出的方法在车道检测方面优于其他竞争方法，尤其是在处理困难情况方面。
二元神经网络：调查,二元神经网络在很大程度上节省了存储和计算，是在资源有限的设备上部署深度模型的有前途的技术。然而，二值化不可避免地会导致严重的信息丢失，更糟糕的是，它的不连续性给深度网络的优化带来了困难。为了解决这些问题，人们提出了多种算法，并在近年来取得了令人满意的进展。在本文中，我们对这些算法进行了全面的综述，主要分为直接进行二值化的原生解决方案，以及使用最小化量化误差、改进网络损失函数和减少梯度误差等技术的优化算法。我们还研究了二元神经网络的其他实际方面，例如硬件友好设计和训练技巧。然后，我们对不同的任务进行评估和讨论，包括图像分类、对象检测和语义分割。最后对未来研究可能面临的挑战进行了展望。 (C) 2020 Elsevier Ltd. 保留所有权利。
Vcash：一种用于识别互联车辆互联网拒绝交通服务的新型声誉框架,随着 UGV 技术的快速发展，车联网的信任管理成为近年来的热门话题。然而，现有的基于车辆间可信度验证的解决方案使得交通事件的传输效率很低。在本文中，我们假设部署的路边单元 (RSU) 可以在任何一对 RSU 和车辆之间提供有效的通信，并提出车辆现金 (Vcash)，一种用于识别拒绝交通服务的信誉框架，以解决交通服务中的可信度问题。车联网应用层面。在我们的信誉框架中，每辆车都直接与 RSU 通信以进行交通事件验证，并传播经过验证的交通事件通知。我们借鉴市场交易的思想，建立交易规则，限制恶意车辆传播虚假信息，鼓励车辆为交通事件监测和验证做出贡献。为了评估我们的声誉框架的有效性，我们进行了模拟实验。我们的实验结果表明，我们的提议设法避免虚假事件传播，并且我们框架中的车辆必须对交通事件检测做出贡献才能正常使用交通服务。
通过类似游戏的 BIM 和机器学习混合应用程序对建设项目进行按需监控,虽然不可避免，但检查、进度监控以及建设项目中按计划与竣工条件进行比较并不能轻易地为最终用户增加有形的内在价值。在大型建设项目中，由于以进度表的形式生成的大量数据，监控建筑物每个部分的实施并将其反映在 BIM 模型上的过程可能会变得高度劳动密集且容易出错，报告和照片日志。为了解决上述方法和技术差距，本文提出了一个框架和概念验证原型，用于建筑项目的按需自动化模拟，集成了一些尖端的 IT 解决方案，即图像处理、机器学习、BIM 和虚拟现实.本研究利用 Unity 游戏引擎整合来自原始 BIM 模型和竣工图像的数据，这些数据通过各种计算机视觉技术进行处理。这些方法包括对象识别和语义分割，通过监督训练来识别不同的结构元素，以便将真实世界的图像叠加在计划模型上。所提出的框架导致 3D 虚拟环境与施工现场状态的自动更新。该框架为项目经理和股东提供了先进的决策工具，以有效的方式突出不一致。本文通过为 ML 和图像处理方法与沉浸式和交互式 BIM 界面的集成提供技术范例来促进身体知识，其算法和程序代码可以帮助其他学者复制这些方法。
用于遥感图像中目标检测的旋转感知和多尺度卷积神经网络,目标检测在遥感影像分析领域发挥着重要作用。推进这项任务最具挑战性的问题是物体尺度的巨大变化和物体的任意方向。在本文中，我们在基于区域的卷积神经网络上构建了一个统一的框架，用于遥感图像中的任意方向和多尺度目标检测。为了处理多尺度目标检测问题，提出了一种特征融合架构来生成多尺度特征层次结构，该架构通过自顶向下的路径将浅层的特征与语义表示相结合，并结合顶层的特征图。通过自下而上的路径具有低级信息的层。通过组合不同层次的特征，我们可以为多尺度对象形成强大的特征表示。大多数以前的方法通过轴对齐的框定位具有任意方向和密集空间分布的对象，这些框可能覆盖相邻的实例和背景区域。我们构建了一个旋转感知对象检测器，它使用定向框来定位遥感图像中的对象。区域提议网络使用多个默认角度增强锚点以覆盖定向对象。它利用定向提议框来包围对象，而不是粗略定位定向对象的水平提议。引入定向 RoI 池化操作以提取定向提议的特征图，用于以下 R-CNN 子网络。我们在公共数据集上进行了综合实验，用于遥感图像中的定向目标检测。我们的方法实现了最先进的性能，这证明了所提出方法的有效性。
面向自动驾驶的 ApolloScape 开放数据集及其应用,自动驾驶引起了极大的关注，尤其是在过去几年中。自动驾驶汽车的关键技术包括解决诸如 3D 地图构建、自我定位、解析驾驶道路和理解物体等任务，这些任务使车辆能够推理和行动。然而，用于训练和系统评估的大规模数据集仍然是开发鲁棒感知模型的瓶颈。在本文中，我们介绍了 ApolloScape 数据集 [1] 及其在自动驾驶中的应用。与来自真实场景的现有公共数据集（例如 KITTI [2] 或 Cityscapes [3]）相比，ApolloScape 包含更大更丰富的标签，包括每个站点的整体语义密集点云、立体、每像素语义标签、lanemark 标签、实例分割、3D 汽车实例、来自多个站点、城市和白天的各种驾驶视频中每一帧的高精度定位。对于每个任务，它包含的图像数量至少是 SOTA 数据集的 15 倍。为了标记这样一个完整的数据集，我们为每个任务开发了各种工具和算法来加速标记过程，例如联合 3D-2D 片段标记、视频中的主动标记等。依靠 ApolloScape，我们能够开发联合考虑的算法多项任务的学习和推理。在本文中，我们提供了一种传感器融合方案，集成了摄像头视频、消费级运动传感器 (GPS/IMU) 和 3D 语义地图，以实现自动驾驶的鲁棒自定位和语义分割。我们表明，实际上，传感器融合和多个任务的联合学习有利于实现更强大和更准确的系统。我们希望我们的数据集和提出的相关算法能够支持和激励研究人员在计算机视觉领域进一步发展多传感器融合和多任务学习。
SDDNet：实时裂缝分割,本文报告了一种用于分割图像中混凝土裂缝的纯深度学习方法的发展。目标是实现实时性能，同时有效地消除各种复杂背景和裂纹状特征。为了实现这些目标，提出了一种原始的卷积神经网络。该模型由标准卷积、密集连接的可分离卷积模块、改进的空洞空间金字塔池化模块和解码器模块组成。语义损伤检测网络 (SDDNet) 在手动创建的裂纹数据集上进行训练，训练后的网络在测试集上记录了 0.846 的平均交并比。分析每个测试图像，并呈现具有代表性的分割结果。结果表明，除非特征太微弱，否则 SDDNet 片段会有效地破裂。所提出的模型还与最近的模型进行了比较，结果表明它返回了更好的评估指标，尽管它的参数数量是比较模型的 88 倍。此外，该模型处理 1025 x 512 像素的实时 (36 FPS) 图像，比最近的工作快 46 倍。
语义分割的损失函数调查,图像分割一直是一个活跃的研究领域，因为它具有广泛的应用，从自动疾病检测到自动驾驶汽车。在过去的五年中，各种论文提出了在不同情况下使用的不同目标损失函数，例如有偏数据、稀疏分割等。在本文中，我们总结了一些广泛用于图像分割和列出了使用它们可以帮助模型快速和更好地收敛的情况。此外，我们还引入了一种新的 log-cosh dice 损失函数，并将其在 NBFS 头骨分割开源数据集上的性能与广泛使用的损失函数进行了比较。我们还展示了某些损失函数在所有数据集上都表现良好，并且可以作为未知数据分布场景中的良好基线选择。
用于医学图像分割的多尺度自引导注意,尽管卷积神经网络 (CNN) 正在推动医学图像分割的进步，但标准模型仍然存在一些缺点。首先，使用多尺度方法，即编码器-解码器架构，会导致信息的冗余使用，其中类似的低级特征在多个尺度上被多次提取。其次，远程特征依赖没有被有效地建模，导致与每个语义类相关的非最优判别特征表示。在本文中，我们尝试通过使用引导式自我注意机制来捕获更丰富的上下文依赖关系，从而克服所提出的架构的这些限制。这种方法能够将局部特征与其相应的全局依赖关系集成，并以自适应的方式突出相互依赖的通道图。此外，不同模块之间的额外损失引导注意力机制忽略不相关的信息，并通过强调相关的特征关联来关注图像的更具判别性的区域。我们在三个不同数据集的语义分割背景下评估所提出的模型：腹部器官、心血管结构和脑肿瘤。一系列消融实验支持了这些注意力模块在所提出的架构中的重要性。此外，与其他最先进的分割网络相比，我们的模型产生了更好的分割性能，提高了预测的准确性，同时降低了标准偏差。这证明了我们的方法在生成精确可靠的医学图像自动分割方面的效率。我们的代码在以下网址公开：<uri>https://github.com/sinAshish/Multi-Scale-Attention</uri>。
相关联合聚类的运动分割和多目标跟踪,计算机视觉模型通常定义为低级概念（例如要分组的像素）或高级概念（例如要检测和跟踪的语义对象）。将自下而上的分组与自上而下的检测和跟踪相结合，虽然非常可取，但却是一个具有挑战性的问题。我们将这个联合问题描述为一个协同聚类问题，它是现有算法的原则性和可处理性。我们通过将通过点轨迹分组的自下而上运动分割与通过边界框聚类的高级多对象跟踪相结合来证明这种方法的有效性。我们表明，在 FBMS59 运动分割基准方面，解决联合问题在低层次上是有益的，在多目标跟踪基准 MOT15、MOT16 和 MOT17 挑战方面，在高层次上是有益的，并且是在某些指标上是最先进的。
基于全卷积网络的航空图像道路提取集成方法,这封信提出了一种基于全卷积网络（FCNs）和集成策略的道路提取方法，以解决航拍图像中道路和背景区域的不平衡问题。通过利用 FCN，我们将道路提取视为语义分割问题。在网络中，由于道路和背景的不平衡，损失函数的权重被修改，如果道路被错误地分类为背景，将会有更大的惩罚。由于很难确定给定图像的损失函数的适当权重，因此提出了一种基于空间一致性（SC）的集成方法。从具有不同损失函数的 FCN 获得的结果图融合在我们提出的集成策略中，这也避免了权重的确定。我们的方法使用马萨诸塞州道路数据集进行了测试，根据我们的实验结果，与基础全卷积模型相比，它被证明是有效的。
将点与 3D 中的标签联系起来：点云语义分割的回顾,3D 点云语义分割（PCSS）和点云分割（PCS）随着深度学习技术提供的可能性和在与遥感、计算机视觉和机器人相关的应用中的有用性而成熟，正引起越来越多的兴趣。本文总结了有关 PCSS 和 PCS 最新发展的可用数据集和相关研究。
深度学习语义分割的简要概述,
Mask TextSpotter：一种端到端的可训练神经网络，用于发现具有任意形状的文本,以端到端的训练方式统一文本检测和文本识别已成为野外阅读文本的新趋势，因为这两个任务具有高度相关性和互补性。在本文中，我们研究了场景文本定位问题，旨在同时检测和识别自然图像中的文本。提出了一种名为 Mask TextSpotter 的端到端可训练神经网络。与之前的文本检测器遵循由提议生成网络和序列到序列识别网络组成的管道，Mask TextSpotter 享有简单流畅的端到端学习过程，其中可以实现检测和识别通过语义分割直接从二维空间。此外，提出了一个空间注意模块来提高性能和通用性。受益于所提出的检测和识别二维表示，它可以轻松处理不规则形状的文本实例，例如弯曲文本。我们在四个英语数据集和一个多语言数据集上对其进行评估，在检测和端到端文本识别任务中实现了始终优于最先进方法的性能。此外，我们进一步研究了我们方法的识别模块，它在常规和不规则文本数据集上的场景文本识别显着优于最先进的方法。
通过自我监督的无监督域内自适应语义分割,基于卷积神经网络的方法在语义分割方面取得了显着进展。然而，这些方法严重依赖于劳动密集型的注释数据。为了应对这一限制，从图形引擎生成的自动注释数据用于训练分割模型。然而，从合成数据训练的模型很难转移到真实图像上。为了解决这个问题，以前的工作已经考虑将模型从源数据直接调整到未标记的目标数据（以减少域间差距）。尽管如此，这些技术并未考虑目标数据本身之间的大分布差距（域内差距）。在这项工作中，我们提出了一种两步自监督域自适应方法，以最小化域间和域内的差距。首先，我们对模型进行域间自适应，从这种自适应中，我们使用基于熵的排序函数将目标域分为简单和硬分割。最后，为了减少域内差距，我们建议采用从易到难子域的自我监督适应技术。许多基准数据集的实验结果突出了我们的方法对现有最先进方法的有效性。源代码可在 https://github.com/feipan664/IntraDA.git 获得。
Kimera：实时度量语义定位和映射的开源库,我们为实时度量语义视觉惯性同步定位和映射 (SLAM) 提供开源 C++ 库。该库通过启用 3D 网格重建和语义标记，超越了现有的视觉和视觉惯性 SLAM 库（例如，ORB-SLAM、VINS-Mono、OKVIS、ROVIO）。 Kimera 在设计时考虑了模块化，并具有四个关键组件：用于快速准确状态估计的视觉惯性里程计 (VIO) 模块、用于全局轨迹估计的稳健位姿图优化器、用于快速网格重建的轻量级 3D 网格器模块，以及一个密集的 3D 度量语义重建模块。这些模块可以单独运行或组合运行，因此 Kimera 可以轻松回退到最先进的 VIO 或完整的 SLAM 系统。 Kimera 在 CPU 上实时运行，并从语义标记的图像中生成 3D 度量语义网格，这可以通过现代深度学习方法获得。我们希望 Kimera 提供的灵活性、计算效率、稳健性和准确性将为未来的度量语义 SLAM 和感知研究奠定坚实的基础，并允许研究人员跨多个领域（例如，VIO、SLAM、3D 重建、分割）无需从头开始即可对自己的工作进行基准测试和原型设计。
ConvPoint：点云处理的连续卷积,与图像相反，点云是非结构化和无序的数据。因此，大多数为图像开发的机器学习方法不能直接转移到点云。在本文中，我们提出了离散卷积神经网络 (CNN) 的泛化，以便通过用连续内核替换离散内核来处理点云。这个公式很简单，允许任意大小的点云，并且可以很容易地用于设计类似于 2D CNN 的神经网络。我们展示了各种架构的实验结果，突出了所提出方法的灵活性。与大规模点云的形状分类、部分分割和语义分割的最新技术相比，我们获得了具有竞争力的结果。 (C) 2020 Elsevier Ltd. 保留所有权利。
用于医学图像分割的 DENSE-INception U -net,
CGNet：用于语义分割的轻量级上下文引导网络,在移动设备上应用语义分割模型的需求一直在快速增长。当前最先进的网络具有大量参数，因此不适合移动设备，而其他小内存占用模型遵循分类网络的精神，忽略了语义分割的固有特征。为了解决这个问题，我们提出了一种新颖的上下文引导网络（CGNet），它是一种用于语义分割的轻量级高效网络。我们首先提出了上下文引导（CG）块，它有效地学习了局部特征和周围上下文的联合特征，并进一步改进了与全局上下文的联合特征。基于 CG 块，我们开发了 CGNet，它在网络的所有阶段捕获上下文信息。 CGNet 是专门为利用语义分割的固有属性和提高分割精度而量身定制的。此外，CGNet 经过精心设计，可减少参数数量并节省内存占用。在相同数量的参数下，所提出的 CGNet 显着优于现有的轻量级分割网络。在 Cityscapes 和 CamVid 数据集上的大量实验验证了所提出方法的有效性。具体来说，在没有任何后处理和多尺度测试的情况下，所提出的 CGNet 在 Cityscapes 上实现了 64.8% 的平均 IoU，且参数少于 0.5 M。
基于超像素语义分类的乳腺超声图像分割,乳腺癌是对女性的巨大威胁。超声成像已广泛应用于乳腺癌的诊断。由于图像质量差，乳腺超声（BUS）图像的分割仍然是一项非常具有挑战性的任务。此外，BUS图像分割是进一步分析的关键步骤。在本文中，我们提出了一种通过语义分类和合并补丁来分割乳腺肿瘤的新方法。所提出的方法首先选择两个对角点来裁剪原始图像上的感兴趣区域（ROI）。然后，采用直方图均衡化、双边滤波器和金字塔均值移位滤波器对图像进行增强。使用简单的线性迭代聚类 (SLIC) 将裁剪后的图像划分为许多超像素。此外，从超像素中提取一些特征，可以创建词袋模型。初始分类可以通过反向传播神经网络（BPNN）获得。为了细化初步结果，使用k近邻（KNN）进行重新分类并获得最终结果。为了验证所提出的方法，我们收集了一个包含 320 个案例的 BUS 数据集。我们的方法的分割结果已经与五种现有方法获得的相应结果进行了比较。实验结果表明，与传统方法相比，我们的方法在 TP 和 FP 方面取得了具有竞争力的结果，并在综合考虑所有指标的情况下对手工标记的肿瘤轮廓产生了良好的近似（F1-score = 89.87% +/- 4.05 %，平均径向误差 = 9.95% +/- 4.42%）。 (C) 2020 Elsevier BV 保留所有权利。
CrackU-net：一种用于像素级路面裂缝检测的新型深度卷积神经网络,"定期道路裂缝监测是有效路面管理的重要程序。高效和准确的裂纹测量是学术界和工业界的关键研究课题。自动方法逐渐取代了传统的人工调查，以获得更可靠的评估输出和更高的效率，而考虑到高成本和有限预算，这些设备并非适用于所有功能类别的路面和不同部门。最近，智能手机和数码相机的广泛使用使得以更容易的方式以可承受的价格收集路面裂缝图像成为可能。然而，这些裂缝图像的质量受到路面背景、道路等噪声的不同影响。因此，传统方法通常无法从路面图像中提取准确的裂缝信息。因此，本研究提出了一种最先进的像素级裂缝检测架构，称为 CrackU-net，其特点是利用了先进的深度卷积神经网络技术。 CrackU-net通过卷积、池化、转置卷积和级联操作实现逐像素裂纹检测，形成U型模型架构。该模型使用 Adam 算法通过 3,000 张路面裂缝图像进行训练和验证，其中 2,400 张用于训练，600 张用于验证。 CrackU-net 的性能损失 = 0.025，准确度 = 0.9901，精确度 = 0.9856，召回率 = 0.9798，F-measure = 0.9842，学习率为 10(-2)。同时，在 CrackU-net 中避免了假阳性裂缝检测问题。因此，对于像素级裂纹检测，CrackU-net 优于传统方法以及完全卷积网络 (FCN) 和 U-net。"
Kvasir-SEG：分段息肉数据集,逐像素图像分割是医学图像分析中一项要求很高的任务。在实践中，很难找到带有相应分割掩码的注释医学图像。在本文中，我们介绍了 Kvasir-SEG：一个开放获取的胃肠息肉图像和相应的分割掩码数据集，由医生手动注释，然后由经验丰富的胃肠病学家验证。此外，我们还借助分割掩码生成了息肉区域的边界框。我们展示了我们的数据集与传统分割方法和现代基于深度学习的卷积神经网络 (CNN) 方法的使用。该数据集对于研究人员重现结果和比较方法具有价值。通过向仅提供逐帧注释的 Kvasir 数据集添加分割掩码，我们使多媒体和计算机视觉研究人员能够在息肉分割和结肠镜检查图像的自动分析领域做出贡献。
弱监督语义分割的自监督等变注意机制,图像级弱监督语义分割是近年来深入研究的一个具有挑战性的问题。大多数高级解决方案都利用类激活图 (CAM)。然而，由于完全监督和弱监督之间的差距，CAM 几乎不能用作对象掩码。在本文中，我们提出了一种自我监督的等变注意机制（SEAM）来发现额外的监督并缩小差距。我们的方法基于观察到等方差是完全监督语义分割中的隐式约束，其像素级标签在数据增强期间采用与输入图像相同的空间变换。然而，这种约束在通过图像级监督训练的 CAM 上丢失了。因此，我们建议对来自各种变换图像的预测 CAM 进行一致性正则化，为网络学习提供自我监督。此外，我们提出了一个像素相关模块（PCM），它利用上下文外观信息并通过其相似的邻居细化当前像素的预测，从而进一步提高 CAM 的一致性。在 PASCAL VOC 2012 数据集上进行的大量实验表明，我们的方法优于使用相同监督级别的最先进方法。代码在网上发布。
在 EO 数据上绘制滑坡图：深度学习模型与传统机器学习模型的性能对比,使用自动化方法绘制滑坡图是一项具有挑战性的任务，这在很大程度上仍然需要人工完成。如今，高分辨率 EO 数据产品的可用性呈指数级增长，目标之一是利用该数据源快速生成滑坡清单。在过去十年中，对基于像素和基于对象的机器学习策略等传统方法进行了广泛研究。此外，CNN（卷积神经网络）的最新进展是一种深度学习方法，在从图像中提取信息方面取得了广泛的成功，并且优于其他传统的学习方法。在过去的几年里，只有少数尝试将 CNN 用于滑坡测绘。在这项研究中，我们介绍了一种改进的 U-Net 模型，用于使用 ResNet34 块从 EO 数据中对区域尺度的滑坡进行语义分割以进行特征提取。我们还将其与传统的基于像素和基于对象的方法进行了比较。该实验在美国俄勒冈州波特兰南部选定的研究区域道格拉斯县进行，从 SLIDO（俄勒冈州全州滑坡信息数据库）中提取的滑坡清单被认为是基本事实。滑坡测绘是一个不平衡的学习问题，训练数据的可用性非常有限。我们的网络使用从选定训练区域采样的增强图像瓦片，结合了焦点 Tversky 损失和交叉熵损失函数进行了训练。观察到深度学习方法比传统方法具有更好的性能，MCC（马修斯相关系数）得分为 0.495，POD（检测概率）率为 0.72。
ASIF-Net：用于 RGB-D 显着目标检测的注意力转向交织融合网络,从 RGB-D 图像中检测显着目标是一项重要但具有挑战性的视觉任务，旨在通过结合颜色信息和深度约束来检测场景中最独特的目标。与先前的融合方式不同，我们提出了一种注意力转向交织融合网络（ASIF-Net）来检测显着对象，该网络通过注意力机制的转向逐步整合了来自 RGB 图像和相应深度图的跨模式和跨级别互补性。具体来说，RGB-D 图像的互补特征被联合提取并以密集和交织的方式分层融合。这种方式打破了跨模态数据存在的不一致障碍，也充分捕捉到了互补性。同时，引入了一种注意力机制，以注意力加权的方式定位潜在的显着区域，在突出显着对象和抑制杂乱的背景区域方面取得了进步。我们不仅关注像素显着性，还通过结合为 RGB-D 显着性对象检测提供全局语义约束的对抗性学习来确保检测到的显着性对象具有对象性特征（例如，完整的结构和清晰的边界）。定量和定性实验表明，所提出的方法在四个公开可用的 RGB-D 显着对象检测数据集上优于 17 个最先进的显着性检测器。我们方法的代码和结果可在 https://github.com/Li-Chongyi/ASIF-Net 获得。
FDA：语义分割的傅立叶域自适应,我们描述了一种用于无监督域适应的简单方法，通过交换一个与另一个的低频频谱来减少源分布和目标分布之间的差异。我们说明了语义分割中的方法，其中密集注释的图像在一个域（例如，合成数据）中很多，但在另一个域（例如，真实图像）中很难获得。当前最先进的方法很复杂，有些方法需要对抗性优化以使神经网络的主干对离散域选择变量保持不变。我们的方法不需要任何训练来执行域对齐，只需简单的傅立叶变换及其逆变换即可。尽管它很简单，但当集成到相对标准的语义分割模型中时，它在当前基准测试中实现了最先进的性能。我们的结果表明，即使是简单的程序也可以消除更复杂的方法难以学习的数据中令人讨厌的可变性。（1）
用于 COVID-19 CT 分类的重新设计网络的对比跨站点学习,2019 年冠状病毒病 (COVID-19) 大流行已导致全球公共卫生危机蔓延到数百个国家。随着新感染病例的不断增长，迫切需要开发利用 CT 图像识别 COVID-19 的自动化工具，以帮助临床诊断并减少繁琐的图像解读工作量。为了扩大用于开发机器学习方法的数据集，聚合来自不同医疗系统的案例以学习稳健和可概括的模型本质上是有帮助的。本文提出了一种新的联合学习框架，通过有效地学习具有分布差异的异构数据集来执行准确的 COVID-19 识别。我们通过在网络架构和学习策略方面重新设计最近提出的 COVID-Net 来构建强大的主干网络，以提高预测准确性和学习效率。在我们改进的主干之上，我们通过在潜在空间中进行单独的特征归一化进一步明确地解决跨站点域转移。此外，我们建议使用对比训练目标来增强语义嵌入的域不变性，以提高每个数据集的分类性能。我们使用由 CT 图像组成的两个公共大规模 COVID-19 诊断数据集开发和评估我们的方法。大量实验表明，我们的方法持续提高了两个数据集的性能，在 AUC 上分别比在每个数据集上训练的原始 COVID-Net 高 12.16% 和 14.23%，也超过了现有的最先进的多站点学习方法。
基于双向词向量的像素级遥感图像识别,在传统的遥感图像识别中，传统的特征（如颜色特征和纹理特征）不能充分描述复杂的图像，图像像素之间的关系也不能很好的捕捉。使用单个模型或传统的顺序联合模型，在特征挖掘过程中很容易丢失深层特征。本文提出了一种新的特征提取方法，该方法利用自然语言处理中的词嵌入方法生成双向真实密集向量，以反映像素之间的上下文关系。将双向独立循环神经网络（BiIndRNN）与卷积神经网络（CNN）相结合，改进切片循环神经网络（SRNN）算法模型，然后在注意力机制下与图卷积网络（GCN）并行构建充分利用图像的深层特征并捕获上下文的语义信息。该模型统称为改进的 SRNN 和基于注意力处理的基于 GCN 的并行 (SAGP) 模型。在胡杨林上进行的实验表明，所提出的方法在识别准确率方面优于传统方法。在公共数据集上进行的验证也证明了这一点。
自适应多视觉技术增强的果园香蕉中心种群三维感知,在果园和田地中进行基于视觉的自动采摘是一项极具挑战性的任务。本研究以果园香蕉中心砧木体积大、颜色对比度低、背景复杂等特点作为研究对象。建立了基于多视觉技术的测量框架，并利用一套通用方法提高了基于多视图几何的视觉模块在果园采摘任务中的综合性能。部署了多个不同角度的摄像头，以最大限度地扩大感知范围。对相机的全局几何参数进行标定，并训练鲁棒的语义分割网络以实现有效的图像预处理。设计了一种新颖的自适应立体匹配策略，以确保机器人在穿过目标区域时可靠地完成不同深度的 3D 三角测量。通过高精度点云拼接算法校正全局校准误差。实验结果表明，所提出的自适应立体匹配策略对不同的采样深度都准确，表现出稳定的性能，所提出的点云拼接算法对多视点点云进行了准确拼接。这项工作为复杂环境中香蕉中心种群的 3D 传感提供了理论和实践参考。所提出的技术是针对多视觉系统对田间感知的适应性而设计的，因此它可以很容易地转移到类似的应用中，例如农业目标的 3D 重建、水果簇的 3D 定位和 3D 机械臂避障。
分层注意连体网络的视觉对象跟踪,视觉跟踪解决了根据带注释的边界框定位视频中任意目标的问题。在本文中，我们提出了一种新颖的跟踪方法，将注意力机制引入 Siamese 网络以增加其匹配辨别力。我们提出了一种计算注意力权重的新方法，以通过子连体网络 [Attention Net (A-Net)] 提高匹配性能，该网络定位注意力部分以解决搜索问题。此外，较高层的特征可以保留更多的语义信息，而较低层的特征可以保留更多的位置信息。因此，为了解决高层特征跟踪失败的情况，我们充分利用多级特征的位置和语义信息，并提出一种融合各层多尺度响应图的新方法，以获得更准确的目标位置估计。我们通过结合注意力权重和多层集成进行跟踪，进一步提出了分层注意力连体网络。我们的方法是使用预训练网络实现的，即使没有任何微调和在线更新，它也可以胜过大多数训练有素的连体跟踪器。在流行的跟踪基准上与最先进的方法的比较结果表明，我们的方法取得了更好的性能。我们的源代码和结果将在 https://github.com/shenjianbing/HASN 上提供。
在没有人工注释的情况下学习深度显着性网络的综合监督,近年来，随着深度神经网络的广泛应用，显着目标检测的研究领域正在经历快速而显着的发展。深度显着目标检测器经过大量使用强像素级真实掩码注释的图像进行训练，达到了最先进的性能。然而，为每个训练图像提供像素级的真实掩码既昂贵又耗时。为了解决这个问题，本文提出了最早的框架之一来学习深度显着对象检测器，而无需任何人工注释。我们的学习框架中使用的监督信号是通过一种新颖的监督合成方案生成的，其中关键见解是知识源转换和融合监督。具体来说，在所提出的学习框架中，外部知识源和内部知识源都被动态探索，为我们方法中所需的合成监督提供信息线索，同时还建立了双流融合机制来实现监督合成过程。对四个基准数据集的综合实验表明，由我们新提出的学习框架训练的深度显着对象检测器通常在不需要任何人工注释掩码的情况下运行良好，甚至接近在完全监督学习方式下获得的上限（仅 3% 以内）性能差距）。此外，我们还应用通过我们的无注释学习框架学习的显着对象检测器来辅助弱监督语义分割任务，这表明我们的方法还可以减轻现有弱监督语义分割框架中所需的大量补充监督。
用于遥感图像语义分割的超像素增强深度神经森林,语义分割在遥感图像理解中起着重要作用。随着深度卷积神经网络 (DCNN) 的发展，该领域取得了巨大进展。然而，由于地物频谱的复杂性，具有简单分类器的DCNN即使能够有效地表示图像特征，也难以区分地物类别。此外，基于 DCNN 的语义分割方法学习在导致对象边界模糊的大感受野上积累上下文信息。在这项工作中，提出了一种名为超像素增强深度神经森林 (SDNF) 的新方法来解决上述问题。为了提高分类能力，我们引入了深度神经森林（DNF），其中深度神经网络的表示学习是由一个完全可微的决策森林进行的。因此，通过以端到端的方式将 DCNN 与决策森林相结合，可以实现更好的分类精度。此外，考虑到超像素内部的同质性和超像素之间的异质性，提出了一种超像素增强区域模块（SRM），以进一步减轻噪声并增强地面物体的边缘。 ISPRS 2D 语义标签基准的实验结果表明，我们的模型显着优于最先进的方法，从而验证了我们提出的 SDNF 的效率。
SEAN：具有语义区域自适应归一化的图像合成,我们提出语义区域自适应归一化（SEAN），这是生成对抗网络的一个简单但有效的构建块，其条件是分割掩码，描述了所需输出图像中的语义区域。使用 SEAN 归一化，我们可以构建一个可以单独控制每个语义区域的样式的网络架构，例如，我们可以为每个区域指定一个样式参考图像。在重建质量、可变性和视觉质量方面，SEAN 比以前最好的方法更适合编码、转移和合成风格。我们在多个数据集上评估 SEAN，并报告比当前最先进的更好的定量指标（例如 FID、PSNR）。 SEAN 还推动了交互式图像编辑的前沿。我们可以通过更改分割掩码或任何给定区域的样式来交互式地编辑图像。我们还可以从每个区域的两个参考图像中插入样式。代码：https：//github。 com/ZPdesu/肖恩。
多器官核分割挑战,"广义细胞核分割技术可以极大地减少为新的数字病理学数据集开发和验证视觉生物标志物的时间。我们总结了 MoNuSeg 2018 挑战赛的结果，其目标是在数字病理学中开发可推广的细胞核分割技术。该挑战是 MICCAI 2018 会议的官方卫星活动，来自不同地区的机构的 32 个团队和 80 多名参与者参加了该会议。参赛者获得了一个训练集，其中包含来自七个器官的 30 张图像，并带有 21,623 个单个核的注释。一个测试数据集包含从七个器官拍摄的 14 张图像，包括两个未出现在训练集中的器官，在没有注释的情况下发布。根据测试集上的平均聚合 Jaccard 指数 (AJI) 评估条目，以优先考虑准确的实例分割，而不是单纯的语义分割。完成挑战的团队超过一半的表现优于之前的基准。观察到的有助于提高准确性的趋势包括使用颜色归一化以及大量数据增强。此外，受 U-Net、FCN 和 Mask-RCNN 变体启发的全卷积网络被广泛使用，通常基于 ResNet 或 VGG 基础架构。预测语义分割图上的分水岭分割是一种流行的后处理策略。与单个人类注释器相比，一些顶级技术具有优势，并且可以放心地用于核形态测量学。"
使用社交机器人试镜的普通话膳食成分感知算法,随着人口老龄化问题越来越严重，社交机器人对人类生活的影响越来越大。通过使用定期问答对话或可穿戴设备，一些社交机器人产品可以建立个人健康档案。但这些机器人无法通过机器人视觉或听觉自动收集饮食信息。健康的饮食可以降低一个人患癌症、糖尿病、心脏病和其他与年龄有关的疾病的风险。为了通过听人聊天自动感知老年人的膳食成分，本文提出了一种基于聊天的自动膳食成分感知算法（DCPA）。 DCPA 使用社交机器人试听来了解汉语的语义信息和感知膳食成分。首先，基于梅尔频率倒谱系数和卷积神经网络，设计了一种说话人识别方法来识别语音数据。基于语音分割和说话人识别算法，提出了一种音频片段分类方法，用于区分不同说话人，存储其身份信息和语音会话中的表达顺序。其次，建立了饮食词典，提出了两种饮食成分语义理解算法来理解饮食语义和感知饮食成分信息。为了评估提出的 DCPA 算法的性能，我们在我们的社交机器人平台中实现了提出的 DCPA。然后我们建立了与单人和多人聊天相关的两类测试数据集。测试结果表明DCPA能够理解用户；膳食成分，F1 分数分别为 0.9505、0.8940 和 0.8768，用于单人交谈、两人聊天和三人聊天。 DCPA对于获取膳食信息具有良好的鲁棒性。
对比增强 CT 成像中肾脏和肾脏肿瘤分割的最新技术：KiTS19 挑战的结果,有大量文献将肾脏肿瘤的解剖和几何特征与围手术期和肿瘤学结果联系起来。这些肿瘤及其宿主肾脏的语义分割是定量表征这些病变的有前途的工具，但由于产生这些结构的高质量 3D 分割所需的手动工作，其采用受到限制。近来，基于深度学习的方法在自动 3D 分割方面取得了很好的效果，但它们需要大量数据集进行训练，对于哪种方法表现最好还没有达成共识。 2019 年肾脏和肾脏肿瘤分割挑战赛 (KiTS19) 是与 2019 年国际医学图像计算和计算机辅助干预会议 (MICCAI) 联合举办的竞赛，旨在解决这些问题并促进这一自动分割问题的进展。公开发布了包含 210 幅肾肿瘤横截面 CT 图像的训练集，并带有相应的语义分割掩码。来自五大洲的 106 个团队使用这些数据开发了自动化系统，以在 90 张 CT 图像的测试集上预测真正的分割掩模，其中相应的地面真实分割是保密的。这些预测根据所有 90 个病例的肾脏和肿瘤之间的平均 Sorensen-Dice 系数进行评分和排名。获胜团队的 Dice 为肾脏 0.974，肿瘤为 0.851，接近肾脏 (0.983) 的注释器间性能，但在肿瘤 (0.923) 上的表现不及格。这一挑战现已进入开放排行榜阶段，成为 3D 语义分割中具有挑战性的基准。 (C) 2020 Elsevier BV 保留所有权利。
使用 Transformer 从序列到序列的角度重新思考语义分割,最近的语义分割方法采用具有编码器-解码器架构的全卷积网络 (FCN)。编码器逐渐降低空间分辨率并学习更多具有更大感受野的抽象/语义视觉概念。由于上下文建模对于分割至关重要，因此最新的努力集中在通过扩张/空洞卷积或插入注意力模块来增加感受野。然而，基于编码器-解码器的 FCN 架构保持不变。在本文中，我们旨在通过将语义分割视为序列到序列的预测任务来提供另一种视角。具体来说，我们部署了一个纯转换器（即没有卷积和分辨率降低）来将图像编码为一系列补丁。借助在转换器的每一层中建模的全局上下文，该编码器可以与简单的解码器相结合，以提供强大的分割模型，称为 SEgmentation TRansformer (SETR)。大量实验表明，SETR 在 ADE20K (50.28% mIoU)、Pascal Context (55.83% mIoU) 和 Cityscapes 上取得了竞争性结果。特别是在提交当天，我们在竞争激烈的 ADE2OK 测试服务器排行榜中获得了第一名。
基于特征融合模型改进语义图像分割的研究,由于特征的低分辨率以及最大池化层和下采样层的重复组合，图像的上下文信息已经丢失。当使用卷积网络执行特征提取过程时，语义图像分割的结果对对象的位置失去了敏感性。提出了基于逐层上下文特征的特征融合模型的语义图像分割。首先，对原始图像进行高斯核函数预处理，生成一系列不同分辨率的图像，形成图像金字塔。其次，将图像金字塔输入到网络结构中，将多个全卷积网络并行组合，通过使用Atrous Convolutions扩展感受野得到一组不同粒度的初始特征，并进行不同层的特征融合初始化- 自上而下方法中的逐层粒度。最后，计算出特征融合模型的得分图并发送给条件随机场，利用全连接条件随机场对原图像的图像像素之间的类相关性以及图像的空间位置信息和颜色矢量信息进行建模。像素被连接以优化并获得结果。在 PASCAL VOC 2012 和 PASCAL Context 数据集上的实验比最先进的作品取得了更好的平均交叉联合。所提出的方法比传统方法改进了约 6.3%。
Mask-Refined R-CNN：用于在实例分割中细化对象细节的网络,随着柔性视觉传感器和视觉传感器网络的快速发展，目标检测和跟踪等计算机视觉任务正在进入一个新阶段。因此，包括实例分割在内的更具挑战性的综合任务可以迅速发展。大多数最先进的网络框架，例如分割，都是基于 Mask R-CNN（掩模区域卷积神经网络）。然而，实验结果证实，Mask R-CNN 并不总能成功预测实例细节。 Mask R-CNN 的尺度不变全卷积网络结构忽略了不同大小的感受野之间的空间信息差异。大规模感受野更关注细节信息，而小感受野更关注语义信息。所以网络不能考虑物体边缘像素之间的关系，这些像素就会被错误分类。为了克服这个问题，提出了Mask-Refined R-CNN（MR R-CNN），其中对ROIAlign（region of interest align）的stride进行了调整。此外，将原来的全卷积层替换为新的语义分割层，通过构建特征金字塔网络，将相同分辨率的特征图的前向和后向传输相加，实现特征融合。通过结合关注全局和详细信息的特征层，可以显着提高分割精度。在 COCO（Common Objects in Context）和 Cityscapes 数据集上的实验结果表明，MR R-CNN 的分割精度比使用相同主干的 Mask R-CNN 高 2% 左右。大实例的平均精度达到 56.6%，高于所有最先进的方法。此外，所提出的方法所需的时间成本低且易于实施。在 Cityscapes 数据集上的实验也证明了所提出的方法具有很强的泛化能力。
PointPainting：用于 3D 对象检测的顺序融合,摄像头和激光雷达是一般机器人，尤其是自动驾驶汽车的重要传感器模式。传感器提供补充信息，为紧密的传感器融合提供了机会。令人惊讶的是，仅激光雷达的方法在主要基准数据集上的表现优于融合方法，这表明文献中存在差距。在这项工作中，我们提出了 PointPainting：一种填补这一空白的顺序融合方法。 PointPainting 的工作原理是将激光雷达点投影到仅图像语义分割网络的输出中，并将类分数附加到每个点。然后可以将附加（绘制）的点云馈送到任何仅使用激光雷达的方法。实验表明，在 KITTI 和 nuScenes 数据集上，三种不同的最先进方法（Point-RCNN、VoxelNet 和 PointPillars）有很大改进。 PointRCNN 的彩绘版本代表了 KITTI 排行榜上鸟瞰图检测任务的最新技术。在消融中，我们研究了绘画的效果如何取决于语义分割输出的质量和格式，并展示了如何通过流水线将延迟最小化。
使用集成深度学习方法在皮肤镜图像中进行皮肤病变分割,早期发现皮肤癌，尤其是黑色素瘤，对于实现高级治疗至关重要。由于皮肤癌数量的快速增长，对皮肤病变的计算机分析的需求日益增长。用于皮肤损伤的最先进的公共可用数据集通常伴随着数量非常有限的分割基础事实标签。此外，可用的分割数据集由嘈杂的专家注释组成，反映了表示皮肤病变边界的精确注释既费力又昂贵的事实。病变边界分割对于在皮肤镜图像中准确定位病变和对不同皮肤病变类型进行病变诊断至关重要。在这项工作中，我们提出了全自动深度学习集成方法，以实现病变边界分割的高灵敏度和高特异性。我们在 ISIC-2017 分割训练集上训练了基于 Mask R-CNN 和 DeeplabV3 C 方法的集成方法，并在 ISIC-2017 测试集和 PH2 数据集上评估了集成网络的性能。我们的结果表明，对于 ISIC-2017 测试集，所提出的集成方法以 89.93% 的敏感性和 97.94% 的特异性对皮肤病变进行分割。所提出的集成方法 Ensemble-A 在灵敏度方面分别优于 FrCN、FCNs、U-Net 和 SegNet 4.4%、8.8%、22.7% 和 9.8%。此外，所提出的集成方法 Ensemble-S 在 ISIC-2017 测试集上实现了临床良性病例 97.98%、黑色素瘤病例 97.30% 和脂溢性角化病病例 98.58% 的特异性评分，表现出比 FrCN、FCNs 更好的性能、U-Net 和 SegNet。
基于全卷积网络的多标签遥感图像检索,传统的遥感图像检索 (RSIR) 系统通常执行单标签检索，其中每个图像都由表示图像最重要语义内容的单个标签进行注释。然而，在这种情况下，遥感图像的场景复杂性被忽略了，其中图像可能有多个类别（即多个标签），导致检索性能不佳。因此，我们提出了一种基于全卷积网络 (FCN) 的新型多标签 RSIR 方法。具体来说，首先训练 FCN 以预测所考虑的图像存档中每个图像的分割图。然后我们获得多标签向量并根据其分割图提取每个图像的区域卷积特征。提取的区域特征最终用于执行基于区域的多标签检索。实验结果表明，与手工和卷积神经网络特征相比，我们的方法实现了最先进的性能。
卫星图像细粒度城中村提取的域自适应,城中村是快速城市化过程中形成的特色产品。由于复杂的城市结构和标记样本的不足，从卫星图像中对 UV 进行细粒度映射一直是一个相当大的挑战。在这封信中，我们建议使用域适应策略来解决域转移问题，通过对抗性学习来调整语义分割网络，从而自适应地获得来自不同域的输入图像的相似输出。所提出的方法与几个分割网络相结合，包括 U-Net、RefineNet 和 DeepLab v3+，结果表明域适应可以显着改善 UV 的像素级映射。
苹果园环境的水果检测、分割和 3D 可视化,开发准确可靠的水果检测系统是一项具有挑战性的任务。果园环境中存在许多复杂的条件，例如光照变化、外观变化和遮挡等。需要机器人视觉从感官数据中了解工作环境并引导机械臂分离水果。在我们之前的工作中，开发了一个深度神经网络 DaSNet-v1 来对果园环境中的水果和树枝进行检测和分割。但是，语义分割返回每个类而不是每个对象的掩码。每个水果的分割很重要，因为它可以提供每个对象的丰富信息，特别是对于那些重叠的水果。这项工作提出了一种改进的深度神经网络 DaSNet-v2，它可以对水果进行检测和实例分割，以及对树枝进行语义分割。 DaSNet-v2 通过在苹果园的现场测试中获得的实验结果进行了测试和验证。从实验结果来看，带有 resnet-101 的 DaSNet-v2 的召回率和检测精度以及水果实例分割的准确率分别达到 0.868、0.88 和 0.873，分支分割的准确率分别达到 0.794。具有轻量级骨干 resnet-18 的 DaSNet-v2 在召回率和检测精度、水果实例分割精度以及分支分割精度分别达到 0.85、0.87 和 0.866。轻量级 DaSNet-v2 的平均运行时间和权重大小分别为 55 ms 和 8.1 M。实验结果表明，DaSNet-v2 可以稳健高效地执行视觉传感，用于苹果园的机器人收割。
Panoptic-DeepLab：一个简单、强大、快速的自下而上全景分割的基线,在这项工作中，我们介绍了 Panoptic-DeepLab，这是一个简单、强大且快速的全景分割系统，旨在为自下而上的方法建立一个坚实的基线，该方法可以实现与两阶段方法相当的性能，同时产生快速的推理速度。特别是，Panoptic-DeepLab 分别采用了特定于语义和实例分割的双 ASPP 和双解码器结构。语义分割分支与任何语义分割模型（例如，DeepLab）的典型设计相同，而实例分割分支与类无关，涉及简单的实例中心回归。因此，我们的单个 Panoptic-DeepLab 同时在所有三个 Cityscapes 基准测试中均排名第一，在测试集上设置了 84.2% mIoU、39.0% AP 和 65.5% PQ 的最新技术水平。此外，配备 MobileNetV3 的 Panoptic-DeepLab 几乎实时运行单张 1025 倍 2049 图像（每秒 15.8 帧），同时在 Cityscapes 上实现了具有竞争力的性能（测试集上的 54.1 PQ%）。在 Mapillary Vistas 测试集上，我们的六个模型的集合达到了 42.7% 的 PQ，比 2018 年的挑战获胜者高出 1.5%。最后，我们的 Panoptic-DeepLab 在具有挑战性的 COCO 数据集上的表现也与几种自上而下的方法相当。我们首次展示了一种自下而上的方法可以在全景分割上提供最先进的结果。
场景分割的上下文先验,最近的工作广泛探索了上下文依赖关系，以实现更准确的分割结果。然而，大多数方法很少区分不同类型的上下文依赖关系，这可能会污染场景理解。在这项工作中，我们直接监督特征聚合以清楚地区分类内和类间上下文。具体来说，我们在 Affinity Loss 的监督下开发了一个 Context Prior。给定输入图像和相应的基本事实，Affinity Loss 构建一个理想的亲和图来监督 Context Prior 的学习。学习的上下文先验提取属于同一类别的像素，而反向先验则关注不同类别的像素。嵌入到传统的深度 CNN 中，所提出的上下文先验层可以选择性地捕获类内和类间的上下文依赖关系，从而实现鲁棒的特征表示。为了验证有效性，我们设计了一个有效的上下文先验网络（CPNet）。广泛的定量和定性评估表明，所提出的模型优于最先进的语义分割方法。更具体地说，我们的算法在 ADE20K 上达到 46.3% mIoU，在 PASCAL-Context 上达到 53.9% mIoU，在 Cityscapes 上达到 81.3% mIoU。代码可在 https://git.io/ContextPrior 获得。
通过融合多级 CNN 特征进行 RGB-T 显着目标检测,RGB 诱导的显着目标检测最近取得了实质性进展，这归功于深度卷积神经网络 (CNN) 的卓越特征学习能力。然而，此类检测会遇到具有挑战性的场景，其特点是背景杂乱、光线不足和光照变化。本文没有改进基于 RGB 的显着性检测，而是利用了 RGB 和热红外图像的互补优势。具体来说，我们提出了一种用于多模态显着性目标检测的新型端到端网络，它将 RGB-T 显着性检测的挑战转变为 CNN 特征融合问题。为此，首先采用骨干网络（例如，VGG-16）从每个RGB或热红外图像中单独提取粗略特征，然后设计几个相邻深度特征组合（ADFC）模块来提取多级考虑到在不同深度捕获的特征在语义信息和视觉细节方面存在差异，对每个单模态输入图像进行细化特征。随后，采用多分支组融合 (MGF) 模块通过融合来自 ADFC 模块的那些特征来捕获跨模态特征，以获得每个级别的 RGB-T 图像对。最后，联合注意力引导的双向消息传递（JABMP）模块通过集成来自 MGF 模块的多级融合特征来承担显着性预测的任务。在几个公共 RGB-T 显着目标检测数据集上的实验结果证明了我们提出的算法优于最先进的方法，特别是在具有挑战性的条件下，例如光照差、背景复杂和对比度低。
具有双重关系感知注意网络的场景分割,在本文中，我们提出了一个双关系感知注意网络 (DRANet) 来处理场景分割任务。如何有效地利用上下文对于像素级识别至关重要。为了解决这个问题，我们基于关系感知注意机制自适应地捕获上下文信息。特别是，我们在扩张的全卷积网络（FCN）的顶部附加了两种类型的注意力模块，它们分别对空间和通道维度的上下文依赖关系进行建模。在注意力模块中，我们采用自注意力机制来模拟任意两个像素或通道之间的语义关联。每个像素或通道可以根据它们的相关性自适应地聚合来自所有像素或通道的上下文。为了降低上述成对关联计算带来的高计算和内存成本，我们进一步设计了两种紧凑的注意力模块。在紧凑的注意力模块中，每个像素或通道仅与少数几个聚集中心建立关联，并在这些聚集中心上获得相应的上下文聚合。同时，我们添加了一个跨级门控解码器，以选择性地增强空间细节，从而提高网络的性能。我们进行了广泛的实验来验证我们网络的有效性，并在四个具有挑战性的场景分割数据集（即 Cityscapes、ADE20K、PASCAL Context 和 COCO Stuff 数据集）上实现新的最先进的分割性能。特别是，在 Cityscapes 测试集上的平均 IoU 得分为 82.9%，而无需使用额外粗略的注释数据。
使用 CT 扫描图像自动进行 COVID-19 肺部感染区域分割和测量,历史表明，传染病（COVID-19）可以迅速震惊世界，对健康造成巨大损失，从安全和经济角度对数十亿人的生活产生深远影响，以控制 COVID- 19 流行病。最好的策略是提供早期干预以阻止疾病的传播。通常，计算机断层扫描 (CT) 用于检测肺炎、肺、肺结核、肺气肿或其他胸膜（覆盖肺部的膜）疾病中的肿瘤。 CT 成像系统的缺点是：与 MRI 相比，软组织对比度较差，因为它是基于 X 射线的辐射暴露。肺部 CT 图像分割是肺部图像分析的必要初始步骤。由于强度的不均匀性、伪影的存在以及不同软组织灰度的接近性，分割算法的主要挑战被夸大了。本文的目的是设计和评估一种自动工具，用于使用胸部 CT 图像进行自动 COVID-19 肺部感染分割和测量。与最先进的分割方法（即 GraphCut、医学图像分割 (MIS) 和分水岭）相比，广泛的计算机模拟表明，这种端到端学习方法在 CT 图像分割和图像增强方面具有更高的效率和灵活性。在 COVID-CT 数据集上进行的实验，其中包含 (275) 份对 COVID-19 呈阳性的 CT 扫描以及从 EL-BAYANE 放射学和医学成像中心获得的新数据。使用准确度、灵敏度、F-measure、精确度、MCC、Dice、Jacquard 和特异性获得的统计量度均值分别为 0.98、0.73、0.71、0.73、0.71、0.71、0.57、0.99；这比上面提到的方法更好。所取得的结果证明，所提出的方法更加稳健、准确和直接。(c) 2020 Elsevier Ltd. 保留所有权利。
利用卷积神经网络在基于无人机的高分辨率 RGB 图像中绘制森林树种,在植被遥感中使用无人机 (UAV) 可以在时间上灵活且经济高效地获取高分辨率图像。尽管如此，目前用于绘制森林树种的方法并没有利用各自丰富的空间信息。在这里，我们评估了卷积神经网络 (CNN) 和来自无人机的高分辨率 RGB 图像在绘制温带森林树种的潜力。我们使用多旋翼无人机在南部黑森林地区和德国海尼希国家公园的 51 公顷温带森林中获得了非常高分辨率（<2 厘米）的 RGB 图像。为了充分利用 CNN 的端到端学习能力，我们使用了一种语义分割方法 (U-net)，该方法同时对图像中的树种进行分割和分类。凭借研究区域、场地条件、光照特性和物候学方面的多样化数据集，我们准确地绘制了九种树种、三个属级类别、枯木和森林地面（平均 F1 分数 0.73）。 CNN 训练期间较大的图块大小会对代表性不足的类的模型准确性产生负面影响。归一化数字表面模型的附加高度信息略微提高了模型精度，但增加了计算复杂性和数据要求。较粗的空间分辨率显着降低了模型精度（在 32 cm 分辨率下平均 F1 分数为 0.26）。我们的研究结果突出了无人机在森林树种测绘中可以发挥的关键作用，因为航空和航天遥感目前无法提供可比的空间分辨率。 CNN 的端到端学习能力使得广泛的预处理部分过时。使用大而多样的数据集有助于 CNN 的高度泛化，从而促进可迁移性。高分辨率无人机图像和 CNN 的协同作用提供了一种快速、灵活且准确的森林树种测绘方法。
关系问题：关系上下文感知全卷积网络用于高分辨率航空图像的语义分割,当前大多数语义分割方法都依赖于深度卷积神经网络（CNN）。然而，他们使用带有局部感受野的卷积运算导致建模上下文空间关系的失败。先前的工作试图通过在网络中使用图形模型或空间传播模块来解决这个问题。但此类模型通常无法捕捉实体之间的远程空间关系，从而导致空间碎片化的预测。此外，最近的工作表明，通道信息在 CNN 中也起着关键作用。在本文中，我们介绍了两个简单而有效的网络单元，空间关系模块和通道关系模块来学习和推理任意两个空间位置或特征图之间的全局关系，然后生成关系增强 (RA) 特征表示.空间和通道关系模块具有通用性和可扩展性，可以与现有的完全卷积网络（FCN）框架以即插即用的方式使用。我们使用两个航拍图像数据集，即国际摄影测量与遥感学会 (ISPRS) Vaihingen 和 Potsdam 数据集，在语义分割任务上评估配备关系模块的网络，它们从根本上依赖于远程空间关系推理。这些网络取得了非常有竞争力的结果，在 Vaihingen 数据集上的平均 F1 得分为 88.54%，在 Potsdam 数据集上的平均 F1 得分为 88.01%，与基线相比有了显着的改进。
使用具有植被指数的深度学习的语义分割用于多日期无人机可见图像中的水稻倒伏识别,快速、精准的大规模农业灾害调查是农业救灾和保险的基础，但劳动强度大、耗时长。本研究通过深度学习图像处理应用无人机 (UAV) 图像来估计大面积稻田中的水稻倒伏。本研究采用两种神经网络架构 FCN-AlexNet 和 SegNet 建立了图像语义分割模型，探讨了其在解释各种对象大小和计算效率方面的效果。商用无人机在高分辨率可见图像中成像稻田，用于计算三个植被指标，以提高可见图像的适用性。所提出的模型于 2017 年在一组无人机图像上进行了训练和测试，并于 2019 年在一组无人机图像上进行了验证。对于 2017 年无人机图像上的水稻倒伏识别，F1 得分达到 0.80，FCN 得分达到 0.79-分别是 AlexNet 和 SegNet。使用 RGB + ExGR 组合的 FCN-AlexNet 的 F1-score 在 2019 年的验证图像中也达到了 0.78。所提出的采用语义分割网络的模型被证明比最大似然方法具有更好的效率，大约快 10 到 15 倍，并且误译率更低。
DoubleU-Net：用于医学图像分割的深度卷积神经网络,语义图像分割是用相应的类别标记图像的每个像素的过程。基于编码器-解码器的方法，如 U-Net 及其变体，是解决医学图像分割任务的流行策略。为了提高 U-Net 在各种分割任务上的性能，我们提出了一种称为 DoubleU-Net 的新颖架构，它是两个相互堆叠的 U-Net 架构的组合。第一个 U-Net 使用预训练的 VGG-19 作为编码器，它已经从 ImageNet 中学习了特征，可以轻松地转移到另一个任务中。为了有效地捕获更多语义信息，我们在底部添加了另一个 U-Net。我们还采用 Atrous Spatial Pyramid Pooling (ASPP) 来捕获网络中的上下文信息。我们使用四个医学分割数据集评估了 DoubleU-Net，涵盖了各种成像模式，如结肠镜检查、皮肤镜检查和显微镜检查。在 2015 年 MICCAI 子挑战自动息肉检测数据集、CVC-ClinicDB、2018 年数据科学碗挑战和病变边界分割数据集上的实验表明，DoubleU-Net 优于 U-Net 和基线模型。此外，DoubleU-Net 产生更准确的分割掩码，特别是在 CVC-ClinicDB 和 2015 MICCAI 子挑战自动息肉检测数据集的情况下，这些数据集具有具有挑战性的图像，例如较小和扁平的息肉。这些结果显示了对现有 U-Net 模型的改进。在各种医学图像分割数据集上产生的令人鼓舞的结果表明，DoubleU-Net 可以用作医学图像分割和跨数据集评估测试的强大基线，以衡量深度学习 (DL) 模型的普遍性。
用于低对比度医学图像分割的高分辨率编码器-解码器网络,自动图像分割是许多医学图像分析应用的重要步骤，包括计算机辅助放射治疗、疾病诊断和治疗效果评估。这项任务的主要挑战之一是医学图像（例如 CT、MR 和显微图像）的模糊性质，这通常会导致低对比度和消失的边界。随着卷积神经网络的最新进展，图像分割已经取得了巨大的进步，主要基于跳跃连接链接的编码器 - 解码器深度架构。然而，在许多应用中（在模糊图像中具有相邻目标），这些模型通常无法准确定位复杂边界并正确分割微小的孤立部分。在本文中，我们旨在提供一种模糊医学图像分割的方法，并认为跳过连接不足以帮助准确定位模糊边界。因此，我们提出了一种新颖的高分辨率多尺度编码器-解码器网络（HMEDN），其中为编码器-解码器结构引入了多尺度密集连接，以精细地利用综合语义信息。除了跳过连接外，还集成了额外深度监督的高分辨率路径（由密集连接的扩张卷积组成）以收集高分辨率语义信息，以实现准确的边界定位。这些路径与难度引导的交叉熵损失函数和轮廓回归任务配对，以提高边界检测的质量。在盆腔 CT 图像数据集、多模态脑肿瘤数据集和细胞分割数据集上的广泛实验分别表明了我们的方法在 2D/3D 语义分割和 2D 实例分割方面的有效性。我们的实验结果还表明，除了增加网络复杂度外，提高语义特征图的分辨率也会在很大程度上影响模型的整体性能。对于不同的任务，在这两个因素之间找到平衡点可以进一步提高相应网络的性能。
使用深度卷积神经网络进行图像分割的演变：一项调查,从自动驾驶汽车到医疗诊断，图像分割任务的需求无处不在。图像分割是计算机视觉中不可或缺的任务之一。该任务比其他视觉任务相对复杂，因为它需要低级空间信息。基本上，图像分割可以有两种类型：语义分割和实例分割。这两个基本任务的组合版本称为全景分割。在最近的时代，深度卷积神经网络（CNN）的成功极大地影响了分割领域，并为我们提供了迄今为止各种成功的模型。在本次调查中，我们将大致了解基于 CNN 的语义和实例分割工作的演变。我们还指定了一些最先进模型的比较架构细节，并讨论了它们的训练细节，以清晰地理解这些模型的超参数调整。我们还对这些模型在不同数据集上的性能进行了比较。最后，我们瞥见了一些最先进的全景分割模型。 (C) 2020 Elsevier BV 保留所有权利。
CCNet：语义分割的交叉注意力。,上下文信息在视觉理解问题中至关重要，例如语义分割和对象检测。我们提出了一个纵横交错网络（CCNet），用于以非常有效和高效的方式获取全图像上下文信息。具体来说，对于每个像素，一个新的交叉注意力模块会收集其交叉路径上所有像素的上下文信息。通过进一步的循环操作，每个像素最终都可以捕获全图像的依赖关系。此外，提出了一个类别一致的损失来强制交叉注意力模块产生更多的判别特征。总体而言，CCNet 具有以下优点：1）GPU 内存友好。与非局部块相比，所提出的循环交叉注意力模块需要的 GPU 内存使用量减少 11 倍。 2）计算效率高。反复出现的交叉注意力显着减少了非局部块的 85% 左右的 FLOP。 3) 最先进的性能。我们对语义分割基准进行了广泛的实验，包括 Cityscapes、ADE20K、人类解析基准 LIP、实例分割基准 COCO、视频分割基准 CamVid。特别是，我们的 CCNet 在 Cityscapes 测试集、ADE20K 验证集和 LIP 验证集上分别取得了 81.9%、45.76% 和 55.47% 的 mIoU 分数，这是新的最先进的结果。源代码可在 https://github.com/speedinghzl/CCNet 获得。
双分支组合网络 (DCN)：使用 CT 图像实现 COVID-19 的准确诊断和病灶分割,随着医疗资源越来越受到限制，最近全球爆发和传播冠状病毒病 (COVID-19) 使得开发准确有效的疾病诊断工具成为当务之急。人工智能 (AI) 辅助工具已展现出理想的潜力；例如，胸部计算机断层扫描 (CT) 已被证明在 COVID-19 的诊断和评估中发挥重要作用。然而，开发用于疾病检测的基于 CT 的 AI 诊断系统面临着相当大的挑战，这主要是由于缺乏足够的人工描述样本进行训练，以及对早期感染的细微病变有足够的敏感性。阶段。在这项研究中，我们开发了一种用于 COVID-19 诊断的双分支组合网络 (DCN)，可以同时实现个体级分类和病灶分割。为了将分类分支更集中地集中在病变区域，开发了一种新的病变注意模块来整合中间分割结果。此外，为了管理来自各个设施的不同成像参数的潜在影响，提出了一种切片概率映射方法来学习从切片级别到个人级别分类的转换。我们对来自中国十个研究所的 1202 名受试者的大型数据集进行了实验。结果表明：1）提出的DCN在内部数据集上的分类准确率为96.74%，在外部验证数据集上的分类准确率为92.87%，优于其他模型； 2) DCN 在较少样本的情况下获得了相当的性能，并表现出更高的灵敏度，尤其是在细微病变检测方面； 3) 与其他深度模型相比，DCN 在感染位点上提供了良好的可解释性，因为它的分类是由高级语义信息引导的。从我们提出的框架衍生的基于 CT 的 COVID-19 在线诊断平台现已推出。 (C) 2020 Elsevier BV 保留所有权利。
边缘深度学习：使用卷积神经网络从卫星图像中提取场边界,数字农业服务的应用通常需要农民或其顾问提供其田间边界的数字记录。从卫星图像中自动提取田界边界将减少对这些记录的人工输入的依赖，因为人工输入是耗时的，并且将支持远程产品和服务的提供。当前字段边界数据集的缺乏似乎表明现有方法的采用率较低，这可能是因为昂贵的图像预处理要求和局部的（通常是任意的）调整。在本文中，我们提出了一种数据驱动、稳健且通用的方法，以促进从卫星图像中提取场边界。我们将此任务表述为多任务语义分割问题。我们使用了 ResUNet-a，这是一种具有完全连接的 UNet 主干的深度卷积神经网络，具有扩张卷积和条件推理的特点，以识别：1）场的范围； 2) 领域边界； 3) 到最近边界的距离。通过要求算法重构三个相关的输出，模型的性能和泛化能力大大提高。然后通过对三个模型输出进行后处理（例如，通过阈值处理或分水岭分割）来实现各个字段的分割。使用来自 Sentinel-2 的单个月度合成图像作为输入，我们的模型在映射字段范围、字段边界以及因此单个字段方面非常准确。用接近合成周期的单日期图像替换每月合成图像会略微降低准确性。然后，我们在一系列实验中表明，无需重新校准，相同的模型在分辨率（10 m 到 30 m）、传感器（Sentinel-2 到 Landsat-8）、空间和时间上都能很好地推广。通过平均从整个季节获得的至少四张图像的模型预测来建立共识对于减少准确性的时间变化至关重要。我们的卷积神经网络能够从图像中学习复杂的分层上下文特征，以准确检测字段边界并丢弃不相关的边界，从而优于传统的边缘滤波器。通过最小化过度拟合和图像预处理要求，并通过用数据驱动的决策替换局部任意决策，我们的方法有望促进大规模提取单个农田。
PCT：点云变换器,不规则域和缺乏排序使得设计用于点云处理的深度神经网络具有挑战性。本文提出了一种用于点云学习的名为 Point Cloud Transformer (PCT) 的新颖框架。 PCT基于Transformer，在自然语言处理方面取得巨大成功，在图像处理方面显示出巨大潜力。对于处理一系列点来说，它本质上是置换不变的，因此非常适合点云学习。为了更好地捕捉点云中的局部上下文，我们在最远点采样和最近邻搜索的支持下增强了输入嵌入。大量实验表明，PCT 在形状分类、部分分割、语义分割和正常估计任务上实现了最先进的性能。
SG-One：一次性语义分割的相似性指导网络,一次性图像语义分割提出了一项具有挑战性的任务，即从看不见的类别中识别对象区域，只有一个带注释的示例作为监督。在本文中，我们提出了一个简单而有效的相似性引导网络来解决一次性（SG-One）分割问题。我们的目标是参考同一类别的一张密集标记的支持图像来预测查询图像的分割掩码。为了获得支持图像的鲁棒代表性特征，我们首先采用掩码平均池化策略来生成引导特征，仅考虑属于支持图像的像素。然后，我们利用余弦相似度来建立引导特征和查询图像中像素特征之间的关系。通过这种方式，可以采用嵌入在生成的相似度图中的可能性来指导分割对象的过程。此外，我们的 SG-One 是一个统一的框架，可以在一个网络中有效地处理支持和查询图像，并以端到端的方式进行学习。我们在 Pascal VOC 2012 上进行了广泛的实验。特别是，我们的 SG-One 达到了 46.3% 的 mIoU 分数，超过了基线方法。
使用文化遗产深度学习框架进行点云语义分割,在数字文化遗产 (DCH) 领域，使用深度学习 (DL) 技术对 3D 点云进行语义分割有助于以足够的细节水平识别历史建筑元素，从而加快历史建筑的建模过程用于从调查数据开发 BIM 模型，称为 HBIM（历史建筑信息模型）。在本文中，我们提出了一种用于点云分割的 DL 框架，该框架通过添加诸如法线和颜色等有意义的特征来采用改进的 DGCNN（动态图卷积神经网络）。该方法已应用于新收集的公开可用的 DCH 数据集：ArCH（建筑文化遗产）数据集。该数据集包含 11 个标记的点云，这些点云来自多个单次扫描的联合或后者与摄影测量调查的集成。所涉及的场景既有室内的，也有室外的，教堂、小教堂、回廊、门廊和凉廊被各种拱顶覆盖，并由许多不同类型的柱子支撑。它们属于不同的历史时期和不同的风格，以使数据集尽可能不统一和同质（在建筑元素的重复中）并且结果尽可能普遍。实验产生了高精度，证明了所提出方法的有效性和适用性。
2015年尼泊尔国家尺度下基于轮廓深度学习框架的滑坡检测,滑坡带来的致命威胁越来越引起人们对滑坡机理分析以及滑坡与气候变化关系的重视。由于发展中国家历史滑坡的记录有限，相关研究大多在发达国家进行。由于可公开获得的全球长时间序列 Landsat 图像，可以通过提出实用的滑坡检测模型来避免这种不平衡，特别是在国家尺度方面。本文利用google earth引擎平台将覆盖尼泊尔全国范围的年度Landsat图像合成为一张图像，构建了一个端到端的基于轮廓的滑坡检测深度学习框架。该框架由两部分组成，一是利用植被指数和DEM退化进行潜在滑坡检测，二是基于从检测到的潜在滑坡中提取的轮廓区域，利用语义分割深度学习模型进行精确滑坡检测。所提出的方法用于检测尼泊尔 2015 年的滑坡，取得了令人满意的性能，召回率为 65%，准确率为 55.35%。该性能比类似发表的作品准确率高 44%，验证了其在国家案例的实际滑坡检测中的广阔应用前景。
遥感图像语义分割的多尺度上下文聚合,遥感图像（RSI）的语义分割在各种应用中都很重要。传统的基于编码器-解码器的卷积神经网络 (CNN) 使用级联池化操作来聚合语义信息，这会导致定位精度的损失和空间细节的保留。为了克服这些限制，我们引入了使用高分辨率网络（HRNet）在没有解码阶段的情况下产生高分辨率特征。此外，我们分别增强了从不同分支中提取的从低到高的特征，以加强与尺度相关的上下文信息的嵌入。低分辨率特征包含更多的语义信息，空间尺寸较小；因此，它们被用来模拟长期空间相关性。通过引入自适应空间池 (ASP) 模块来聚合更多本地上下文，可以增强高分辨率分支。通过在不同层次上结合这些上下文聚合设计，最终的架构能够在全局和局部层次上利用空间上下文。在两个 RSI 数据集上获得的实验结果表明，我们的方法显着提高了常用 CNN 的准确性，并实现了最先进的性能。
基于改进Faster-RCNN模型的目标识别多尺度目标语义分割,图像语义分割在计算机视觉中受到了极大的关注，其目的是对不同的对象进行分割，并为其提供不同的语义类别标签，使计算机能够充分获取场景的语义信息。然而，目前的研究主要集中在彩色图像数据作为训练，用于户外场景和单任务语义分割。本文基于改进的 Faster-RCNN 算法，利用 RGB-D 图像信息，在复杂的室内环境中进行多任务语义分割模型联合目标检测，可同时实现室内场景语义分割、目标分类和检测多视觉任务。其中，针对环境中光照不均的影响，改进了RGB图像与深度图像融合的方法。在增强融合图像特征信息的同时，也提高了模型训练的效率。同时，为了满足对多尺度目标对象进行操作的需要，对非极大值抑制算法进行了改进，以提高模型的性能。为了实现模型多任务信息的输出，损失函数也进行了重新设计和优化。本文构建的室内场景语义分割模型不仅性能好、效率高，而且能够清晰地分割不同尺度物体的轮廓，适应室内光照不均匀的环境。 (C) 2021 年 Elsevier BV 出版
用于显着目标检测的基于 CNN 的编码器-解码器网络：综合回顾和最新进展,基于卷积神经网络 (CNN) 的编码器-解码器模型极大地启发了显着对象检测 (SOD) 领域的最新工作。随着针对大多数像素级密集预测任务的编码器-解码器模型的快速发展，仍然不存在通过在 SOD 任务上应用大量编码器-解码器模型来评估性能的实证研究。在本文中，我们并没有将我们的调查局限于 SOD 方法，而是从基于 CNN 的编码器-解码器模型的关键模块的基本架构和结构的角度进一步提出了更广泛的观点，用于像素级密集预测任务。此外，我们专注于通过利用深度编码器-解码器模型来执行 SOD，并根据不同的编码器主干、损失函数、训练批量大小和注意力结构对基线编码器-解码器模型进行广泛的实证研究。此外，还研究了从语义分割和基于深度 CNN 的 SOD 模型中采用的最先进的编码器-解码器模型。发现了性能优于最先进性能的新基线模型。此外，这些新发现的基线模型在三个基于视频的 SOD 基准数据集上进行了进一步评估。实验结果证明了这些基线模型在基于图像和视频的 SOD 任务上的有效性。本实证研究以综合总结结束，该总结提供了对未来前景的建议。 (c) 2020 Elsevier Inc. 保留所有权利。
遥感影像语义分割的深度学习方法综述,遥感图像的语义分割已在许多应用中得到应用，并且是几十年来的关键研究课题。随着深度学习方法在计算机视觉领域的成功，研究人员努力将其优越的性能转移到遥感图像分析领域。本文首先概述了基本的深度神经网络架构，并回顾了用于遥感图像语义分割的深度学习方法的最新进展，包括非常规数据，如高光谱图像和点云。在我们对文献的回顾中，我们确定了研究人员面临的三大挑战，并总结了应对这些挑战的创新发展。随着人们为提高像素级精度付出了巨大的努力，新兴的深度学习方法在几个公共数据集上表现出显着提高的性能。在处理非常规、非结构化的点云和丰富的光谱图像方面，最先进的方法的性能平均不如卫星图像。从小数据集学习中也存在这样的性能差距。特别是，有限的带有标签的非常规遥感数据集是开发和评估新的深度学习方法的障碍。
多重弱监督约束下的深度语义分割网络用于跨域遥感图像语义分割,由于其广泛的应用，遥感（RS）图像语义分割近年来引起了越来越多的研究兴趣。得益于其层次抽象能力，深度语义分割网络（DSSN）在RS图像语义分割方面取得了巨大成功，并逐渐成为主流技术。但是，DSSN 的优越性能很大程度上取决于两个条件：（I）存在大量的标记训练数据； (II) 测试数据与训练数据严重相似。在实际的遥感应用中，由于遥感传感器的变化以及不同地理位置的明显景观变化，很难完全满足这些条件。为了使 DSSN 适合实际的 RS 场景，本文利用了跨域 RS 图像语义分割任务，这意味着 DSSN 在一个标记数据集（即源域）上进行训练，但在另一个不同的数据集（即目标域）。在这种情况下，由于源域和目标域之间的数据转移，DSSN 的性能不可避免地非常有限。为了减少数据移位的不利影响，本文提出了一种具有多个弱监督约束的新目标函数来学习跨域RS图像语义分割的DSSN。通过仔细研究跨域RS图像语义分割的特点，多个弱监督约束包括弱监督传递不变约束（WTIC）、弱监督伪标签约束（WPLC）和弱监督旋转一致性约束（WRCC） ）。具体来说，建议 DualGAN 在源域和目标域之间进行无监督的风格迁移以进行 WTIC。为了充分利用多重约束的优点，本文提出了一种动态优化策略，在训练过程中动态调整目标函数的约束权重。充分考虑跨域RS图像语义分割任务的特点，本文给出了两种跨域RS图像语义分割设置：（I）地理位置的变化和（II）地理位置和成像模式的变化。大量实验表明，我们提出的方法在这两种设置下都显着优于最先进的方法。收集的数据集和评估基准已在线公开（htt ps://github.com/te-shi/MUCSS）。
使用两阶段多尺度训练架构对大尺寸 VHR 遥感图像进行语义分割,与计算机视觉应用中使用的典型自然图像相比，超高分辨率 (VHR) 遥感图像 (RSI) 具有显着更大的空间尺寸。因此，在这些图像上以全尺寸训练和测试分类器在计算上是负担不起的。用于 RSI 语义分割的常用方法对裁剪的图像块执行训练和预测。因此，它们的局限性在于未能包含足够的上下文信息。为了更好地利用地面对象之间的相关性，我们提出了一种具有两阶段多尺度训练策略的深度架构，该策略适用于大型 VHR RSI 的语义分割。在训练策略的第一阶段，语义嵌入网络旨在从覆盖大面积的缩小图像中学习高级特征。在第二个训练阶段，设计了一个局部特征提取网络来从裁剪的图像块中引入低级信息。由此产生的训练策略能够融合从多个级别学习的互补信息来进行预测。两个数据集的实验结果表明，它在准确性和稳定性方面都优于基于局部补丁的训练模型。
多模态语义分割的自监督模型自适应,"学习可靠地感知和理解场景是机器人在现实世界中运行的不可或缺的推动力。由于物体类型众多，以及因光照和天气条件的变化而引起的外观变化，这个问题本质上是具有挑战性的。利用互补的模态可以学习语义更丰富的表示，这些表示对这种扰动有弹性。尽管近年来取得了巨大进步，但大多数多模态卷积神经网络方法直接将来自单个模态流的特征图连接起来，使得模型无法仅关注相关的互补信息进行融合。为了解决这一限制，我们提出了一种多模态语义分割框架，该框架动态地适应特定模态特征的融合，同时以自我监督的方式对对象类别、空间位置和场景上下文敏感。具体来说，我们提出了一种由两个特定于模态的编码器流组成的架构，它们使用我们提出的自我监督模型自适应融合机制将中间编码器表示融合到一个解码器中，该机制最佳地结合了互补特征。由于中间表示没有跨模态对齐，我们引入了一种注意力方案以获得更好的相关性。此外，我们提出了一种计算效率高的单峰分割架构，称为 AdapNet++，它结合了一个具有多尺度残差单元的新编码器和一个高效的空洞空间金字塔池，其具有超过 10x\documentclass[12pt]{minimal} \usepackage 的更大有效感受野{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$10 \,\times $$\end{document} 更少的参数，辅以具有恢复高分辨率细节的多分辨率监督方案的强大解码器。对 Cityscapes、Synthia、SUN RGB-D、ScanNet 和 Freiburg Forest 基准的综合实证评估表明，我们的单模态和多模态架构都实现了最先进的性能，同时在参数和推理时间方面也很高效，并证明了在不利的感知条件下具有实质性的鲁棒性。"
SLOAM：用于森林清单的语义激光雷达里程计和制图,这封信描述了基于语义分割和激光雷达里程计和映射的树直径估计的端到端管道。由于地面和树木被树叶、荆棘和藤蔓包围，因此对此类环境进行精确映射具有挑战性，而且传感器通常会经历极端运动。我们提出了一种基于语义特征的姿态优化，在估计机器人姿态的同时优化树模型。该管道利用自定义虚拟现实工具来标记用于训练语义分割网络的 3D 扫描。掩蔽点云用于计算网格图，该网格图识别单个实例并提取 SLAM 模块使用的相关特征。我们表明，传统的基于激光雷达和图像的方法在无人驾驶飞行器 (UAV) 和手持系统的森林环境中都失败了，而我们的方法更加稳健、可扩展，并且可以自动生成树木直径估计。
具有上下文编码和多路径解码的语义分割,语义图像分割旨在将场景图像的每个像素分类为多个类别之一。它隐含地涉及对象识别、定位和边界描绘。在本文中，我们提出了一种称为 CGBNet 的分割网络，通过上下文编码和多路径解码来提高分割性能。我们首先提出了一个上下文编码模块，该模块生成上下文对比的局部特征，以利用信息上下文和有区别的局部信息。这个上下文编码模块极大地提高了分割性能，特别是对于不显眼的对象。此外，我们提出了一种尺度选择方案，可以选择性地融合每个空间位置不同尺度特征的分割结果。它自适应地从丰富的特征尺度中选择合适的分数图。为了提高边界处的分割性能结果，我们进一步提出了一个边界描绘模块，该模块鼓励边界附近的特定位置的非常低级特征参与最终预测，并在远离边界的地方抑制它们。所提出的分割网络在六个流行的场景分割数据集、Pascal Context、SUN-RGBD、Sift Flow、COCO Stuff、ADE20K 和 Cityscapes 上，在所有三个不同的评估指标方面都取得了非常有竞争力的性能。
为弱监督语义分割挖掘跨图像语义,"本文仅研究从图像级监督学习语义分割的问题。当前流行的解决方案利用来自分类器的对象定位图作为监督信号，并且努力使定位图捕获更完整的对象内容。与以前主要关注图像内信息的努力不同，我们解决了跨图像语义关系对综合对象模式挖掘的价值。为了实现这一点，两个神经共同注意力被合并到分类器中，以互补地捕捉跨图像语义的相似性和差异。特别是，给定一对训练图像，一个共同注意强制分类器从共同注意对象中识别出共同语义，而另一个称为对比共同注意，驱动分类器从其余对象中识别非共享语义, 不常见的对象。这有助于分类器在图像区域中发现更多的对象模式和更好的地面语义。除了促进对象模式学习之外，共同注意还可以利用来自其他相关图像的上下文来改进定位图推断，从而最终有利于语义分割学习。更重要的是，我们的算法提供了一个统一的框架，可以很好地处理不同的 WSSS 设置，即通过 (1) 仅精确的图像级监督、(2) 额外简单的单标签数据和 (3) 额外嘈杂的网络数据来学习 WSSS。它在所有这些设置上设置了新的最先进技术，很好地展示了它的有效性和普遍性。"
在高分辨率无人机光学图像上应用全卷积架构在城市环境中对单个树种进行语义分割,本研究提出并评估了五个深度全卷积网络 (FCN)，用于对单个树种进行语义分割：SegNet、U-Net、FC-DenseNet 和两个 DeepLabv3+ 变体。 FCN 设计的性能在分类精度和计算负载方面进行了实验评估。我们还验证了完全连接的条件随机场 (CRF) 作为改进分割图的后处理步骤的好处。该分析是对在城市区域上空飞行的无人机上的 RGB 相机拍摄的一组图像进行的。该数据集还包含一个掩码，该掩码指示一种称为 Dipteryx alata Vogel（也称为 cumbaru）的濒危物种的出现，作为要识别的物种。实验分析显示了每个设计的有效性，并报告了平均总体准确度范围为 88.9% 至 96.7%，F1 分数在 87.0% 至 96.1% 之间，IoU 为 77.1% 至 92.5%。我们还意识到 CRF 不断提高性能，但计算成本很高。
BAS(4)Net：用于超高分辨率遥感图像的边界感知半监督语义分割网络,语义分割是遥感图像理解的一项基本任务。最近，深度卷积神经网络 (DCNN) 大大提高了自然场景语义分割的性能。然而，对于非常高分辨率的遥感图像仍然具有挑战性。由于场景大而复杂，以及光照和成像角度的影响，现有方法尤其难以准确获取物体边界像素的类别——即所谓的边界模糊。我们提出了一个称为边界感知半监督语义分割网络 (BAS(4)Net) 的框架，该框架无需额外的注释工作量即可获得更准确的分割结果，尤其是在对象边界处。 Channel-weighted Multi-scale Feature (CMF) 模块平衡语义和空间信息，Boundary Attention Module (BAM) 对具有丰富语义边界信息的特征进行加权以减轻边界模糊。此外，为了减少遥感图像的困难和繁琐的手动标记量，判别器网络从未标记的图像中推断出伪标签以辅助半监督学习，并进一步提高分割网络的性能。为了验证所提出框架的有效性，已经对 ISPRS Vaihingen 数据集和具有更多类别和复杂边界的新型遥感数据集 AIR-SEG 进行了广泛的实验。结果表明，精度显着提高，尤其是在边界和小物体上。
实时语义分割的深度学习：在超声成像中的应用,提出了一种医学图像语义分割的实时架构，称为全卷积密集扩张网络，以提高分割效率，同时确保高精度。考虑到分辨率和对比度低，阴影的干扰，以及结节位置和大小的差异，难以获得准确的超声图像分割。因此，提出了一种新的层，它集成了密集连接、扩张卷积和分解滤波器的优点，试图在保持高效的同时保持显着的准确性。密集连接将低级精细分割与高级粗分割相结合，从超声图像中提取更多特征。扩张卷积可以扩大滤波器的感受野，不同大小的滤波器可以解决结节大小和位置不同的问题。本研究还将分解滤波器引入网络，以进一步优化模型的效率。此外，针对医学图像语义分割中的类不平衡问题，提出了一种损失函数优化方法，进一步提高了网络的准确性。基于甲状腺数据集的一组完整的实验表明，所提出的模型在鲁棒性和效率方面实现了最先进的性能。 (C) 2021 Elsevier BV 保留所有权利。
基于具有注意块和多个损失的 U-Net 的建筑物提取,高分辨率遥感图像的语义分割在建筑物提取的应用中起着重要作用。然而，目前的算法存在一些语义信息提取的局限性，这些都会导致分割结果不佳。为了以高精度提取建筑物，我们提出了一种基于注意力的多损失神经网络。所设计的网络，基于 U-Net，可以通过注意力块提高模型的敏感性，抑制不相关特征区域的背景影响。为了提高模型的能力，在训练网络时提出了一种多损失方法。实验结果表明，所提出的模型比其他最先进的方法有了很大的改进。对于公开的 Inria Aerial Image Labeling 数据集，F1 得分达到 76.96%，在 Aerial Imagery for Roof Segmentation 数据集上表现出良好的性能。
通过具有深度结构化特征嵌入的门控图卷积神经网络构建分割,由于例如建筑物形状的复杂性，从光学图像中自动提取建筑物仍然是一个挑战。语义分割是此任务的有效方法。深度卷积神经网络 (DCNN) 的最新发展使准确的像素级分类任务成为可能。然而，一个核心问题仍然存在：边界的精确划分。由于渐进式下采样，深度架构通常无法产生具有准确边界的细粒度分割。因此，我们引入了一个通用框架来克服这个问题，将图卷积网络 (GCN) 和深度结构化特征嵌入 (DSFE) 集成到端到端的工作流程中。此外，我们没有使用经典的图卷积神经网络，而是提出了一个门控图卷积网络，它能够细化弱和粗略的语义预测，以生成清晰的边界和细粒度的像素级分类。以建筑物足迹的语义分割为例，我们比较了不同的特征嵌入架构和图神经网络。我们提出的具有新 GCN 架构的框架优于最先进的方法。尽管我们在这项工作中的主要任务是构建足迹提取，但所提出的方法通常可以应用于其他二进制或多标签分割任务。
自监督单目深度估计：通过语义引导解决动态对象问题,自监督单目深度估计提供了一种从单个相机图像中获取 3D 场景信息的强大方法，该方法可以在任意图像序列上进行训练，而不需要深度标签，例如来自 LiDAR 传感器。在这项工作中，我们提出了一种新的自监督语义引导深度估计 (SGDepth) 方法来处理移动的动态类 (DC) 对象，例如移动的汽车和行人，这违反了在训练过程中通常做出的静态世界假设。这样的模型。具体来说，我们提出（i）互利的（监督）语义分割和自我监督深度估计的跨域训练，使用特定任务的网络头，（ii）提供指导以防止移动 DC 对象污染光度计的语义掩蔽方案损失，以及（iii）具有非移动DC对象的帧的检测方法，从中可以学习DC对象的深度。我们在几个基准测试中展示了我们的方法的性能，特别是在 Eigen 拆分上，我们在没有测试时间细化的情况下超过了所有基准。
智能交通系统异常事件检测的智能视频分析方法,智能交通系统普遍部署了数千个摄像机。分析来自这些摄像机的实时视频流对公共安全非常重要。随着流媒体视频的增加，让人类操作员坐在数百个屏幕前捕捉可疑活动或实时检测感兴趣的对象变得不可行。实际上，随着安装了数百万个交通监控摄像头，视频检索比以往任何时候都更加重要。为此，本文提出了一种基于超帧分割的长视频事件检索算法。通过检测长视频的运动幅度，可以有效地去除长视频中的大量冗余帧，从而减少后续需要计算的帧数。然后，通过使用基于特征融合的超帧分割算法，将剩余的长视频划分为若干个包含视频事件的感兴趣段（SOI）。最后，使用训练好的语义模型匹配文本问题生成的答案，匹配值最高的结果被认为是问题对应的视频片段。实验结果表明，我们提出的长视频事件检索和描述方法显着提高了语义描述的效率和准确性，显着减少了检索时间。
具有高级和低级一致性的半监督语义分割,从有限的标记数据中理解视觉信息的能力是机器学习的一个重要方面。虽然图像级分类已在半监督环境中得到广泛研究，但数据有限的密集像素级分类最近才引起关注。在这项工作中，我们提出了一种半监督语义分割方法，该方法从有限的像素级注释样本中学习，同时利用额外的无注释图像。所提出的方法依赖于具有特征匹配损失的对抗性训练来从未标记的图像中学习。它使用两个网络分支，将半监督分类与包括自我训练的半监督分割联系起来。双分支方法减少了使用少量标签进行训练时典型的低级和高级工件。与现有方法相比，该方法取得了显着改进，尤其是在使用极少标记样本进行训练时。在几个标准基准——PASCAL VOC 2012、PASCAL-Context 和 Cityscapes——上，该方法实现了半监督学习的最新技术。
CHAOS Challenge-联合（CT-MR）健康腹部器官分割,多年来，腹部器官的分割一直是一个综合性但尚未解决的研究领域。在过去十年中，深度学习 (DL) 的密集发展引入了新的最先进的分割系统。尽管优于现有系统的整体准确性，但 DL 模型属性和参数对性能的影响很难解释。这使得比较分析成为可解释研究和系统的必要工具。此外，DL 在跨模态和多模态语义分割任务等新兴学习方法中的性能很少被讨论。为了扩展有关这些主题的知识，CHAOS-Combined (CT-MR) 健康腹部器官分割挑战与 2019 年在意大利威尼斯举行的 IEEE 国际生物医学成像研讨会 (ISBI) 联合举办。常规采集的腹部器官分割在多种临床应用中发挥着重要作用，例如各种疾病的术前计划或形态学和体积随访。这些应用程序需要在各种指标（例如最大对称表面距离 (MSSD)）上具有一定水平的性能，以确定手术误差范围或重叠误差，以跟踪尺寸和形状差异。以前与腹部相关的挑战主要集中在单一模式的肿瘤/病变检测和/或分类上。相反，CHAOS 提供来自健康受试者的腹部 CT 和 MR 数据，用于单个和多个腹部器官分割。设计了五个不同但互补的任务，以从多个角度分析参与方法的能力。与手动注释和交互式方法相比，对结果进行了彻底调查。分析表明，针对单一模态 (CT/MR) 的 DL 模型的性能可以表现出可靠的体积分析性能（DICE：0.98 +/- 0.00 / 0.95 +/- 0.01），但最佳 MSSD 性能仍然有限（21.89 +/ - 13.94 / 20.85 +/- 10.63 毫米）。对于肝脏的跨模式任务，参与模型的性能显着下降（DICE：0.88 +/- 0.15 MSSD：36.33 +/- 21.97 mm）。尽管在不同的应用程序上有相反的例子，但观察到设计用于分割所有器官的多任务 DL 模型与特定器官的模型相比表现更差（性能下降约 5%）。尽管如此，一些成功的模型在其多器官版本中表现出更好的性能。我们得出结论，在单器官与多器官和跨模态分割中探索这些优点和缺点将对进一步研究开发支持现实世界临床应用的有效算法产生影响。最后，有超过 1500 名参与者并收到超过 550 份提交，本研究的另一个重要贡献是分析挑战组织的缺点，例如多次提交的影响和偷看现象。 (c) 2020 Elsevier BV 保留所有权利。
LANet：局部注意力嵌入改进遥感图像的语义分割,特征表示能力和空间定位精度之间的权衡对于遥感图像（RSI）的密集分类/语义分割至关重要。从神经网络的后期层提取的高级特征具有丰富的语义信息，但具有模糊的空间细节；从网络的早期层中提取的低级特征包含更多像素级信息，但它们是孤立的和嘈杂的。因此，由于它们在物理信息内容和空间分布方面的差异，很难弥合高级和低级特征之间的差距。在本文中，我们通过两种方式增强特征表示来解决这个问题。一方面，提出了一种补丁注意力模块（PAM），以基于局部注意力的补丁计算来增强上下文信息的嵌入。另一方面，提出了一种注意力嵌入模块（AEM），通过嵌入来自高级特征的局部焦点来丰富低级特征的语义信息。两个提出的模块都是轻量级的，可用于处理卷积神经网络（CNN）的提取特征。实验表明，通过将所提出的模块集成到基线全卷积网络（FCN）中，生成的局部注意力网络（LANNet）大大提高了基线的性能，并在两个 RSI 数据集上优于其他基于注意力的方法。
粉末床增材制造过程的逐层异常检测和分类：一种与机器无关的实时逐像素语义分割算法,提高粉末床金属增材制造的行业接受度需要改进对异常的实时检测和分类。其中许多异常情况，例如重涂机刀片冲击、粘合剂沉积问题、飞溅物产生和一些孔隙率，在构建过程的每一层都是表面可见的。在这项工作中，作者提出了一种新颖的卷积神经网络架构，用于逐层粉末床成像数据的像素定位（语义分割）。该算法的主要优势包括它能够以成像传感器的原始分辨率返回分割结果，在不同的增材制造机器之间无缝传输学习知识，并提供实时性能。该算法在六种不同的机器上进行了演示，涵盖了三种技术：激光融合、粘合剂喷射和电子束融合。最后，该算法的性能被证明在定位、准确性、计算时间和泛化性方面优于作者提出的先前算法。
DeepSeg：使用磁共振 FLAIR 图像进行自动脑肿瘤分割的深度神经网络框架,目的 胶质瘤是最常见和侵袭性的脑肿瘤类型，因为它们具有浸润性和快速进展。区分肿瘤边界与健康细胞的过程仍然是临床常规中的一项具有挑战性的任务。流体衰减反转恢复 (FLAIR) MRI 模式可以为医生提供有关肿瘤浸润的信息。因此，本文提出了一种新的通用深度学习架构，即 DeepSeg，用于使用 FLAIR MRI 数据对脑病变进行全自动检测和分割。方法 开发的 DeepSeg 是一个模块化的解耦框架。它由两个基于编码和解码关系连接的核心部分组成。编码器部分是负责空间信息提取的卷积神经网络（CNN）。将生成的语义图插入解码器部分以获得全分辨率概率图。本研究基于改进的 U-Net 架构，使用了残差神经网络 (ResNet)、密集卷积网络 (DenseNet) 和 NASNet 等不同的 CNN 模型。结果 所提出的深度学习架构已经成功地基于脑肿瘤分割 (BraTS 2019) 挑战的 MRI 数据集进行了在线测试和评估，其中包括 s336 个案例作为训练数据和 125 个案例作为验证数据。得到的分割结果的骰子和豪斯多夫距离分数分别约为0.81到0.84和9.8到19.7。结论本研究表明，在新的 DeepSeg 框架中应用不同的深度学习模型以在 FLAIR MR 图像中进行自动脑肿瘤分割的成功可行性和比较性能。提议的 DeepSeg 是开源的，可在 https://github.com/razeineldin/DeepSeg/ 免费获得。 .
解耦的非局部神经网络,非局部块是一种流行的模块，用于增强常规卷积神经网络的上下文建模能力。本文首先深入研究了非局部块，我们发现它的注意力计算可以分为两个项，一个白化的成对项说明两个像素之间的关系，一个一元项表示每个像素的显着性。我们还观察到，单独训练的两个术语倾向于对不同的视觉线索进行建模，例如，白化的成对术语学习区域内关系，而一元术语学习显着边界。然而，这两个术语在非局部块中紧密耦合，这阻碍了每个术语的学习。基于这些发现，我们提出了解耦的非局部块，其中两个术语被解耦以促进两个术语的学习。我们展示了解耦设计在各种任务上的有效性，例如 Cityscapes、ADE20K 和 PASCAL Context 上的语义分割、COCO 上的对象检测以及 Kinetics 上的动作识别。代码可在 https://github.com/yinmh17/DNL-Semantic-Segmentation 和 https://github.com/Howal/DNL-Object-Detection 获得。
PolarNet：在线 LiDAR 点云语义分割的改进网格表示,自动驾驶系统对细粒度感知的要求导致最近增加了对单扫描 LiDAR 在线语义分割的研究。新兴数据集和技术进步使研究人员能够对这个问题进行基准测试并改进适用的语义分割算法。尽管如此，由于三个原因，自动驾驶应用中激光雷达扫描的在线语义分割仍然具有挑战性：(1) 需要在有限硬件的情况下实现近实时延迟，(2) 点在空间中分布不均匀，以及 (3)越来越多的更细粒度的语义类。上述挑战的结合促使我们提出了一种新的 LiDAR 专用、无 KNN 分割算法 - PolarNet。我们的极地鸟瞰图表示不是使用常见的球面或鸟瞰图投影，而是平衡每个网格的点，从而间接地将网络的注意力重新分配到极坐标中径向轴上的长尾点分布上。我们发现我们的编码方案大大增加了三个截然不同的真实城市 LiDAR 单扫描分割数据集中的 mIoU，同时保持了超低延迟和接近实时的吞吐量。
事件感知和记忆,事件构成了我们生活经验的大部分，代表经验事件的知觉机制对行动控制、语言使用和记忆具有普遍影响。感知和记忆中的事件表示具有丰富的内部结构和彼此之间的联系，并且两者都很大程度上受到从以前经验中积累的知识的影响。事件感知和记忆已被确定为具有特定的计算和神经机制，这些机制显示出儿童时期的长期发展，并受到语言使用、专业知识、脑部疾病和损伤的影响。当前的理论方法侧重于将事件从正在进行的经验中分割出来的机制，并强调事件对感知、行动和记忆的共同编码。在眼动追踪、神经影像学和计算机科学的发展的推动下，事件感知和记忆的研究正在从小型实验室类似物转向野外事件的复杂性。
具有关系驱动自集成模型的半监督医学图像分类,训练深度神经网络通常需要大量的标记数据才能获得良好的性能。然而，在医学图像分析中，为数据获取高质量标签既费力又昂贵，因为准确注释医学图像需要临床医生的专业知识。在本文中，我们提出了一种新的关系驱动的医学图像分类半监督框架。它是一种基于一致性的方法，通过鼓励在扰动下给定输入的预测一致性来利用未标记数据，并利用自集成模型为未标记数据生成高质量的一致性目标。考虑到人类诊断通常参考以前的类似案例来做出可靠的决策，我们引入了一种新的样本关系一致性（SRC）范式，通过对不同样本之间的关系信息进行建模来有效地利用未标记的数据。优于现有的基于一致性的方法，这些方法简单地强制单个预测的一致性，我们的框架明确地强制不同样本之间在扰动下语义关系的一致性，鼓励模型从未标记的数据中探索额外的语义信息。我们进行了广泛的实验来评估我们在两个公共基准医学图像分类数据集上的方法，即使用 ISIC 2018 挑战的皮肤病变诊断和使用 ChestX-ray14 的胸部疾病分类。我们的方法在单标签和多标签图像分类场景中都优于许多最先进的半监督学习方法。
UAVId：无人机图像的语义分割数据集,语义分割最近一直是计算机视觉领域的主要研究兴趣之一。它是许多领域的感知基础，例如机器人技术和自动驾驶。语义分割的快速发展很大程度上归功于大规模数据集，尤其是与深度学习相关的方法。已经存在多个语义分割数据集，用于比较复杂城市场景中的语义分割方法，例如 Cityscapes 和 CamVid 数据集，其中对象的侧视图是通过安装在驾驶汽车上的摄像头捕获的。还存在用于机载图像和卫星图像的语义标记数据集，其中捕获了对象的最低点视图。然而，只有少数数据集从倾斜的无人机（UAV）视角捕捉城市场景，其中可以观察到物体的俯视图和侧视图，为物体识别提供了更多信息。在本文中，我们介绍了我们的 UAVId 数据集，这是一种新的高分辨率无人机语义分割数据集作为补充，它带来了新的挑战，包括大规模变化、移动对象识别和时间一致性保持。我们的无人机数据集由 30 个视频序列组成，这些视频序列在斜视图中捕获高分辨率图像。总共有 300 张图像被密集标记为 8 个类别，用于语义标记任务。我们提供了几种带有预训练的深度学习基线方法，其中提出的 Multi-Scale-Dilation 网络通过多尺度特征提取表现最好，平均交叉联合 (IoU) 得分达到 50% 左右。我们还利用特征空间优化 (FSO) 和 3D 条件随机场 (CRF) 探索了时空正则化对序列数据的影响。我们的 UAVId 网站和标签工具已在线发布 (https://uavid.nl/)。
一种基于对象卷积神经网络的多级上下文引导分类方法，用于使用超高分辨率遥感图像进行土地覆盖分类,由于难以从丰富的图像细节中挖掘复杂的空间和光谱模式，超高分辨率图像 (VHRI) 的分类具有挑战性。已经提出了各种用于 VHRI 分类的基于对象的卷积神经网络 (OCNN)，以克服冗余像素级 CNN 的缺点，因为它们的计算成本低且轮廓保持良好。然而，OCNN 的分类性能仍然受到几何失真、特征表示不足和缺乏上下文指导的限制。在本文中，提出了一种创新的基于 OCNN 的多级上下文引导分类方法（MLCG-OCNN）。通过同时从独立的光谱模式、几何特征和对象级上下文信息中学习高级特征，开发了一种特征融合 OCNN，包括对象轮廓保留掩码策略和对象变形系数的补充，以实现准确的对象识别。然后使用像素级上下文引导来进一步改进每个对象的分类结果。 MLCG-OCNN 方法有意在两个经过验证的具有有限训练样本的小型图像数据集上进行测试，以评估土地覆盖分类应用中的性能，其中需要在样本训练的时间消耗和整体准确性之间进行权衡，如这在实践中很常见。与传统的基准方法相比，包括基于补丁的每像素 CNN（PBPP）、基于补丁的每对象 CNN（PBPO）、具有对象分割细化的像素级 CNN（PO）、语义分割 U-Net（U -NET）和 DeepLabV3+（DLV3+），MLCG-OCNN 方法实现了显着的分类性能（> 80 %）。与最先进的架构 DeepLabV3+ 相比，MLCG-OCNN 方法展示了 VHRI 分类的高计算效率（快 4-5 倍）。
显微镜图像上基于深度学习的细胞分割的测试时间增强,深度学习的最新进展彻底改变了细胞显微镜图像的处理方式。深度学习网络架构具有大量参数，因此，为了达到高精度，它们需要大量的注释数据。提高准确性的一种常见方法是通过使用不同的增强技术来人为地增加训练集。一种不太常见的方法依赖于测试时间增强 (TTA)，它产生用于预测的图像的转换版本，并将结果合并。在本文中，我们描述了我们如何将测试时间论证预测方法纳入显微镜图像单细胞分析中使用的两种主要分割方法中。这些方法是基于 U-Net 的语义分割和基于 Mask R-CNN 模型的实例分割。我们的研究结果表明，即使仅应用简单的测试时间增强（例如旋转或翻转和适当的合并方法），TTA 也可以显着提高预测准确性。我们利用了来自 Data Science Bowl (DSB) 2018 细胞核分割竞赛和其他来源的组织和细胞培养图像。此外，通过 TTA 提升 DSB 的最高得分方法，我们可以进一步提高预测准确性，我们的方法在 DSB 中达到了有史以来的最佳分数。
PhaseNet 2.0：基于深度学习方法的噪声数据的相位展开,相位展开是一个不适定的经典问题，在许多具有重要意义的实际应用中，例如通过条纹投影进行 3D 轮廓分析、合成孔径雷达和磁共振成像。传统的相位展开技术通过通过受限路径积分（称为路径跟踪方法）或通过最小化包裹相位与近似真实相位之间的能量函数（称为最小范数方法）来估计相位。然而，这些传统方法具有一些关键挑战，如误差累积和高计算时间，并且在低 SNR 条件下经常失败。为了解决这些问题，本文提出了一种新颖的深度学习框架来展开相位，称为 PhaseNet 2.0。相位展开问题被表述为密集分类问题，并训练基于全卷积 DenseNet 的神经网络从包裹相位图中预测每个像素的包裹计数。为了训练这个网络，我们模拟了任意形状并提出了新的损失函数，它通过最小化梯度的差异来整合残差，并使用损失来克服类不平衡问题。与我们之前的方法 PhaseNet 不同，所提出的方法不需要后处理，对噪声具有高度鲁棒性，即使在 -5 dB 的严重噪声水平下也能准确地展开相位，即使在相对较高的动态范围内也可以展开相位图。针对不同 SNR 值和不连续性，将所提出框架的仿真结果与不同类别的现有相位展开方法进行比较，这些评估证明了所提出框架的优势。我们还展示了所提出的方法在具有不同结构和更精细几何变化的合成 CAD 模型的 3D 重建上的普遍性。最后，将所提出的方法应用于使用条纹投影技术和数字全息干涉测量法对物体进行 3D 轮廓分析的真实数据。所提出的框架在现有方法的基础上实现了显着改进，同时在现代 GPU 上以交互式帧速率实现了高效。
基于条带池法的改进编解码网络应用于农田空地分割,在遥感图像分割领域的绿色植被覆盖度研究中，往往通过对高空拍摄的图像进行语义分割得到作物种植面积。这种方法可以得到一个地区（如一个国家）的耕地率，但不能反映特定农田的真实情况。因此，本文以农田的低空图像构建数据集。在比较了几种主流的语义分割算法后，提出了一种更适合农田空置分割的新方法。此外，设计了以条带池为核心的条带池模块（SPM）和混合池模块（MPM），并融合到语义分割网络结构中，以更好地提取空缺特征。考虑到人工数据标注的高成本，本文使用改进的 ResNet 网络作为信号传输的主干，同时使用数据增强来提高模型的性能和鲁棒性。结果，该方法在测试集中的准确率为 95.6%，mIoU 为 77.6%，错误率为 7%。与现有模型相比，mIoU值提高了近4%，达到了实际应用的水平。
高度不平衡分割的边界损失,CNN 分割中广泛使用的损失函数，例如 Dice 或交叉熵，是基于分割区域上的积分。不幸的是，对于高度不平衡的分割，此类区域总和的值在不同类别之间相差几个数量级，这会影响训练性能和稳定性。我们提出了一种边界损失，它采用轮廓空间上的距离度量的形式，而不是区域。这可以减轻高度不平衡问题的困难，因为它使用区域之间界面上的积分而不是区域上的不平衡积分。此外，边界损失补充了区域信息。受用于计算活动轮廓流的基于图的优化技术的启发，我们将轮廓空间上的非对称 L-2 距离表示为区域积分，这避免了涉及轮廓点的完全局部微分计算。这产生了用网络的区域 softmax 概率输出表示的边界损失，它可以很容易地与标准区域损失相结合，并与任何现有的用于 ND 分割的深度网络架构一起实现。我们报告了对不同不平衡问题的综合评估和比较，表明我们的边界损失可以在提高训练稳定性的同时显着提高性能。我们的代码是公开的 (1)。 (C) 2020 Elsevier BV 保留所有权利。
用于土地覆盖分类的密集扩张卷积合并网络,由于注释数据量有限、类别高度不平衡、像素级注释错误频繁以及语义分割任务固有的复杂性，遥感图像的土地覆盖分类是一项具有挑战性的任务。在本文中，我们提出了一种称为密集扩张卷积合并网络 (DDCM-Net) 的新颖架构来解决此任务。所提出的 DDCM-Net 由密集的扩张图像卷积和不同的扩张率组成。与遥感领域中最先进的方法相比，这有效地利用了扩张卷积的丰富组合，以更少的参数和特征扩大了网络的感受野。重要的是，DDCM-Net 获得了融合的局部和全局上下文信息，实际上结合了对高分辨率航空图像中具有相似颜色和纹理的多尺度和复杂形状对象的周围判别能力。我们在公开可用的 ISPRS Potsdam 和 Vaihingen 数据集以及 DeepGlobe 土地覆盖数据集上展示了提议的 DDCM-Net 的有效性、稳健性和灵活性。我们的单一模型在三波段 Potsdam 和 Vaihingen 数据集上进行训练，与其他已发布的使用超过三波段数据训练的模型相比，在平均交并比 (mIoU) 和 F1 分数方面实现了更好的准确性。我们在 DeepGlobe 数据集上进一步验证了我们的模型，与最近的相关工作相比，以更少的参数和更低的计算成本实现了最先进的结果 56.2% mIoU。
使用深度学习对建筑物内部点云进行语义分割：使用基于 BIM 的合成点云增强训练数据集,本文研究了使用从建筑信息模型 (BIM) 生成的合成点云来训练深度神经网络以对建筑内部点云进行语义分割的可行性。为了实现这些目标，本文首先介绍了一种使用三个商用软件系统将数字 3D BIM 转换为合成点云的程序。然后使用生成的合成点云来训练深度神经网络。比较了几个经过训练的模型的语义分割性能：真实点云、合成点云以及真实点云和合成点云的组合。一个关键发现是，与仅在真实数据上训练分类器相比，当一个小的真实点云数据集通过合成点云进行训练增强时，性能提高了 7.1%。实验结果证实了使用从构建信息模型生成的合成点云与真实点云的小型数据集相结合的可行性。这开启了开发建筑内部分割模型的可能性，该模型可应用于包含看不见的室内结构的建筑物的竣工建模。
使用 3D U-Net 集合进行脑肿瘤分割和使用放射特征进行总体生存预测,多模态MRI扫描准确分割胶质瘤不同亚区，如瘤周水肿、坏死核心、增强和非增强肿瘤核心，对脑肿瘤的诊断、预后和治疗具有重要的临床意义。然而，由于这些肿瘤的外观和形状高度异质，子区域的分割具有挑战性。使用深度学习模型的最新发展已证明其在各种语义和医学图像分割任务中的有效性，其中许多基于具有对称编码和解码路径的 U-Net 网络结构，用于端到端分割，由于其高效和很棒的表演。在脑肿瘤分割中，多模态 MRI 的 3D 特性在直接采用 U-Net 结构时会带来内存和计算限制以及类别不平衡等挑战。在这项研究中，我们的目标是使用 3D U-Net 开发一个深度学习模型，并在训练和测试策略、网络结构和脑肿瘤分割模型参数方面进行调整。此外，不是选择一个最佳模型，而是使用使用不同超参数训练的多个模型的集合来减少每个模型的随机误差并提高性能。初步结果证明了该方法的有效性，并在竞争激烈的 2018 年多模态脑肿瘤分割 (BraTS) 挑战赛中获得第 9 名。此外，为了强调所开发的分割方法的临床价值，开发了一个基于从分割中提取的放射组学特征和其他临床特征的线性模型来预测患者的总体生存率。对这些创新的评估表明，低级别胶质瘤和胶质母细胞瘤患者的预测准确性很高，在 2018 年 BraTS 挑战赛中获得第一名。
预测肿瘤对直肠癌放化疗的反应：使用 MRI 放射组学的模型开发和外部验证,背景：对于局部晚期直肠癌 (LARC) 放化疗反应良好的患者，可以考虑采取观察等待策略。为了实施保留器官的策略，需要准确的患者选择。我们研究了使用基于 MRI 的放射组学模型来预测肿瘤反应以改善患者选择。材料和方法：模型是在 70 名患者的队列中开发的，并在 55 名患者的外部队列中进行验证。患者接受了化放疗，随后接受了手术，并在化放疗前后接受了 T2 加权和弥散加权 MRI（DW-MRI）。结果测量是（接近）完全病理肿瘤反应（ypT0-1N0）。肿瘤分割在 T2 图像上进行，并转移到 b800 图像和 ADC 图，然后提取定量和四个语义特征。我们使用主成分分析组合特征并使用 LASSO 回归分析建立模型。选择基于精度和性能的最佳模型进行验证。结果：21/70 名患者 (30%) 在开发队列中达到 ypT0-1N0，而在验证队列中为 13/55 名患者 (24%)。三个模型（t2_dwi_pre_post、semantic_dwi_adc_pre、semantic_dwi_post）的曲线下面积（AUC）分别为 0.83（95% CI 0.70-0.95）、0.86（95% CI 0.75-0.98）和 0.84（95% CI 0.75） -0.94) 分别。两个模型（t2_dwi_pre_post、semantic_dwi_post）在外部队列中验证良好，AUC 分别为 0.83（95% CI 0.70-0.95）和 0.86（95% CI 0.76-0.97）。然而，这些模型并没有优于先前建立的四特征语义模型。结论：基于 MRI 放射组学的预测模型非侵入性地预测直肠癌放化疗后的肿瘤反应，并可用作识别符合器官条件的患者的附加工具。保留治疗。 (C) 2019 Elsevier BV 保留所有权利。
MAP-Net：用于从遥感图像中构建足迹提取的多参与路径神经网络,建筑足迹提取是地图绘制、图像理解、计算机视觉等领域的一项基本任务。由于建筑物的复杂结构、多种尺度和多样的外观，从广泛的遥感图像中准确有效地提取建筑物足迹仍然是一项挑战。现有的基于卷积神经网络 (CNN) 的建筑物提取方法因无法检测微小建筑物而受到批评，因为 CNN 特征图的空间信息在 CNN 的重复池化操作中丢失。此外，大型建筑物仍然存在不准确的分割边缘。此外，CNN提取的特征总是部分受限于感受野的大小，低纹理的大型建筑物在提取时总是不连续和有孔的。为了缓解这些问题，在最新的研究工作中引入了多尺度策略来提取不同尺度的建筑物。分辨率较高的特征通常是从浅层中提取的，这对于微小的建筑物而言提取的语义信息不足。本文提出了一种新颖的多参与路径神经网络（MAP-Net），用于准确提取多尺度建筑物足迹和精确边界。与现有的多尺度特征提取策略不同，MAP-Net 通过逐步生成每个阶段的多并行路径来学习保留空间定位的多尺度特征，以提取具有固定分辨率的高级语义特征。然后，注意力模块自适应地压缩从每条路径中提取的通道特征，以优化多尺度融合，金字塔空间池化模块捕获全局依赖性，以优化不连续的建筑足迹。实验结果表明，与 Urban 3 上最新的 HRNetv2 相比，我们的方法在不增加计算复杂度的情况下，实现了 0.88%、0.93% 和 0.45% 的 F1 分数以及 1.53%、1.50% 和 0.82% 的交叉并集 (IoU) 分数改进-D、Deep Globe 和 WHU 数据集。具体来说，MAP-Net 在没有预训练和后处理的 WHU 数据集上优于多尺度聚合全卷积网络 (MA-FCN)，后者是具有后处理和模型投票策略的最先进 (SOTA) 算法。 TensorFlow 实现可在 https://github.com/lehaifeng/MAPNet 获得。
基于深度学习的分割，用于在格子线上自动训练苹果树,由于果实产量和质量高，以及在修剪和收获过程中适用于机器人操作，棚架式结果墙训练系统正在成为现代苹果园的标准。在美国 PNW 地区，将年轻的苹果树训练到经过格子训练的树冠系统的常见做法是手动选择树枝，然后将其绑在 6 或 7 层的水平格子线上。由于熟练的人力资源减少和劳动力成本迅速增加，苹果树对这些现代果园架构的人工培训变得越来越具有挑战性，使用传感和机器人技术的自动化培训可能是一种替代解决方案。分割树干、树枝和网格线是自动化树木训练操作的关键步骤。在这项研究中，开发了一种基于深度学习的语义分割方法来自动执行此分割任务。使用 Kinect V2 传感器获取目标树的 RGB 和点云数据。然后使用简单和前景 RGB 图像来训练基于卷积神经网络 (CNN) 的分割网络 (SegNet) 来分割主干、分支和网格线。具有一些共同特征的树干和分支被相互分割，简单 RGB 图像的精度分别为 0.82 和 0.89，前景 RGB 图像的精度分别为 0.91 和 0.92。类似地，对于简单和前景 RGB 图像，分别以 0.92 和 0.97 的精度分割从树干和树枝具有不同特征的格状线。获得的结果表明，所开发的语义分割技术在 Foreground-RGB 图像上的性能优于 Simple-RGB 图像。识别前景-RGB 图像中分割区域边界的准确度（由边界-F1 分数表示）对于主干线、分支线和格状线分别为 0.93、0.89 和 0.91。这些结果显示了采用基于深度学习的语义分割在果园环境中自动化苹果树训练的巨大潜力。
“挤压和激发”引导立体图像的少镜头分割,深度神经网络可以实现高度准确的图像分割，但需要大量手动注释数据来进行监督训练。 Few-shot learning 旨在通过从几个带注释的支持示例中学习一个新类来解决这个缺点。我们介绍了一种新颖的少镜头框架，用于分割只有少数注释切片的体积医学图像。与计算机视觉中的其他相关工作相比，主要挑战是缺乏预训练网络和医学扫描的体积性质。我们通过提出一种包含“挤压和激发”块的小样本分割新架构来应对这些挑战。我们的双臂架构由一个调节器臂组成，它处理带注释的支持输入并生成特定于任务的表示。该表示被传递到使用该信息来分割新查询图像的分割器臂。为了促进调节器和分段器臂之间的有效交互，我们建议使用“通道压缩和空间激励”块 - 一个轻量级计算模块 - 可以实现两个臂之间的大量交互，而模型复杂性的增加可以忽略不计。这种贡献使我们能够在不依赖预训练模型的情况下执行图像分割，而预训练模型通常不适用于医学扫描。此外，我们提出了一种有效的体积分割策略，通过将支持体积的几个切片与查询体积的所有切片进行最佳配对。我们对来自内脏数据集的全身对比增强 CT 扫描进行器官分割实验。我们提出的模型在分割精度方面明显优于多个基线和现有方法。源代码可在 https://github.comiabhi4ssj/few-shot-segmentation 获得。 (C) 2019 Elsevier BV 保留所有权利。
BSUV-Net：一种用于对看不见的视频进行背景减法的全卷积神经网络,背景减法是计算机视觉和视频处理中的一项基本任务，通常用作对象跟踪、人识别等的预处理步骤。最近，已经提出了许多成功的背景减法算法，但几乎所有顶级算法表演者受到监督。至关重要的是，他们的成功依赖于训练期间测试视频的一些注释帧的可用性。因此，他们在完全看不见的视频上的表现在文献中没有记载。在这项工作中，我们提出了一种新的、有监督的、基于全卷积神经网络的看不见的视频背景减法算法（BSUV-Net）。我们网络的输入包括当前帧和在不同时间尺度上捕获的两个背景帧以及它们的语义分割图。为了减少过度拟合的机会，我们还引入了一种新的数据增强技术，可以减轻背景帧和当前帧之间的光照差异的影响。在 CDNet-2014 数据集上，BSUV-Net 在包括 F 度量、召回率和精度在内的几个指标方面优于对看不见的视频进行评估的最先进算法。
使用无人机图像和深度学习对亚马逊棕榈树进行个体树检测和物种分类,有关热带森林中棕榈树空间分布的信息对于商业开发和管理至关重要。然而，手掌发生的空间连续知识是稀缺的，并且难以通过传统方法（例如现场清查）获得。在这里，我们开发了一种使用低成本无人机 (UAV) 获取的 RGB 图像在单个树冠 (ITC) 级别绘制亚马逊棕榈树物种的新方法。我们的方法基于从完全卷积神经网络模型派生的棕榈物种评分图中执行的形态学操作。我们首先通过将研究区域（亚马逊古老森林中的 135 公顷）划分为 28 个 250 mx 150 m 的地块来构建一个标记数据集。然后，我们用 4 cm 像素手动勾勒出所有在 RGB 图像中看到的棕榈树。我们确定了三种棕榈树种：Attalea butyracea、Euterpe precatoria 和 Iriartea deltoidea。我们随机选择了 22 个地块 (80%) 用于训练和 6 个地块 (20%) 用于测试。我们更改了用于训练和测试的图，以评估分类准确性的可变性并评估模型的泛化性。我们的方法比传统的补丁语义分割（CSS）的平均生产者准确率高出 4.7%。此外，平均而言，我们的方法正确识别的 ITC 比 CSS 多 34.7 个百分点，CSS 倾向于合并彼此接近的树。生产者对 A. butyracea、E. precatoria 和 I. deltoidea 的准确度分别为 78.6 +/- 5.5%、98.6 +/- 1.4% 和 96.6 +/- 3.4%。幸运的是，亚马逊地区开发和商业化程度最高的棕榈树种之一（E. precatoria，aka，Acai）以最高的分类准确度被绘制出来。源自低成本无人机系统的 E. precatoria 地图可以支持亚马逊地区的管理项目和基于社区的森林监测计划。
使用跨步空间金字塔池和双注意力解码器的语义分割,语义分割是一项端到端的任务，需要语义和空间准确性。有效利用语义信息丰富的高层特征图和空间信息准确的低层特征图对于基于深度学习的分割方法非常重要。然而，现有的分割网络通常不能充分利用这两种特征图，导致性能较差。本文试图通过引入两种新颖的结构来克服这一挑战。一方面，我们提出了一种称为跨步空间金字塔池（SSPP）的结构，以从高级特征图中捕获多尺度语义信息。与现有的基于atrous卷积的金字塔池化方法相比，SSPP结构能够以更快的推理速度从高层特征图中收集更多信息，显着提高了高层特征图的利用效率。另一方面，我们提出了一种由通道注意分支和空间注意分支组成的双注意解码器，以同时充分利用高级和低级特征图。双重注意力解码器可以产生更语义的低级特征图和具有更准确空间信息的高级特征图，这弥合了这两种特征图之间的差距，有利于它们的融合。我们在几个公开可用的语义图像分割基准上评估所提出的模型，包括 PASCAL VOC 2012、Cityscapes 和 COCO-Stuff。定性和定量结果表明，我们的方法可以达到最先进的性能。 (C) 2020 Elsevier Ltd. 保留所有权利。
半监督图像分割的深度协同训练,在本文中，我们的目标是提高半监督设置中语义图像分割的性能，其中使用减少的注释图像集和附加的非注释图像进行训练。我们提出了一种基于深度分割模型集合的方法。模型在注释数据的子集上进行训练，并使用非注释图像相互交换信息，类似于协同训练。模型的多样性是通过使用对抗样本来实现的。我们展示了我们的方法在三个具有挑战性的图像分割问题上的潜力，并说明了它在同时训练的模型之间共享信息的能力，同时保持它们的多样性。结果表明，与最近提出的半监督分割方法相比，在性能方面具有明显优势。 (C) 2020 Elsevier Ltd. 保留所有权利。
一种用于自动海上溢油检测的新型深度学习实例分割模型,浮油和其他元素的视觉相似性（称为相似）会影响合成孔径雷达 (SAR) 图像用于海上溢油检测的可靠性。到目前为止，漏油和相似物的检测和判别仍然局限于使用传统的机器学习算法和语义分割深度学习模型，准确性有限。因此，本研究使用计算机视觉实例分割基于 Mask-Region 的卷积神经网络 (Mask R-CNN) 模型开发了一种新颖的深度学习溢油检测模型。模型训练是使用 COCO 上的 ResNet 101 上的迁移学习作为主干，结合特征金字塔网络 (FPN) 架构，以 30 个 epoch 和 0.001 的学习率进行特征提取。使用保留的测试图像上的最小训练和验证损失值对模型进行测试。使用精度、召回率、特异性、IoU、F1-measure 和整体准确度值评估模型的性能。船舶检测和分割的性能最高，总体准确率为 98.3%。该模型同样显示出更高的溢油和相似检测和分割准确度，尽管溢油检测的总体准确度值分别为 96.6% 和 91.0%，优于相似检测。研究得出结论，深度学习实例分割模型在检测和分割方面的表现优于传统机器学习模型和深度学习语义分割模型。
实例分割调查：最新技术,对象检测或定位是从粗略到精细的数字图像推理过程中的一个增量步骤。它不仅提供图像对象的类别，还提供已分类的图像对象的位置。位置以边界框或质心的形式给出。语义分割通过预测输入图像中每个像素的标签来提供精细的推理。每个像素都根据其所在的对象类别进行标记。为了进一步发展，实例分割为属于同一类的对象的不同实例提供不同的标签。因此，实例分割可以定义为同时解决对象检测和语义分割问题的技术。在这篇关于实例分割的调查论文中，讨论了它的背景、问题、技术、演变、流行数据集、相关工作以及最新技术和未来范围。该论文为那些想在实例分割领域进行研究的人提供了有价值的信息。
基于U-Net的医学图像分割：综述,医学图像分析是通过分析医学成像系统获得的图像来解决临床问题。目的是提取有效信息，提高临床诊断水平。近年来，基于深度学习（DL）方法的自动分割得到了广泛应用，其中神经网络可以自动学习图像特征，这与传统的手动学习方法形成鲜明对比。 U-net 是卷积神经网络 (CNN) 最重要的语义分割框架之一。它广泛用于医学图像分析领域的病灶分割、解剖分割和分类。该网络框架的优势在于，不仅可以准确分割期望的特征目标，有效地处理和客观评价医学图像，而且有助于提高医学图像诊断的准确性。因此，本文对基于 U-net 的医学图像分割进行文献综述，重点介绍 U-net 在六种医学成像系统中对不同病变区域的成功分割经验。结合深度学习的最新进展，本文介绍了将原始 U-net 架构与深度学习相结合的方法以及改进 U-net 网络的方法。 (C) 2020 年影像科学与技术学会。
使用语义分割在整个幻灯片图像中识别肾小球硬化,背景与目的：肾小球鉴定，即检测和表征，是许多肾病理学研究中的关键程序。在本文中，提出了基于卷积神经网络 (CNN) 的语义分割来检测肾小球，使用全幻灯片成像 (WSI) 和分类 CNN 将肾小球分为正常和硬化。方法：U-Net 和 SegNet CNN 之间的比较考虑到二类和三类问题，即a）非肾小球和肾小球结构和b）非肾小球正常肾小球和硬化结构，执行像素级分割。然后将两类语义分割结果用于 CNN 分类，其中肾小球区域分为正常和全局硬化肾小球。结果：这些方法在由 47 个 WSI 组成的数据集上进行了测试，这些 WSI 属于用高碘酸席夫 (PAS) 染色的人肾切片）。最好的方法是用于两类分割的 SegNet，然后是微调的 AlexNet 网络来表征肾小球。使用连续 CNN (SegNet-AlexNet) 进行分割和分类的这一过程获得了 98.16% 的准确率。结论：获得的结果表明，顺序 CNN 分割分类策略实现了更高的准确度，减少了错误分类的病例，因此是针对肾小球硬化提出的方法检测。 (C) 2019 Elsevier BV 保留所有权利。
使用深度神经网络进行乳腺癌语义分割的图像数据实践,医疗保健中的图像数据发挥着至关重要的作用。医疗数据记录正在迅速增加，这既有利也不利。大型图像数据集难以处理、提取信息和机器学习。本研究中使用的乳房 X 线照片数据是乳房区域的低范围 X 射线图像，其中包含异常。乳腺癌是最常被诊断出的癌症，在全球乳腺癌相关死亡人数中排名第 9。在巴基斯坦，每 9 名女性中就有 1 名预计在生命的某个阶段会患上乳腺癌。筛查乳腺X线摄影是早期发现其最有效的手段。如此高的过采样率导致数十亿美元的超额医疗保健成本和不必要的患者焦虑。这项研究主要集中在开发基于深度学习的计算机辅助系统，以检测、分类和分割乳房 X 线照片中的癌变区域。此外，还提出了去除可能导致高误报率的噪声、伪影和肌肉区域的预处理机制。为了提高系统效率并应对大量资源需求，将预处理后的图像转换为 512 x 512 块。采用了两个公开可用的乳腺癌数据集，即乳房 X 线摄影图像分析协会 (MIAS) 数字乳房 X 线摄影数据集和（用于筛查乳房 X 线摄影的数字数据库） (CBIS-DDSM) 的策划乳房成像子集。使用了两种最先进的基于深度学习的实例分割框架，即 DeepLab 和 Mask RCNN。预处理算法有助于增加每种迁移学习方法的接收器操作曲线下的面积。进行微调以获得更好的性能，在 150 个案例的测试集上，mask RCNN 和 deep lab 的曲线下面积分别等于 0.98 和 0.95。然而，分割任务的平均精度为 0.80 和 0.75。放射科医师的准确度范围为 0.80 到 0.88。拟议的研究有可能帮助放射科医生进行乳房肿块分类以及癌变区域的分割。
用于织物缺陷检测的多级 GAN,织物缺陷检测是一个有趣但具有挑战性的话题。已经提出了许多用于织物缺陷检测的方法，但由于织物纹理和缺陷的复杂多样性，这些方法仍然不是最优的。在本文中，我们提出了一种基于生成对抗网络 (GAN) 的织物缺陷检测框架。考虑到实际应用中存在的挑战，所提出的织物缺陷检测系统能够学习现有的织物缺陷样本，并在不同的应用期间自动适应不同的织物纹理。具体来说，我们为织物缺陷检测定制了一个深度语义分割网络，可以检测不同的缺陷类型。此外，我们尝试训练多阶段 GAN 以在新的无缺陷样本中合成合理的缺陷。首先，训练一个以纹理为条件的 GAN，以探索给定不同纹理背景的缺陷的条件分布。给定一种新颖的面料，我们的目标是生成合理的缺陷补丁。然后，基于 GAN 的融合网络将生成的缺陷融合到特定位置。最后，训练有素的多级 GAN 不断更新现有的织物缺陷数据集，并有助于微调语义分割网络，以更好地检测不同条件下的缺陷。对各种代表性织物样品进行了综合实验，以验证我们提出的方法的检测性能。
RandLA-Net：大规模点云的高效语义分割,我们研究了大规模 3D 点云的有效语义分割问题。通过依赖昂贵的采样技术或计算量大的预处理/后处理步骤，大多数现有方法只能在小规模点云上进行训练和操作。在本文中，我们介绍了 RandLA-Net，这是一种高效且轻量级的神经架构，可直接推断大规模点云的每点语义。我们方法的关键是使用随机点采样而不是更复杂的点选择方法。尽管计算和内存效率非常高，但随机抽样可能会偶然丢弃关键特征。为了克服这个问题，我们引入了一种新的局部特征聚合模块来逐步增加每个 3D 点的感受野，从而有效地保留几何细节。大量实验表明，我们的 RandLA-Net 可以一次处理 100 万个点，速度比现有方法快 200 倍。此外，我们的 RandLA-Net 在两个大型基准 Semantic3D 和 SemanticKITTI 上明显超越了最先进的语义分割方法。
SNE-RoadSeg：将表面法线信息纳入语义分割以实现准确的自由空间检测,自由空间检测是自动驾驶汽车视觉感知的重要组成部分。最近在数据融合卷积神经网络 (CNN) 方面所做的努力显着改善了语义驾驶场景分割。自由空间可以假设为地平面，其上的点具有相似的表面法线。因此，在本文中，我们首先介绍了一种名为表面法线估计器（SNE）的新模块，它可以从密集的深度/视差图像中以高精度和高效的方式推断表面法线信息。此外，我们提出了一种数据融合 CNN 架构，称为 RoadSeg，它可以从 RGB 图像和推断的表面法线信息中提取和融合特征，以实现准确的自由空间检测。出于研究目的，我们发布了一个大型合成自由空间检测数据集，名为 Ready-to-Drive (R2D) 道路数据集，在不同的光照和天气条件下收集。实验结果表明，我们提出的 SNE 模块可以使所有最先进的 CNN 用于自由空间检测，并且我们的 SNE-RoadSeg 在不同数据集之间实现了最佳的整体性能。
用于语义分割的双超分辨率学习,当前最先进的语义分割方法通常应用高分辨率输入来获得高性能，这带来了大量的计算预算并限制了它们在资源受限设备上的应用。在本文中，我们提出了一种简单灵活的双流框架，称为双超分辨率学习（DSRL），以有效提高分割精度，而不会引入额外的计算成本。具体来说，所提出的方法由三部分组成：语义分割超分辨率（SSSR）、单图像超分辨率（SISR）和特征亲和（FA）模块，可以在保持低分辨率输入的高分辨率表示的同时减少模型计算复杂度。而且;它可以很容易地推广到其他任务，例如人体姿态估计。这种简单而有效的方法导致了强大的表示，并且在语义分割和人体姿势估计方面都有很好的表现证明了这一点。具体来说，对于 CityScapes 上的语义分割，我们可以在相似的 FLOP 上实现 >= 2% 的 mIoU，并在 70% 的 FLOP 下保持性能。对于人体姿态估计，我们可以在相同的 FLOPs 下获得 >= 2% 的 mAP，并在减少 30% 的 FLOPs 的情况下保持 mAP。代码和模型可在 https://github.com/wanglixilinx/DSRL 获得。
SEED：用于场景文本识别的语义增强编码器-解码器框架,场景文本识别是计算机视觉领域的一个热门研究课题。最近，已经提出了许多基于编码器-解码器框架的识别方法，它们可以处理透视失真和曲线形状的场景文本。尽管如此，他们仍然面临着图像模糊、光照不均匀、字符不完整等诸多挑战。我们认为大多数编码器-解码器方法都是基于局部视觉特征而没有明确的全局语义信息。在这项工作中，我们提出了一个语义增强的编码器-解码器框架来稳健地识别低质量的场景文本。语义信息在编码器模块中用于监督和在解码器模块中用于初始化。特别是，最先进的 ASTER 方法作为示例被集成到所提出的框架中。大量实验表明，所提出的框架对于低质量文本图像更加稳健，并在多个基准数据集上实现了最先进的结果。源代码将可用。
EDRNet：编码器-解码器残差网络，用于带钢表面缺陷的显着目标检测,由于带钢表面缺陷的复杂变化，包括多变的缺陷类型、杂乱的背景、低对比度和噪声干扰，检测带钢表面缺陷仍然是一项具有挑战性的任务。现有的检测方法不能有效地从复杂背景中分割出缺陷对象，实时性较差。为了解决这些问题，我们提出了一种基于编码器-解码器残差网络（EDRNet）的新型显着性检测方法。在编码器阶段，我们使用全卷积神经网络来提取丰富的多级缺陷特征，并融合注意力机制来加速模型的收敛。然后在解码器阶段，我们交替采用通道加权块（CWB）和残差解码器块（RDB）来整合较浅层的空间特征和深层的语义特征，并逐步恢复预测的空间显着性值。最后，我们设计了带有一维滤波器（RRS_1D）的残差细化结构，以进一步优化粗显着图。与现有的显着性检测方法相比，深度监督的 EDRNet 可以准确地分割具有明确边界的完整缺陷对象，并有效滤除不相关的背景噪声。广泛的实验结果证明，我们的方法始终优于最先进的方法，具有较大的边距和较强的鲁棒性，并且在单个 GPU 上的检测效率超过 27 fps。
深度学习在农业密集场景分析中的应用：综述,深度学习 (DL) 是最先进的机器学习技术，在计算机视觉、生物信息学、自然语言处理等领域表现出卓越的性能。特别是作为现代图像处理技术，DL 已成功应用于各种任务，例如对象检测、语义分割和场景分析。然而，随着现实中密集场景的增加，由于严重的遮挡和小尺寸的物体，密集场景的分析变得特别具有挑战性。为了克服这些问题，DL 最近越来越多地应用于密集场景，并开始用于密集的农业场景。本综述的目的是探索深度学习在农业密集场景分析中的应用。为了更好地阐述这个话题，我们首先描述了农业密集场景的类型，以及挑战。接下来，我们介绍在这些密集场景中使用的各种流行的深度神经网络。然后，本文全面介绍了这些结构在各种农业任务中的应用，包括识别和分类、检测、计数和产量估计。最后，总结了调查的 DL 应用、限制和未来在农业密集图像分析方面的工作。
用于结直肠息肉语义分割的卷积神经网络的不确定性和可解释性,众所周知，结直肠息肉是结直肠癌的潜在前兆，结直肠癌是全球范围内癌症相关死亡的主要原因之一。结直肠癌的早期检测和预防主要是通过人工筛查来实现的，其中对患者的肠道进行目视检查。对于进行筛查的人来说，这样的过程可能具有挑战性并且令人筋疲力尽。这导致了许多关于设计自动系统的研究，旨在在检查期间为医生提供支持。最近，由于公开可用的结直肠图像数量的增加以及物体图像识别的深度学习研究的进步，这种自动系统已经有了显着的改进。具体来说，基于卷积神经网络 (CNN) 的决策支持系统在结直肠息肉的检测和分割方面表现出了最先进的性能。然而，基于 CNN 的模型不仅需要精确，以便在医疗环境中有所帮助。此外，必须很好地理解预测的可解释性和不确定性。在本文中，我们在结肠镜图像中息肉语义分割的背景下开发和评估了不确定性估计和模型可解释性的最新进展。此外，我们提出了一种估计与输入中重要特征相关的不确定性的新方法，并演示了如何在 DSS 中对可解释性和不确定性进行建模，以用于结直肠息肉的语义分割。结果表明，深度模型正在利用息肉的形状和边缘信息进行预测。此外，与精确预测相比，不准确的预测显示出更高程度的不确定性。 (C) 2019 年作者。爱思唯尔 BV 出版
使用深度多任务注意网络实现完整和准确的虹膜分割以进行非合作虹膜识别,在非合作环境中捕获的虹膜图像通常会受到不利噪声的影响，这对许多现有的虹膜分割方法提出了挑战。为了解决这个问题，本文提出了一种高效的基于深度学习的虹膜分割方法，命名为 IrisParseNet。不同于以往许多基于CNN的虹膜分割方法，只关注于遵循流行的语义分割框架来预测准确的虹膜掩膜，本文提出的方法是一个完整的虹膜分割解决方案，即虹膜掩膜和参数化的虹膜内外边界共同实现通过主动将它们建模成一个统一的多任务网络。此外，一个精心设计的注意力模块被纳入其中以提高分割性能。为了训练和评估所提出的方法，我们手动标记了三个具有代表性且具有挑战性的虹膜数据库，即 CASIA.v4-distance、UBIRIS.v2 和 MICHE-I，它们涉及多个照明（NIR、VIS）和成像传感器（长距离范围和移动虹膜相机），以及各种类型的噪音。此外，还建立了几个统一的评估协议以进行公平比较。对这些新注释的数据库进行了广泛的实验，结果表明，所提出的方法在各种基准测试中实现了最先进的性能。此外，作为一种通用的替代方法，所提出的虹膜分割方法可用于任何虹膜识别方法，并将显着提高非合作虹膜识别的性能。
用于人脸标签的端到端检测分割系统,在本文中，我们提出了一种端到端检测分割系统来实现详细的人脸标记。由于最先进的性能，完全卷积网络（FCN）已成为语义分割领域的主流算法。但是，一般的 FCN 通常会产生平滑且均匀的结果。此外，当样本中的语义类别极度不平衡时，例如人脸标注问题，FCN 无法很好地探索某些类别的特征。为了缓解这些问题，首先通过金字塔FCN将人脸图像编码为多级特征图，然后根据一级检测头提供的边界框分别提取不同人脸成分的特征。三个特定类别的子网络用于处理提取的特征以获得各自的分割结果。皮肤-毛发区域可以直接从金字塔 FCN 的后端解码。最后结合不同的分支得到整体的分割结果。此外，所提出的方法在单人脸标记数据集上进行训练，可以直接用于执行详细的多人脸标记任务，而无需任何网络修改和额外的模块或数据。整体结构可以以端到端的方式进行训练，同时保持较小的网络大小（12 MB）。实验表明，与以前的工作相比，所提出的方法可以生成更准确的（单个或多个）人脸标记结果，并在 HELEN 人脸数据集中获得最先进的结果。
使用基于 CNN 的分割和跟踪从大规模遥感图像中同时提取路面和中心线,准确和最新的路线图在广泛的应用中非常重要。不幸的是，由于树木和建筑物的遮挡、道路的可辨别性和复杂的背景，从高分辨率遥感图像中自动提取道路仍然具有挑战性。为了解决这些问题，特别是道路连通性和完整性，在本文中，我们引入了一种新颖的基于深度学习的多阶段框架，以同时准确地提取路面和道路中心线。我们的框架由三个步骤组成：提升分割、多起点追踪和融合。初始路面分割是通过完全卷积网络（FCN）实现的，之后多次应用另一个更轻的 FCN 以提高初始分割的准确性和连通性。在多起点追踪步骤中，通过提取分割结果的道路交叉点自动生成起点，然后通过嵌入在卷积神经网络（CNN）中的迭代搜索策略将起点用于追踪连续完整的道路网络。融合步骤通过结合分割和跟踪结果来聚合道路网络的语义和拓扑信息，以生成最终和细化的道路分割和中心线图。我们利用三个数据集评估了我们的方法，这些数据集涵盖了全球 40 多个城市的各种道路情况。结果证明了我们提出的框架的卓越性能。具体来说，我们的方法在路面分割的连通性指标和中心线提取的完整性指标上的性能分别比其他方法高出 7% 和 40%。
用于 3D 点云语义分割的点注意网络,卷积神经网络 (CNN) 在由规则排列的网格（例如图像）表示的数据上表现得非常好。然而，由于其不规则和无序的性质，直接利用稀疏 3D 点云上的经典卷积核或参数共享机制效率低下。我们提出了一个点注意网络，该网络可以学习丰富的局部形状特征及其上下文相关性，用于 3D 点云语义分割。由于相邻点的几何分布对点排序是不变的，我们提出了一种局部注意力-边缘卷积（LAE-Conv）来构建基于多方向搜索的邻域点的局部图。我们为每条边分配注意力系数，然后将点特征聚合为其邻居的加权和。然后将学习到的 LAE-Conv 层特征提供给逐点空间注意模块，以生成所有点的相互依赖矩阵，而不管它们的距离如何，从而捕获有助于更精确语义信息的远程空间上下文特征。所提出的点注意网络由编码器和解码器组成，与 LAE-Conv 层和逐点空间注意模块一起，使其成为一个端到端的可训练网络，用于预测 3D 点云分割的密集标签。对 3D 点云具有挑战性的基准进行的实验表明，我们的算法可以比现有的最先进方法执行同等或更好的性能。 (C) 2020 Elsevier Ltd. 保留所有权利。
基于地球观测数据的深度学习目标检测和图像分割：综述-第二部分：应用,在地球观测 (EO) 中，传统上通过调查聚合类来分析大规模地表动力学。具有非常高空间分辨率的数据的增加使得能够在细粒度特征级别上进行调查，这可以帮助我们通过考虑物体动力学来更好地理解地表动力学。为了提取细粒度的特征和对象，最流行的图像分析深度学习模型是常用的：卷积神经网络（CNN）。在这篇评论中，我们通过回顾 429 项关于使用 CNN 进行图像分割和对象检测的研究，全面概述了深度学习对 EO 应用的影响。我们广泛检查了研究地点的空间分布、使用的传感器、使用的数据集和 CNN 架构，并全面概述了使用 CNN 的 EO 中的应用。我们的主要发现是 CNN 处于从计算机视觉到 EO 的高级过渡阶段。基于此，我们认为在不久的将来，使用 CNN 分析物体动力学的研究将对 EO 研究产生重大影响。在本第二部分重点关注 EO 申请，我们完成了第一部分提供的方法审查。
DSNet：自动皮肤镜皮肤病变分割,背景和目的：皮肤病变的自动分割被认为是用于黑色素瘤检测的计算机辅助诊断 (CAD) 系统中的关键步骤。尽管具有重要意义，但皮肤病变分割仍然是一个未解决的挑战，因为它们在颜色、纹理和形状方面的可变性以及无法区分的边界。方法：通过这项研究，我们提出了一种新的自动语义分割网络，用于稳健的皮肤病变分割，称为皮肤镜皮肤网络（DSNet）。为了减少参数数量以使网络轻量化，我们使用深度可分离卷积代替标准卷积，将学习到的判别特征投影到编码器不同阶段的像素空间。此外，我们实现了 U-Net 和全卷积网络 (FCN8s) 以与提议的 DSNet 进行比较。结果：我们在两个公开可用的数据集上评估我们提出的模型，即 ISIC-2017(1) 和 PH2(2)。对于 ISIC-2017 和 PH2 数据集，获得的平均联合交叉 (mIoU) 分别为 77.5% 和 87.0%，在 mIoU 方面比 ISIC-2017 挑战获胜者高出 1.0%。我们提出的网络在 ISIC-2017 数据集上的 mIoU 方面也分别优于 U-Net 和 FCN8s 3.6% 和 6.8%。结论：我们的皮肤病变分割网络优于文章中讨论的其他方法，并且能够提供更好的- 两个不同测试数据集上的分段掩码，可以提高黑色素瘤检测的性能。我们训练有素的模型以及源代码和预测掩码已公开发布 (3)。
RefineNet：用于密集预测的多路径细化网络,最近，非常深的卷积神经网络（CNNs）在物体识别方面表现出了出色的性能，也成为了语义分割和深度估计等密集预测问题的首选。然而，重复的子采样操作，如深度 CNN 中的池化或卷积跨步，会导致初始图像分辨率显着下降。在这里，我们介绍了 RefineNet，这是一种通用的多路径细化网络，它明确利用下采样过程中可用的所有信息，以使用远程残差连接实现高分辨率预测。通过这种方式，捕获高级语义特征的更深层可以直接使用来自早期卷积的细粒度特征进行细化。 RefineNet 的各个组件采用身份映射思维方式的残差连接，从而实现有效的端到端训练。此外，我们引入了链式残差池，它以有效的方式捕获丰富的背景上下文。我们对密集分类问题语义分割进行了综合实验，并在七个公共数据集上取得了良好的性能。我们进一步将我们的方法应用于深度估计，并证明了我们的方法在密集回归问题上的有效性。
利用机载高分辨率图像进行树种分类的改进 Res-UNet 模型,树种分类对于森林资源的管理和可持续发展具有重要意义。传统的面向对象的树种分类方法，如支持向量机，需要人工进行特征选择，精度普遍较低，而深度学习技术可以自动提取图像特征，实现端到端的分类。因此，本研究提出了一种基于深度学习的树分类方法。该方法将语义分割网络U-Net和特征提取网络ResNet组合成一个改进的Res-UNet网络，其中U-Net网络的卷积层由ResNet的残差单元表示，使用线性插值代替每个上采样层中的反卷积。在网络的输出端，条件随机场用于后处理。该网络模型用于对中国广西南宁高峰林场机载正射影像进行分类实验。然后将结果与 U-Net 和 ResNet 网络的结果进行比较。所提出的方法表现出更高的分类准确率，总体分类准确率为 87%。因此，该模型可以有效地实施森林树种分类，为南方树种分类提供新的机遇。
语义分割领域适应的学习纹理不变表示,由于为语义分割注释像素级标签很费力，因此利用合成数据是一个有吸引力的解决方案。然而，由于合成域和真实域之间的域差距，用合成数据训练的模型很难泛化到真实数据。在本文中，考虑到两个域之间作为纹理的根本区别，我们提出了一种适应目标域纹理的方法。首先，我们使用风格转移算法来多样化合成图像的纹理。生成图像的各种纹理可以防止分割模型过度拟合到一个特定的（合成）纹理。然后，我们通过自我训练对模型进行微调，以获得对目标纹理的直接监督。我们的结果达到了最先进的性能，并且我们通过大量实验分析了在程式化数据集上训练的模型的属性。
使用深度学习方法进行 COVID-19 肺部 CT 图像分割：U-Net 与 SegNet,背景 目前，迫切需要有效的工具来评估 COVID-19 患者的诊断。在本文中，我们提出了在此类患者的 CT 肺部图像上检测和标记感染组织的可行解决方案。研究了两种结构不同的深度学习技术，即 SegNet 和 U-NET，用于在 CT 肺部图像中对感染组织区域进行语义分割。方法 我们建议使用两个已知的深度学习网络 SegNet 和 U-NET 进行图像组织分类。 SegNet 的特点是场景分割网络和 U-NET 作为医学分割工具。这两个网络都被用作二元分段器来区分受感染的和健康的肺组织，也被用作多类分段器来学习肺部的感染类型。每个网络使用 72 张数据图像进行训练，在 10 张图像上进行验证，并针对剩下的 18 张图像进行测试。计算结果的几个统计分数并相应地制成表格。结果结果表明，与其他方法相比，SegNet 在对感染/未感染组织进行分类方面具有卓越的能力（平均准确度为 0.95），而 U-NET 作为多类分割器显示出更好的结果（平均准确度为 0.91）。结论 对 COVID-19 患者的 CT 扫描图像进行语义分割是一个关键目标，因为它不仅有助于疾病诊断，还有助于量化疾病的严重程度，从而相应地优先考虑人群治疗。我们提出了基于计算机的技术，这些技术被证明在肺部 CT 扫描中作为受感染组织的检测器是可靠的。在今天的大流行中，这种方法的可用性将有助于在全球范围内自动化、优先考虑、加强和扩大 COVID-19 患者的治疗。
使用改进的 SegNet 进行 CT 扫描中的肝肿瘤分割,全世界与癌症相关的主要死因是肝癌。使用计算机断层扫描 (CT) 及早发现肝癌可以防止每年数百万患者死亡。然而，读取数百甚至数十个 CT 扫描对于放射科医生来说是一个巨大的负担。因此，迫切需要自动、快速、准确地读取、检测和评估 CT 扫描。然而，从 CT 扫描中分割和提取肝脏是任何系统的瓶颈，并且仍然是一个具有挑战性的问题。在这项工作中，采用并修改了一种基于深度学习的道路场景语义像素分类技术，以适应肝脏 CT 分割和分类。深度卷积编码器-解码器的架构称为 SegNet，由编码-解码器层的分层对应组成。所提出的架构在肝脏 CT 扫描的标准数据集上进行了测试，在训练阶段实现了高达 99.9% 的肿瘤准确度。
具有 3D 离散小波变换和马尔可夫随机场的极化 SAR 图像语义分割,极化合成孔径雷达（PolSAR）图像分割目前在遥感应用的图像处理中具有重要意义。然而，由于两个主要原因，这是一项具有挑战性的任务。首先，由于标注成本高，标签信息难以获取。其次，嵌入在 PolSAR 成像过程中的散斑效应显着降低了分割性能。为了解决这两个问题，我们在本文中提出了一种上下文 PolSAR 图像语义分割方法。以新定义的通道一致特征集作为输入，采用三维离散小波变换（3D-DWT）技术来提取对散斑噪声具有鲁棒性的判别性多尺度特征。然后进一步应用马尔可夫随机场（MRF）在分割过程中在空间上加强标签平滑度。通过首次同时利用 3D-DWT 特征和 MRF 先验，在分割过程中充分整合了上下文信息，以确保准确和平滑的分割。为了证明所提出方法的有效性，我们对三个真实基准 PolSAR 图像数据集进行了广泛的实验。实验结果表明，所提出的方法使用最少数量的标记像素实现了有希望的分割精度和更好的空间一致性。
图像级标签的粗到细语义分割,基于深度神经网络的语义分割通常需要大规模成本广泛的注释进行训练以获得更好的性能。为了避免大多数方法所需的逐像素分割注释，最近一些研究人员尝试使用对象级标签（例如，边界框）或图像级标签（例如，图像类别）。在本文中，我们提出了一种新的基于图像级类别标签的递归从粗到细的语义分割框架。对于每张图像，首先由基于卷积神经网络的无监督前景分割模型生成初始粗掩模，然后通过图模型进行增强。增强的粗略掩码被馈送到完全卷积神经网络以进行递归细化。与现有的基于图像级标签的语义分割方法不同，需要对包含多种对象的图像的所有类别进行标记，我们的框架对每个图像只需要一个标签，并且可以处理包含多类对象的图像。仅在 ImageNet 上训练，我们的框架在 PASCAL VOC 数据集上实现了与其他基于图像级标签的最先进语义分割方法相当的性能。此外，我们的框架可以很容易地扩展到前景对象分割任务，并在互联网对象数据集上实现与最先进的监督方法相当的性能。
通过域自适应语义分割的不确定性估计纠正伪标签学习,本文重点研究在语义分割的上下文中将知识从源域转移到目标域的无监督域适应。现有方法通常将伪标签视为基本事实，以充分利用未标记的目标域数据。然而，目标域数据的伪标签通常由在源域上训练的模型预测。因此，由于训练域和测试域之间的差异，生成的标签不可避免地包含不正确的预测，这可能会转移到最终适应的模型中，并在很大程度上影响训练过程。为了克服这个问题，本文提出在训练期间显式地估计预测不确定性，以纠正伪标签学习以进行无监督语义分割自适应。给定输入图像，模型输出语义分割预测以及预测的不确定性。具体来说，我们通过预测方差对不确定性进行建模，并将不确定性纳入优化目标。为了验证所提出方法的有效性，我们在两个流行的合成到真实语义分割基准上评估所提出的方法，即 GTA5 -> Cityscapes 和 SYNTHIA -> Cityscapes，以及一个跨城市基准，即 Cityscapes -> 牛津机器人车。我们通过大量实验证明，所提出的方法（1）根据预测方差动态设置不同的置信度阈值，（2）纠正噪声伪标签的学习，以及（3）比传统的伪标签学习取得显着改进并产生有竞争力的在所有三个基准上的表现。
联合网络图像处理：基于CNN的室内场景多任务图像语义分割,图像语义分割一直是机器人领域的研究热点。其目的是通过对不同的对象进行分割，为对象分配不同的语义类别标签。但在实际应用中，机器人除了知道物体的语义类别信息外，还需要知道物体的位置信息，才能完成更复杂的视觉任务。针对复杂的室内环境，本研究设计了一种联合目标检测的图像语义分割网络框架。利用在目标检测网络中加入语义分割分支的并行操作，创新地实现了目标分类、检测和语义分割相结合的多视觉任务。通过设计新的损失函数，利用迁移学习的思想调整训练，最后在自建的室内场景数据集上进行验证，实验证明本研究方法可行有效，具有良好的鲁棒性。
探索多尺度基于对象的卷积神经网络（multi-OCNN）用于高空间分辨率的遥感图像分类,"卷积神经网络 (CNN) 已越来越多地用于遥感图像的土地覆盖制图。然而，使用传统 CNN 进行大面积分类的计算成本很高，并且使用滑动窗口方法生成粗略的地图。为了解决这个问题，基于对象的 CNN（OCNN）成为提高分类性能的替代解决方案。然而，以往的研究主要集中在城市区域或小场景，对于异质景观的大面积分类仍然需要OCNN方法的实现。此外，分割对象的大量标记需要一种实用的方法来减少计算量，包括对象分析和多个 CNN。本研究提出了一种新的多尺度 OCNN (multi-OCNN) 框架，用于在超过 145,740 公里 (2) 的 1 米分辨率下进行大规模土地覆盖分类。我们的方法包括三个主要步骤：（i）图像分割，（ii）使用基于骨架的算法进行对象分析，以及（iii）应用多个 CNN 进行最终分类。此外，我们开发了一个名为 IowaNet 的大型基准数据集，其中包含 100 万张标记图像和 10 个类别。在我们的方法中，多尺度 CNN 被训练以在对象的语义标记期间捕获最佳上下文信息。同时，骨架化算法提供了对象的形态表示（中轴），以支持选择卷积位置进行 CNN 预测。总的来说，与传统的基于补丁的 CNN (81.6%) 和固定输入 OCNN (82%) 相比，提出的多 OCNN 具有更好的分类准确率（总体准确率接近 87.2%）。此外，结果表明，该框架分别比传统的像素级 CNN16 或 CNN256 快 8.1 倍和 111.5 倍。事实证明，多个 CNN 和对象分析对于准确和快速的分类至关重要。虽然多 OCNN 在土地覆盖产品中产生了高水平的空间细节，但在某些类别中观察到错误分类，例如道路与建筑物或阴影与湖泊。尽管存在这些小缺点，但我们的结果也证明了 IowaNet 训练数据集在模型性能方面的优势；过拟合过程随着样本数量的增加而减少。多 OCNN 的局限性部分可以通过分割质量和航空数据中有限的光谱带数量来解释。随着深度学习方法的进步，本研究支持多 OCNN 对 1 米分辨率可操作大规模土地覆盖产品的好处的主张。"
用于遥感图像语义分割的多尺度自适应特征融合网络,由于存在复杂的背景、不规则的目标形状以及多个目标类别外观的相似性，高分辨率遥感图像的语义分割极具挑战性。现有的大多数分割方法仅依赖于提取的多尺度特征的简单融合，当目标尺寸差异较大时，往往无法提供令人满意的结果。通过多尺度上下文提取和多尺度特征的有效融合来解决这个问题，在本文中，我们提出了一种端到端的多尺度自适应特征融合网络（MANet），用于遥感图像中的语义分割。它是一种编解码结构，包括多尺度上下文提取模块（MCM）和自适应融合模块（AFM）。 MCM 采用两层具有不同膨胀率的空洞卷积和全局平均池来并行提取多个尺度的上下文信息。 MANet 嵌入了通道注意机制来融合语义特征。通过全局平均池化连接高级和低级语义信息以生成全局特征。这些全局特征作为通道权重，由全连接层获取每个通道的自适应权重信息。为了实现有效的融合，这些调整后的权重被应用于融合的特征。通过与其他六个最先进的网络进行比较来评估所提出方法的性能：完全卷积网络 (FCN)、U-net、UZ1、轻量级 RefineNet、DeepLabv3+ 和 APPD。使用公开可用的 Potsdam 和 Vaihingen 数据集进行的实验表明，所提出的 MANet 显着优于其他现有网络，总体准确率分别达到 89.4% 和 88.2%，平均 F1 分别达到 90.4% 和 86.7%。
优化卷积神经网络以对大型材料成像数据集执行语义分割：X 射线断层扫描和连续切片,机器学习用于分割由基于同步加速器的枝晶生长的 X 射线计算机断层扫描 (XCT) 图像和枝晶粗化的连续切片 (SS) 图像产生的大型材料科学数据集。与仅使用 30 个 XCT 或 6 个 SS 训练图像的传统分割技术相比，这两种神经网络 (NN) 在数量上都产生了更准确的输出。我们表明，如果使用从固定数量的训练数据中采样的大量小图像来训练 NN，则可以提高性能。为 XCT 和 SS 数据集确定了最佳图像大小和训练图像数量。还通过将性能最高的 XCT 和 SS NN 应用于相关数据集来测试 NN 可迁移性。虽然初始分割是成功的，但对原始图像应用简单的变换进一步提高了 NN 性能。这些结果显示了使用机器学习分割大型材料科学数据集的强大预测能力和充满希望的未来。
作物类型之间的迁移学习，用于精准农业中作物与杂草的语义分割,农业机器人依靠语义分割来区分农作物和杂草，以进行选择性处理并提高产量和农作物健康，同时减少化学品的使用量。深度学习方法最近实现了出色的分类性能和实时执行。然而，这些技术也依赖于大量的训练数据，需要大量的标注工作，而这两者在精准农业中都是稀缺的。需要额外的设计工作才能在不同的环境条件和作物生长阶段达到商业上可行的性能水平。在本文中，我们探讨了不同作物类型的基于深度学习的分类器之间知识转移的作用，目的是减少新作物所需的再训练时间和标记工作。我们检查了三个具有不同作物类型并包含各种杂草的数据集的分类性能，并比较了使用像素级别标记的数据与通过较少耗时的分割输出注释过程获得的部分标记数据时所需的性能和再训练工作.我们表明，不同作物类型之间的迁移学习是可能的，并且可以将训练时间减少多达 80%。此外，我们表明，即使用于再训练的数据注释不完善，分类性能也与使用费力注释的像素精度数据训练的网络相比，分类性能在 2% 以内。
通过基于密集属性的注意力的细粒度广义零样本学习,我们解决了视觉相似类的细粒度广义零样本识别问题，而无需为某些类训练图像。我们提出了一种基于密集属性的注意机制，该机制针对每个属性关注最相关的图像区域，获得基于属性的特征。我们没有将图像的全局特征向量与其关联的类语义向量对齐，而是提出了一种属性嵌入技术，该技术将每个基于属性的特征与其属性语义向量对齐。因此，我们计算一个属性分数向量，用于图像中每个属性的存在，其与真实类语义向量的相似性最大化。此外，我们使用属性上的注意机制调整每个属性分数，以更好地捕捉不同属性的判别力。为了解决测试期间对可见类的偏见的挑战，我们提出了一种新的自校准损失，它可以调整未见类的概率以解释训练偏差。我们对 CUB、SUN 和 AWA2 三个流行的数据集以及大规模的 DeepFashion 数据集进行了实验，表明我们的模型显着提高了最先进的水平。
IMRAM：用于跨模态图像文本检索的循环注意记忆的迭代匹配,启用图像和文本的双向检索对于理解视觉和语言之间的对应关系非常重要。现有方法利用注意力机制以细粒度的方式探索这种对应关系。然而，它们中的大多数都平等地考虑所有语义，因此将它们统一对齐，而不管它们的复杂性如何。事实上，语义是多种多样的（即涉及不同种类的语义概念），人类通常遵循一种潜在结构将它们组合成可理解的语言。在现有方法中可能难以最佳地捕获这种复杂的对应关系。在本文中，为了解决这一缺陷，我们提出了一种迭代匹配与循环注意记忆（IMRAM）方法，其中图像和文本之间的对应关系通过多个对齐步骤来捕获。具体来说，我们引入了一种迭代匹配方案来逐步探索这种细粒度的对应关系。内存蒸馏单元用于将对齐知识从早期步骤提炼到后面的步骤。在三个基准数据集（即 Flickr8K、Flickr30K 和 MS COCO）上的实验结果表明，我们的 IMRAM 实现了最先进的性能，很好地证明了它的有效性。在名为 KWAI-AD 的实用商业广告数据集上进行的实验进一步验证了我们的方法在实际场景中的适用性。
用于光学航空图像变化检测的基于卷积神经网络的迁移学习,考虑到监督变化检测任务缺乏标记的训练数据集，在这封信中，我们试图通过提出一种基于卷积神经网络 (CNN) 的变化检测方法和新设计的损失函数来实现迁移学习。不同的数据集。为了实现这一目标，我们首先利用用于监督语义分割任务的相对充足的训练数据，在开源数据集上预训练 U-Net 模型。然后，我们最小化一个巧妙设计的损失函数，结合从预训练模型中提取的高级特征和变化检测数据集中包含的语义信息，从而实现迁移学习。第三，我们计算从上述步骤获得的特征向量之间的距离并生成差异图。最后，在差异图上使用简单的聚类方法甚至可以获得满意的变化图。在典型的光学航拍图像数据集上进行的实验验证了所提出的方法与最先进的无监督方法相比具有优势。
微观藻类检测中的语义与实例分割,微观藻类分割，特别是硅藻，是水质评估的重要程序。这些微藻的分割仍然是计算机视觉的挑战。本文首次解决了这个问题，使用深度学习方法来准确预测属于每个类别的像素，即硅藻和非硅藻。对语义分割和实例分割进行了比较，并在存在不同类型噪声的情况下评估了这些方法的性能。然后使用用于手动硅藻识别的相同原始图像评估经过训练的模型。总共分析了 60 倍放大倍率、2592x1944 像素大小的整个视场的 126 张图像。这些图像包含 10 个不同的分类群以及碎片和碎片。通过实例分割获得了最佳结果，平均精度为 85%，灵敏度为 86%，特异性为 91%（精度高达 92%，某些分类群的灵敏度和特异性均为 98%）。语义分割能够将平均灵敏度提高到 95%，但将特异性降低到 60%，将精度降低到 57%。当发生重叠时，实例分割还能够正确分离硅藻，这有助于估计硅藻的数量，这是水质分级的关键要求。
用于广义零样本学习的域感知视觉偏差消除,广义零样本学习旨在识别来自可见和不可见域的图像。最近的方法侧重于学习统一的语义对齐视觉表示以在两个领域之间传递知识，而忽略了无语义视觉表示在减轻有偏见的识别问题方面的作用。在本文中，我们提出了一种新颖的域感知视觉偏差消除（DVBE）网络，该网络构建了两个互补的视觉表示，即无语义和语义对齐，以分别处理可见域和不可见域。具体来说，我们探索了交叉注意力的二阶视觉统计来压缩无语义表示，并设计了一个自适应边距 Softmax 来最大化类间差异。因此，无语义表示变得具有足够的判别力，不仅可以准确地预测看到的类别，而且还可以根据预测的类别熵过滤掉未看到的图像，即域检测。对于看不见的图像，我们自动搜索最佳语义视觉对齐架构，而不是手动设计，以预测看不见的类别。通过准确的域检测，显着减少了对所见域的偏向识别问题。对五个分类和分割基准的实验表明，DVBE 的性能优于现有方法，平均提高了 5.7%。
自动驾驶中激光雷达点云的深度学习：综述,最近，深度学习 (DL) 在从 3-D LiDAR 数据进行判别特征学习方面的进步导致了自动驾驶领域的快速发展。然而，自动处理不均匀、非结构化、嘈杂和海量的 3-D 点云是一项具有挑战性和乏味的任务。在本文中，我们对应用于激光雷达点云的现有引人注目的深度学习架构进行了系统回顾，详细介绍了自动驾驶中的特定任务，例如分割、检测和分类。尽管有几篇已发表的研究文章专注于自动驾驶汽车计算机视觉的特定主题，但迄今为止，还没有关于在自动驾驶汽车激光雷达点云中应用深度学习的一般性调查。因此，本文的目标是缩小该主题的差距。本次调查总结了近五年来的 140 多项关键贡献，包括具有里程碑意义的 3-D 深度架构、DL 在 3-D 语义分割、对象检测和分类中的显着应用；具体的数据集、评估指标和最先进的性能。最后，我们总结了剩余的挑战和未来的研究。
遥感图像解译的Few-Shot学习研究进展,深度学习的快速发展为遥感图像解译带来了有效的解决方案。训练深度神经网络模型通常需要大量手动标记的样本。然而，在遥感领域获得足够的标记样本来满足数据需求是有局限性的。因此，开展小样本学习在遥感图像解译中的研究具有重要意义。首先，本文对与少样本学习相关的现有遥感解释工作进行了文献计量分析。其次，介绍了基于数据增强和基于先验知识的两类小样本学习方法，用于遥感图像的解释。然后，列出了三种典型的遥感解释应用，包括场景分类、语义分割和目标检测，以及相应的公共数据集和评估标准。最后对研究现状进行了总结，并提出了一些可能的研究方向。本文为从事遥感领域小样本学习研究的学者提供参考。
TGNet：基于 3-D 点云分割的几何图 CNN,最近的几何深度学习工作定义了局部区域的卷积运算，并在非欧几里得数据（包括图形和点云）上取得了显着的成功。然而，输入与其相邻坐标或特征之间的高级几何相关性没有得到充分利用，导致分割性能不理想。在本文中，我们提出了一种新颖的图卷积架构，我们将其称为泰勒高斯混合模型 (GMM) 网络 (TGNet)，以有效地从点云中学习富有表现力和组合的局部几何特征。 TGNet 由基本几何单元 TGConv 组成，这些单元在不规则点集上进行局部卷积，并由一系列滤波器参数化。具体来说，这些滤波器被定义为局部点特征和从局部坐标中提取的相邻几何特征的乘积。这些几何特征由高斯加权泰勒核表示。然后，参数池化层聚合 TGConv 特征，为每个点生成新的特征向量。 TGNet 在多尺度邻域上使用 TGConv 来提取从粗到细的语义深度特征，同时提高其尺度不变性。此外，在输出层内采用条件随机场（CRF）以进一步改善分割结果。使用三个点云数据集，定性和定量实验结果表明，所提出的方法在 ScanNet 上实现了 62.2% 的平均准确率，在斯坦福大型 3D 室内空间 (S3DIS) 和巴黎上实现了 57.8% 和 68.17% 的平均交叉联合 (mIoU) -Lille-3D 数据集，分别。
基于改进Mask R-CNN的高空间分辨率遥感图像高效建筑物提取方法,在本文中，我们考虑从高空间分辨率遥感图像中提取建筑物。目前，大多数建筑物提取方法都是基于人工特征的。然而，建筑物的多样性和复杂性意味着建筑物提取方法仍然面临着巨大的挑战，因此最近提出了基于深度学习的方法。本文提出了一种基于卷积神经网络和边缘检测算法的建筑物提取框架。该方法称为Mask R-CNN Fusion Sobel。由于Mask R-CNN在图像分割领域的突出成就，本文对其进行了改进，然后将其应用于遥感图像建筑物提取。我们的方法由三个部分组成。首先，使用卷积神经网络进行粗略定位和像素级分类，通过自动发现语义特征来解决误提取和漏提取的问题。其次，利用Sobel边缘检测算法对建筑物边缘进行准确分割，解决深度卷积神经网络在语义分割中的边缘提取和对象完整性问题。第三，通过融合算法提取建筑物。我们利用提出的框架从中国卫星GF-2的高分辨率遥感图像中提取建筑物，实验表明，该方法的IOU（intersection over union）平均值为88.7%，平均值为Kappa 分别为 87.8%。因此，我们的方法可以应用于复杂建筑物的识别和分割，并且在准确性上优于经典方法。
使用深度学习从 CubeSat 图像中绘制北麓河地区（青藏高原）的倒退解冻塌陷图,退冻塌陷（RTS）是多年冻土区最具活力的地貌之一，其形成可归因于富含冰的多年冻土的融化。由于 RTS 的位置偏远和自动测绘的技术挑战，人们对青藏高原 RTS 的空间分布和影响知之甚少。在这项研究中，我们创新地将用于语义分割的前沿深度学习算法 DeepLabv3 + 应用于具有高空间和时间分辨率的卫星图像 Planet CubeSat 图像。我们的方法允许我们在 5200 km(2) 的区域内自动描绘 220 个 RTS，平均精度为 0.541。当与并集的交集阈值为 0.5 时，对应的准确率、召回率和 F1 分数分别为 0.863、0.833 和 0.848。此外，大约 100 个关于 k 折交叉验证（k = 3、5 和 10）和数据增强的实验表明我们的方法是稳健的。并且在不同地理区域的测试表明，训练模型的泛化能力非常好。我们发现（1）大多数 RTS 面积较小（面积 < 8 公顷，周长 < 2000 m）；（2）RTS 优先发育在缓坡（4 到 8 度）的位置，以及低于周围环境的区域（平均地形位置指数为 - 0.17) 并且接收的太阳辐射较少（即朝北的斜坡）。结果表明，该方法可以从 Planet CubeSat 图像中自动映射 RTS，并有可能应用于更大的区域。
基于深度学习算法的非增殖性糖尿病视网膜病变微动脉瘤预后和早期诊断系统的糖尿病视网膜病变检测,几十年来，预测眼底图像中微动脉瘤的存在和早期识别糖尿病视网膜病变一直是一项重大挑战。糖尿病视网膜病变 (DR) 受到长期高血糖水平的影响，这会导致微血管并发症和不可逆的视力丧失。视网膜微动脉瘤形成和黄斑水肿是 DR 的最初征兆，在正确的时间进行诊断可以降低非增殖性糖尿病视网膜病变的风险。深度学习的快速改进使其逐渐成为一种有效的技术，为医学图像分析问题提供有趣的解决方案。所提出的系统使用卷积神经网络算法分析眼底图像中微动脉瘤的存在，该算法将深度学习作为核心组件，通过 GPU（图形处理单元）加速，以高性能和低延迟推理执行医学图像检测和分割。语义分割算法用于将眼底图片分类为正常或感染。语义分割根据图像像素的共同语义对其进行划分，以识别微动脉瘤的特征。这提供了一个自动化系统，可帮助眼科医生将眼底图像分级为早期 NPDR、中度 NPDR 和严重 NPDR。已经提出了微动脉瘤的预后和非增殖性糖尿病视网膜病变系统的早期诊断系统，该系统能够有效训练深度卷积神经网络用于眼底图像的语义分割，从而提高 NPDR（非增殖性糖尿病视网膜病变）的效率和准确性预言。
通过具有非局部块的全卷积编码器-解码器网络从高分辨率航空图像中自动提取建筑物,从高分辨率航空图像中自动提取建筑物是土地利用统计和城市规划等各种实际应用的一项重要而基础的任务。最近，基于深度学习的各种方法，尤其是全卷积网络，在这项具有挑战性的语义分割任务中取得了令人瞩目的成绩。然而，缺乏全局上下文信息和粗心的上采样方法限制了建筑物提取任务性能的进一步提高。为了同时解决这些问题，我们提出了一种名为高效非局部残差 U 形网络（ENRU-Net）的新型网络，该网络由精心设计的 U 形编码器-解码器结构和改进的非局部块组成，称为不对称金字塔非局部块（APNB）。采用encoder-decoder结构对特征图进行细致的提取和恢复，APNB可以利用self-attention机制捕获全局上下文信息。我们评估了提议的 ENRU-Net，并将其与两个广泛使用的公共航空建筑图像数据集上的其他最先进的模型进行比较：马萨诸塞州建筑数据集和 WHU 航空图像数据集。实验表明，ENRU-Net 在这些数据集上的准确性与之前最先进的语义分割模型（包括 FCN-8s、U-Net、SegNet 和 Deeplab v3）相比有显着提高。随后的分析还表明，我们的 ENRU-Net 在从高分辨率航空图像中提取建筑物的效率方面具有优势。
通过解耦的身体和边缘监督改进语义分割,现有的语义分割方法要么旨在通过对全局上下文进行建模来提高对象的内部一致性，要么通过多尺度特征融合沿其边界细化对象细节。在本文中，提出了一种新的语义分割范式。我们的见解是，语义分割的吸引人的性能需要明确地建模对象的身体和边缘，这对应于图像的高频和低频。为此，我们首先通过学习流场来扭曲图像特征，以使对象部分更加一致。通过显式采样不同的部分（身体或边缘）像素，在解耦监督下进一步优化生成的身体特征和残余边缘特征。我们表明，所提出的具有各种基线或骨干网络的框架可以带来更好的对象内部一致性和对象边界。在包括 Cityscapes、CamVid、KIITI 和 BDD 在内的四个主要道路场景语义分割基准上的广泛实验表明，我们提出的方法在保持高效推理的同时建立了新的技术状态。特别是，我们在 Cityscape 上仅使用经过精细注释的数据就达到了 83.7 mIoU %。代码和模型可用于促进任何进一步的研究 (https://github.com/lxtGH/DecoupleSegNets)。
高空间分辨率遥感影像地理空间目标分割的前景感知关系网络,地理空间对象分割作为一种特殊的语义分割任务，在高空间分辨率（HSR）遥感影像中总是面临着较大的尺度变化、较大的背景类内方差和前景-背景不平衡的问题。然而，一般的语义分割方法主要关注自然场景中的尺度变化，而对大面积地球观测场景中通常发生的其他两个问题考虑不足。在本文中，我们认为问题在于缺乏前景建模，并从基于关系和基于优化的前景建模的角度提出了前景感知关系网络（FarSeg），以缓解上述两个问题。从关系的角度来看，FarSeg 通过学习前景-场景关系关联的前景相关上下文来增强对前景特征的识别。同时，从优化的角度，提出了一种前景感知优化，在训练过程中关注前景样本和背景的硬样本，实现均衡优化。使用大规模数据集获得的实验结果表明，所提出的方法优于最先进的通用语义分割方法，并在速度和准确性之间取得了更好的平衡。
TSNet：用于 RGB-D 室内语义分割的三流自注意力网络,本文提出了一种用于室内语义分割的三流自注意力网络（TSNet），包括两个不对称输入流（不对称编码器结构）和一个带有自注意力模块的跨模态蒸馏流。两个不对称输入流是用于红绿蓝 (RGB) 流的 ResNet34 和用于深度流的 VGGNet16。伴随 RGB 和深度流，带有自注意力模块的跨模态蒸馏流在自下而上路径的每个级别中提取新的 RGB 和深度特征。此外，在使用双线性上采样恢复特征图的空间分辨率的同时，我们通过自注意力模块将 RGB 流和深度流的特征信息结合起来。我们构建了 NYU Depth V2 数据集来评估 TSNet，并取得了与当前最先进方法相当的结果。
多模态 GAN：迈向跨模态高光谱多光谱图像分割,本文解决了大规模城市场景中跨模态数据有限的语义分割问题。大多数先前的工作都试图通过使用多模态深度神经网络（DNN）来解决这个问题。然而，它们在多模态中有效混合不同属性以及从复杂场景中稳健地学习表示的能力仍然有限，特别是在缺乏足够且注释良好的训练图像的情况下。这导致了与多模态 DNN 的跨模态学习相关的挑战。为此，我们在网络中引入了两个新颖的即插即用单元：自生成对抗网络 (GAN) 模块和相互 GAN 模块，以分别学习扰动不敏感的特征表示并消除多模态之间的差距，产生更有效和稳健的信息传输。此外，设计了一种补丁式渐进式训练策略，以使有限样本的有效网络学习成为可能。我们在两个多模态（高光谱和多光谱）开销图像数据集上评估所提出的网络，并与几种最先进的方法相比取得了显着的改进。
智能农业中的空中视觉感知：小麦黄锈病监测的实地研究,农业正面临来自作物胁迫的严峻挑战，威胁到其可持续发展和粮食安全。本文利用航空视觉感知进行黄锈病监测，无缝集成了无人机传感、多光谱成像、植被分割和深度学习 U-Net 等最先进的技术和算法。设计了一个田间试验，用黄锈病菌侵染冬小麦，在上面用配备RedEdge相机的DJI Matrice 100拍摄多光谱航拍图像。在图像校准和拼接之后，通过检查 Parrot Anafi Drone 拍摄的高分辨率 RGB 图像来标记多光谱正射镶嵌以进行系统评估。所开发的框架同时绘制光谱空间信息的优点通过经典随机森林算法显示出比纯基于光谱的分类器的性能有所提高来证明。此外，通过包装算法的顺序前向选择策略，测试了各种网络输入波段组合，包括三个 RGB 波段和五个选定的光谱植被指数。
深度医学图像分割的置信度校准和预测不确定性估计,全卷积神经网络 (FCN)，尤其是 U-Net，在众多医学成像应用的语义分割方面取得了最先进的成果。此外，批量归一化和 Dice 损失已成功用于稳定和加速训练。然而，这些网络校准不佳，即它们倾向于对正确和错误的分类产生过度自信的预测，使它们不可靠且难以解释。在本文中，我们研究了用于医学图像分割的 FCN 中的预测不确定性估计。我们做出了以下贡献： 1）我们在 FCN 的分割质量和不确定性估计方面系统地比较了交叉熵损失和 Dice 损失； 2）我们提出了模型集成，用于对经过批量归一化和 Dice 损失训练的 FCN 进行置信度校准； 3) 我们评估校准后的 FCN 预测结构分割质量和检测分布外测试示例的能力。我们对大脑、心脏和前列腺的三种医学图像分割应用进行了广泛的实验，以评估我们的贡献。这项研究的结果为医学图像分割中的预测不确定性估计和分布外检测提供了相当多的见解，并为置信度校准提供了实用的方法。此外，我们始终证明模型集成可以提高置信度校准。
DSSNet：用于高光谱图像分类的简单扩张语义分割网络,基于深度学习的方法在高光谱图像分类 (HSIC) 任务中表现出有希望的表现。然而，最近的方法通常将 HSIC 视为一个补丁图像分类问题，并通过为像素周围的补丁提供单个标签来解决该问题。在这封信中，我们提出了一种新的语义分割网络，可以直接以端到端的方式标记每个像素。与patchwise模型相比，我们的方法可以显着提高训练效果并减少一些手动参数。 HSIC 的另一个挑战是高光谱图像的空间分辨率相对较低。在这种情况下，池化操作可能会导致分辨率和覆盖丢失。为了解决这个问题，我们将扩张卷积引入我们的模型并构建扩张语义分割网络（DSSNet）。与现有的一些作品不同，DSSNet 是专门为 HSIC 设计的，没有复杂的架构，不需要预训练的模型。可以通过端到端的方式提取联合空间光谱信息，从而避免各种预处理或后处理操作。与一些最新的基于深度学习的 HSIC 模型相比，对两个公共数据集的实验证明了我们改进的有效性。
PASS：全景环形语义分割,逐像素语义分割能够统一大多数驾驶场景感知任务，并在导航辅助方面取得了显着进展，其中整个环境感知至关重要。然而，当前主流的语义分割器主要针对具有窄视野 (FoV) 的数据集进行基准测试，并且大部分基于视觉的智能车辆仅使用前向摄像头。在本文中，我们提出了一种基于紧凑型全景环形透镜系统和在线全景展开过程的全景环形语义分割（PASS）框架来感知整个环境。为了促进 PASS 模型的训练，我们利用传统的 FoV 成像数据集，绕过了创建完全密集的全景注释所需的工作。为了始终如一地利用展开的全景图中丰富的上下文线索，我们调整了我们的实时 ERF-PSPNet 来预测不同片段中具有语义意义的特征图，并将它们融合以完成全景场景解析。创新在于网络自适应以实现平滑和无缝的分割，并结合一组扩展的异构数据增强来实现全景图像的鲁棒性。各种综合实验证明了在单个 PASS 中对现实世界周围感知的有效性，而适应提议对于最先进的高效网络非常积极。
使用具有优化超参数的 CNN 对多光谱 LiDAR 数据进行土地覆盖分类,多光谱激光雷达（Light Detection And Ranging）以其光谱和空间几何数据的完整性和一致性为特点，为土地覆盖分类提供了新的数据源。近年来，卷积神经网络（CNN）与传统的机器学习方法相比，由于其更强的特征学习和特征表达能力，在图像分类、目标检测、图像语义分割等方面取得了一系列突破。然而，传统的 CNN 模型存在一些问题，例如层数过多，导致计算成本更高。为了解决这个问题，我们提出了一种基于 CNN 的多光谱 LiDAR 土地覆盖分类框架，并分析其最佳参数以提高分类精度。该框架首先将多光谱 3D LiDAR 数据预处理为 2D 图像。接下来，构建具有七个基本功能层的CNN模型，并对其超参数进行全面讨论和优化。构建的具有优化超参数的 CNN 模型在 Titan 多光谱 LiDAR 数据上进行了测试，包括 532 nm、1064 nm 和 1550 nm 三个波长。大量实验表明，构建的具有优化超参数的 CNN 对于多光谱 LiDAR 土地覆盖分类任务是可行的。与经典的 CNN 模型（即 AlexNet、VGG16 和 ResNet50）以及我们之前的研究相比，我们构建的具有优化超参数的 CNN 模型在计算性能和分类精度方面具有优势。
Morpheus：天文图像数据像素级分析的深度学习框架,我们提出了 Morpheus，一种用于生成天文来源的像素级形态分类的新模型。 Morpheus 利用深度学习的进步，通过计算机视觉领域采用的语义分割算法，逐像素执行源检测、源分割和形态分类。通过在物体检测期间利用有关真实天文源通量的形态信息，Morpheus 显示出对源的误报识别的弹性。我们通过对五个 CANDELS 字段中的哈勃太空望远镜数据执行源检测、源分割、形态分类来评估 Morpheus，重点是 GOODS South 字段，并展示了在恢复已知 GOODS South 3D-HST 源方面的高度完整性，H < 26 AB。我们公开发布代码，提供在线演示，并在 GOODS South 中展示 Morpheus 结果的交互式可视化。
使用 ALS 点云进行城市分类的深度点嵌入：从局部到全局的新视角,3D 场景的语义解释是点云处理中最具挑战性的问题之一，这也被视为各种点云应用程序中的一项基本任务。语义解释的核心任务是语义标注，即为点云中的每个点获取唯一的语义标签。尽管有几种报道的方法，但由于场景的复杂性、各种尺度的对象以及不均匀分布点的非均匀性，语义标记仍然是一个挑战。在本文中，我们提出了一种获取机载激光扫描 (ALS) 点云语义标签的新方法，该方法包括通过多尺度深度学习、用于特征降维的非线性流形学习和全局图为每个点嵌入局部上下文信息。 - 优化分类结果。具体来说，我们解决了学习判别特征和全局标记平滑的任务。我们研究的主要贡献是三方面的。首先，应用分层数据增强策略，基于PointNet++网络增强对深度特征的学习，同时在处理大规模数据集时消除分割和采样造成的伪影。随后，学习到的分层深度特征被全局优化并嵌入到低维空间中，采用基于非线性流形的联合学习方法，去除冗余和干扰信息。最后，基于马尔可夫随机场算法进行图结构优化，通过构建加权间接图并使用图割解决优化问题，实现对使用嵌入深度特征获得的初始分类结果的全局优化。我们对 ALS 点云数据集进行了彻底的实验，以评估我们框架的性能。结果表明，与其他常用的高级分类方法相比，我们的方法可以实现较高的分类准确率。我们的方法在 ISPRS 基准数据集上的总体准确率 (OA) 可以扩展到 83.2%，以对九个语义类别进行分类，从而优于其他比较的基于点的策略。此外，我们在 AHN3 数据集的选定部分上评估了我们的框架，它提供了高达 91.2% 的 OA。
高分一号遥感影像的多尺度水提取卷积神经网络（MWEN）方法,自动水体提取方法对于监测洪水、干旱和水资源具有重要意义。在这项研究中，提出了一种新的语义分割卷积神经网络，称为多尺度水提取卷积神经网络（MWEN），用于从高分一号（GF-1）遥感图像中自动提取水体。使用三个用于语义分割的卷积神经网络（全卷积网络 (FCN)、Unet 和 Deeplab V3+）与 MWEN 的水体提取性能进行比较。视觉比较和五个评估指标用于评估这些卷积神经网络 (CNN) 的性能。结果显示如下。 (1) 使用 MWEN 进行多场景水体提取的结果优于其他基于指标的比较方法。 (2) MWEN方法具有准确提取各类水体的能力，如城市水体、露天池塘、高原湖泊等。 （3）通过融合不同尺度提取的特征，MWEN具有提取不同大小水体和抑制噪声的能力，例如建筑物阴影和高速公路。因此，MWEN是一种针对高分一号卫星图像的鲁棒水体提取算法，具有利用多源高分辨率卫星遥感数据进行水体测绘的潜力。
学习用于 3D 冠状动脉分割的树结构表示,广泛的研究致力于冠状动脉的分割。然而，由于其复杂的解剖结构，从 3D 冠状动脉计算机断层扫描血管造影 (CCTA) 中自动分割冠状动脉极具挑战性。受最近使用树结构长短期记忆 (LSTM) 对 NLP 任务的底层树结构建模的想法的启发，我们提出了一种新颖的树结构卷积门控循环单元 (ConvGRU) 模型来学习冠状动脉的解剖结构动脉。然而，与为自然语言处理中的语义相关性和情感分类提出的树结构 LSTM 不同，我们的树结构 ConvGRU 模型考虑了输入数据中的局部空间相关性，因为卷积用于输入到状态以及状态到状态的转换，因此更适合图像分析。为了进行体素分割，提出了一种树结构的分割框架。它由一个用于多尺度判别特征提取和最终预测的全卷积网络 (FCN) 和一个用于解剖结构建模的树结构 ConvGRU 层组成。所提出的框架在四个大型 3D CCTA 数据集（据我们所知最大的数据集）上进行了广泛评估，实验表明，与其他冠状动脉分割方法相比，我们的方法更准确、更有效。 (C) 2019 Elsevier Ltd. 保留所有权利。
使用 UAS 超空间图像进行高效土地覆盖制图的深度学习架构的审查和评估：湿地案例研究,深度学习已被证明是一种强大的先进技术，可用于计算机视觉和其他应用中的许多图像理解任务，包括遥感 (RS) 图像分析。无人机系统 (UAS) 为传统传感器和平台提供了一种可行且经济的替代方案，用于获取具有高操作灵活性的高空间和高时间分辨率数据。沿海湿地是土地覆盖预测和制图任务中最具挑战性和最复杂的生态系统之一，因为土地覆盖目标通常表现出较高的类内和低类间差异。近年来，已经提出了几种深度卷积神经网络（CNN）架构用于像素级图像标记，通常称为语义图像分割。在本文中，回顾了一些最近提出的用于语义图像分割的深度 CNN 架构，并通过在有限的标记图像集上对其进行训练来评估每个模型的训练效率和分类性能。使用湿地区域上的超空间分辨率 UAS 图像提供训练样本，并通过手动图像标记准备所需的地面真实图像。实验结果表明，深度 CNN 在使用 UAS 超空间分辨率图像进行准确的土地覆盖预测任务方面具有巨大潜力。一些简单的深度学习架构的性能与复杂且非常深的架构相当，甚至更好，而且训练时间显着减少。当可用的训练样本有限时，这种性能尤其有价值，这是大多数 RS 应用程序中的常见情况。
基于深度学习的黑色素瘤自动检测系统,黑色素瘤是最致命的皮肤癌。然而，区分黑色素瘤病变与非黑色素瘤病变一直是一项具有挑战性的任务。过去已经为此任务开发了许多计算机辅助诊断和检测系统。由于皮肤病变图像的复杂视觉特征（由不均匀的特征和模糊的边界组成），它们的性能受到限制。在本文中，我们提出了一种基于深度学习的方法，该方法克服了自动黑色素瘤病变检测和分割的这些限制。提出了一种增强的编码器-解码器网络，编码器和解码器子网络通过一系列跳过路径连接，使编码器特征图的语义水平更接近解码器特征图的语义水平，以实现高效的学习和特征提取。该系统采用多阶段和多尺度方法，并利用softmax分类器对黑色素瘤病变进行像素级分类。我们设计了一种称为病变分类器的新方法，该方法根据像素分类的结果将皮肤病变分类为黑色素瘤和非黑色素瘤。我们在两个完善的公共基准皮肤病变数据集上进行的实验，即国际生物医学成像研讨会 (ISBI)2017 和佩德罗伊斯帕诺医院 (PH2)，表明我们的方法比一些最先进的方法更有效。我们实现了 95 & x0025 的准确度和骰子系数；和 92 & x0025;在 ISIC 2017 数据集和 95 & x0025 的准确度和骰子系数上；和 93 & x0025;在 PH2 数据集上。
什么可以转移：内窥镜病变分割的无监督域适应,无监督域适应在语义分割方面引起了越来越多的研究关注。然而，1）由于同一病灶在不同数据集中的表现形式不同，大多数现有模型不能直接应用于医学图像的病灶转移； 2）对所有语义表示给予同等关注，而不是忽略不相关的知识，这导致不可迁移知识的负迁移。为了应对这些挑战，我们开发了一种新的无监督语义转移模型，包括两个互补模块（即 TD 和 TF），用于内窥镜病变分割，它可以替代地确定在哪里以及如何探索标记的源病变数据集（例如，胃镜）和未标记的目标疾病数据集（例如，肠镜检查）。具体来说，TD 侧重于通过剩余可转移性感知瓶颈在哪里翻译医学病变的可转移视觉信息，而忽略不可转移的视觉特征。此外，TF 强调了如何增强各种病变的可迁移语义特征并自动忽略不可迁移的表示，这探索了领域不变的知识，并反过来提高了 TD 的性能。最后，对医学内窥镜数据集和几个非医学公共数据集的理论分析和广泛实验很好地证明了我们提出的模型的优越性。
Line-CNN：使用线路建议单元的端到端交通线路检测,交通线路检测任务是一个基本但具有挑战性的问题。以前的方法通常通过两阶段的方式进行交通线路检测，即线段检测后进行段聚类，这很可能会忽略整条线路的全局语义信息。为了解决这个问题，我们提出了一个名为 Line-CNN (L-CNN) 的端到端系统，其中的关键组件是一个新颖的线路提议单元 (LPU)。 LPU 使用线路建议作为参考来定位准确的交通曲线，这迫使系统学习整个交通线路的全局特征表示。我们在包括 MIKKI 和 TuSimple 在内的两个公共数据集上对提议的 L-CNN 进行了基准测试，结果表明 L-CNN 优于最先进的方法。此外，L-CNN 可以在 Titan X GPU 上以大约 30 f/s 的速度运行，这表明 L-CNN 对于实时智能自动驾驶系统的实用性和有效性。
FCOS：一种简单而强大的无锚物体检测器,在计算机视觉中，对象检测是最重要的任务之一，它支撑着一些实例级识别任务和许多下游应用。最近，一阶段方法由于其更简单的设计和具有竞争力的性能而受到了比两阶段方法更多的关注。在这里，我们提出了一种完全卷积的单级目标检测器 (FCOS)，以按像素预测方式解决目标检测，类似于语义分割等其他密集预测问题。几乎所有最先进的目标检测器，如 RetinaNet、SSD、YOLOv3 和 Faster R-CNN 都依赖于预定义的锚框。相比之下，我们提出的检测器 FCOS 是无锚盒的，也无提议的。通过消除预定义的一组锚框，FCOS 完全避免了与锚框相关的复杂计算，例如在训练过程中计算 IoU 分数。更重要的是，我们还避免了所有与锚框相关的超参数，这些超参数通常对最终检测性能很敏感。通过唯一的后处理非最大抑制（NMS），我们展示了一个更简单灵活的检测框架，可以提高检测精度。我们希望提出的 FCOS 框架可以作为许多其他实例级任务的简单而强大的替代方案。代码位于：git。 io/阿德莱德
使用双任务约束的深度孪生卷积网络模型构建遥感图像的变化检测,"近年来，建筑变化检测方法通过引入深度学习取得了长足的进步，但仍然存在提取的特征判别力不够，导致区域不完整和边界不规则的问题。为了解决这个问题，我们提出了一个双任务约束的深度连体卷积网络（DTCDSCN）模型，它包含三个子网络：一个变化检测网络和两个语义分割网络。 DTCDSCN 可以同时完成变化检测和语义分割，有助于学习更具判别性的对象级特征，获得完整的变化检测图。此外，我们引入了双重注意模块（DAM）来利用通道和空间位置之间的相互依赖关系，从而改进了特征表示。我们还改进了焦点损失函数来抑制样本不平衡问题。使用 WHU 建筑数据集获得的实验结果表明，所提出的方法对于建筑变化检测是有效的，并且在 WHU 建筑数据集的四个指标方面达到了最先进的性能：精度、召回率、F1-score , 和并集上的交集。"
CrackGAN：使用基于生成对抗学习的部分准确地面实况的路面裂缝检测,全卷积网络是逐像素语义分割/检测的强大工具。然而，在使用部分准确的地面实况（GT）处理裂缝检测时存在问题：网络可能很容易收敛到将所有像素视为背景（BG）的状态，并且仍然实现了非常好的损失，称为全黑现象，由于无法获得准确的 GT 和数据不平衡。为了解决这个问题，我们提出了用于端到端训练的crack-patch-only (CPO) 监督生成对抗学习，它迫使网络始终生成crack-GT 图像，同时通过馈送保留crack 和BG-image 翻译能力将较大尺寸的裂纹图像转换为不对称的 U 形生成器，以克服全黑问题。使用四个裂纹数据集验证了所提出的方法；与最近发表的作品相比，在效率和准确性方面达到了最先进的性能。
通过将卷积神经网络与特征成对条件随机场 (FPCRF) 集成来构建足迹生成,建筑足迹图对于许多遥感 (RS) 应用至关重要，例如 3-D 建筑建模、城市规划和灾害管理。由于建筑物的复杂性，从 RS 图像准确可靠地生成建筑物足迹仍然是一项具有挑战性的任务。在本文中，提出了一种集成卷积神经网络（CNN）和图模型的端到端建筑足迹生成方法。 CNN作为特征提取器，而图模型可以考虑空间相关性。此外，我们建议将特征成对条件随机场（FPCRF）作为图模型来实现，以保持清晰的边界和细粒度的分割。实验在四个不同的数据集上进行：1）慕尼黑、巴黎、罗马和苏黎世城市的 Planetscope 卫星图像； 2) 来自波茨坦市的 ISPRS 基准数据； 3）Dstl Kaggle数据集； 4) 奥斯汀、芝加哥、基萨普县、西蒂罗尔和维也纳的 Inria 航空图像标注数据。发现提出的以 FPCRF 作为图模型的端到端建筑足迹生成框架可以进一步提高仅使用 CNN 生成建筑足迹的准确性，这是目前的技术水平。
精准农业中计算机视觉任务的公共数据集调查,近年来，计算机视觉技术引起了人们对精准农业的极大兴趣。作为机器人技术和人工智能的核心，计算机视觉使农作物生产周期中从种植到收获的各种任务能够自动高效地执行。然而，公共图像数据集的稀缺性仍然是针对目标任务的计算机视觉和机器学习算法的快速原型设计和评估的关键瓶颈。自 2015 年以来，已经建立并公开了许多图像数据集，以缓解这一瓶颈。尽管取得了这些进展，但仍然缺乏对这些数据集的专门调查。为了填补这一空白，本文首次全面回顾了在田间条件下为促进精准农业收集的公共图像数据集，其中包括 15 个杂草控制数据集、10 个水果检测数据集和 9 个杂项应用数据集。我们调查了这些数据集的主要特征和应用，并讨论了创建高质量公共图像数据集的关键考虑因素。这份调查论文对于研究界在选择合适的图像数据集进行算法开发和确定需要在哪里创建新的图像数据集以支持精准农业具有重要价值。
具有多尺度网格平均池的通道注意模块用于超声图像中的乳腺癌分割,乳腺癌是全球女性死亡人数第二多的原因，超过 8% 的女性在其一生中都会遭受这种疾病的折磨。由于乳腺癌的早期和精确诊断可以降低死亡率。许多研究已经研究了分割方法，尤其是基于深度学习技术的计算机辅助诊断最近受到了关注。然而，最近提出的全卷积网络（FCN）、SegNet 和 U-Net 等方法由于性能低下，在通过超声成像诊断乳腺癌时仍需要进一步改进，以提供更好的语义分割。在本文中，我们提出了一种具有多尺度网格平均池 (MSGRAP) 的通道注意模块，用于精确分割超声图像中的乳腺癌区域。我们证明了带有 MSGRAP 的通道注意模块对语义分割的有效性，并开发了一种新的语义分割网络，该网络使用所提出的注意模块来精确分割超声图像中的乳腺癌区域。虽然传统的卷积操作不能在输入图像上使用全局空间信息，而只能使用卷积滤波器内核中的小局部信息，但所提出的注意模块允许同时使用全局和局部空间信息。此外，通过消融研究，我们提出了一种用于在超声图像中精确分割乳腺癌的网络架构。所提出的网络是用开源的乳腺癌超声图像数据集构建的，并将其性能与其他用于乳腺癌分割的最先进的深度学习模型进行了比较。实验结果表明，我们的网络优于其他分割方法，所提出的通道注意模块提高了网络在超声图像中分割乳腺癌的性能。
嵌入注意力和残差网络以实现准确的显着目标检测,显着对象检测通常用作预处理步骤，以促进各种后续应用程序，这些应用程序应该花费很少的时间成本。随着最近深度学习的快速发展，取得了重大进展，以实现新的最先进的性能。然而，现有的基于深度学习的方法学习到的特征不够准确，导致在复杂场景中的检测效果不理想，例如显着对象与背景区域之间的对比度低或非常相似，以及具有不同特征的多个（小）显着对象。此外，通常需要一些后处理技术进行细化，这很耗时。为了解决这些问题，本文提出了一种高效的全卷积显着目标检测网络。具体来说，我们首先引入了一种视觉注意机制来指导侧输出层的特征学习。具体来说，注意力权重以自上而下的方式使用，可以桥接高级语义信息，以帮助浅层更好地定位显着对象，并滤除背景区域中的噪声响应。其次，我们提出了一个残差细化网络来逐步融合学习到的多级特征。不是像以前的工作那样简单地逐步添加或连接它们，我们将二阶项引入到元素相加中，以学习阶段残差特征以进行细化。这样的二阶项不仅有利于有效的梯度传播，而且还增加了网络的非线性。在七个标准基准上进行的大量实验表明，与最近的最新技术相比，所提出的方法在小显着目标检测方面表现出色，尤其是在结构测量指标方面。
使用 DCNN 预测距离图的航空图像语义分割,本文解决了使用深度卷积神经网络 (DCNN) 学习空间上下文以对高分辨率航空图像进行语义分割的挑战。所提出的解决方案包括从地面实况标签图中为每个语义类导出一个带符号的距离图，并训练一个 DCNN 来预测这个距离图，而不是每个类的分数图。由于目标像素与其最近对象边界之间的距离测量像素穿透对象的距离，因此距离图编码空间上下文，特别是空间平滑度。距离图中的正像素值对应于正确的类，负值对应于不正确的类。通过选择具有最大距离的类，从预测的距离图导出最终的标签图。由于距离图中的相邻像素具有相似的值，因此分割结果比当前方法更平滑。结果显示比使用完全连接的条件随机场 (CRF) 执行后处理更好，这是一种平滑分割产生的 DCNN 的常用方法。语义标记挑战数据集的实验结果表明，所提出的方法优于大多数最先进的方法。不过，我们的主要贡献是用距离图替换 DCNN 的逐像素类分数图的新想法。因此，这与最先进的方法所采用的其他技术是正交的和互补的，因此可以用来改进它们。
使用多模态传感器融合和语义分割稳定和验证 3D 对象位置,物体测量位置的稳定和验证过程是高级感知功能和正确处理感官数据的重要步骤。这个过程的目标是检测和处理不同传感器测量之间的不一致，这是由感知系统引起的。来自不同传感器的检测的聚合包括将传感器数据组合在一个公共参考框架中，用于每个识别的对象，从而创建一个超级传感器。数据聚合的结果可能会导致错误检测、错误放置的对象立方体或场景中对象数量不正确等错误。稳定和验证过程的重点是缓解这些问题。目前的论文提出了四项贡献，用于解决自动驾驶汽车的稳定和验证任务，使用以下传感器：三焦相机、鱼眼相机、远程雷达（无线电检测和测距）以及 4 层和 16 层激光雷达（光检测和测距）。我们提出了在传感器融合和跟踪过程中使用的两种原始数据关联方法。第一个数据关联算法是为跟踪 LIDAR 对象而创建的，它结合了多种外观和运动特征，以利用道路对象的可用信息。第二种新颖的数据关联算法是为三焦相机对象设计的，其目标是找到与传感器融合对象的测量对应关系，从而通过添加语义类信息来丰富超级传感器数据。实施的三焦点对象关联解决方案使用一种新颖的极性关联方案与决策树相结合，以找到最佳假设测量相关性。我们为稳定物体位置和道路物体的不可预测行为提出的另一项贡献是使用基于无味卡尔曼滤波器和单层感知器的融合方法，由多种类型的互补传感器提供。最后一个新颖的贡献与 3D 对象位置的验证有关，这是使用模糊逻辑技术结合语义分割图像来解决的。所提出的算法具有实时性，累计运行时间为 90 ms，并已使用从高精度 GPS（全球定位系统）中提取的地面实况数据进行评估，精度为 2 cm，平均误差为 0.8米。
基于深度学习的土地覆盖分类和目标检测方法在高分辨率遥感图像上的表现如何？,土地覆盖信息在绘制地球多样化景观的生态和环境变化以进行生态系统监测方面发挥着重要作用。遥感数据已被广泛用于土地覆盖研究，能够从太空有效地绘制地球表面变化的地图。尽管高分辨率遥感图像的可用性每年都在显着增加，但基于像素和对象级别的传统土地覆盖分析方法并不是最佳的。深度学习的最新进展在图像识别领域取得了显着的成功，并在包括分类和目标检测在内的高空间分辨率遥感应用中显示出潜力。在本文中，对使用高分辨率图像的土地覆盖分类和目标检测方法进行了全面回顾。通过两个案例研究，我们展示了最先进的深度学习模型在用于土地覆盖分类和物体检测的高空间分辨率遥感数据中的应用，并针对传统方法评估了它们的性能。对于土地覆盖分类任务，基于深度学习的方法通过使用空间和光谱信息提供端到端的解决方案。它们表现出比传统的基于像素的方法更好的性能，特别是对于不同植被的类别。对于目标检测任务，基于深度学习的目标检测方法在大范围内实现了 98% 以上的准确率；其高精度和高效率可以减轻传统劳动密集型方法的负担。然而，考虑到遥感数据的多样性，需要更多的训练数据集来提高基于深度学习的模型的泛化性和鲁棒性。
农业视觉：用于农业模式分析的大型航空影像数据库,"深度学习在视觉识别任务中的成功推动了多个研究领域的进步。特别是，越来越多地关注其在农业中的应用。然而，虽然农田的视觉模式识别具有巨大的经济价值，但由于缺乏合适的农业图像数据集，计算机视觉和作物科学的融合进展甚微。同时，农业中的问题也对计算机视觉提出了新的挑战。例如，航空农田图像的语义分割需要对具有极端注释稀疏性的超大尺寸图像进行推理。这些挑战在大多数常见对象数据集中都不存在，我们表明它们比许多其他航空影像数据集更具挑战性。为了鼓励对农业计算机视觉的研究，我们提出了农业视觉：用于农业模式语义分割的大规模航空农田图像数据集。我们从美国 3, 432 个农田收集了 94, 986 张高质量航空图像，其中每张图像由 RGB 和近红外 (NIR) 通道组成，分辨率高达每像素 10 厘米。我们注释了对农民最重要的九种田间异常模式。作为航空农业语义分割的试点研究，我们使用流行的语义分割模型进行了综合实验；我们还提出了一种为空中农业模式识别设计的有效模型。我们的实验展示了农业视觉对计算机视觉和农业社区提出的几个挑战。该数据集的未来版本将包括更多航拍图像、异常模式和图像通道。"
SalsaNext：LiDAR 点云的快速、不确定性感知语义分割,在本文中，我们介绍了 SalsaNext，用于实时对全 3D LiDAR 点云进行不确定性感知语义分割。 SalsaNext 是 SalsaNet [1] 的下一个版本，它具有编码器-解码器架构，其中编码器单元具有一组 ResNet 块，解码器部分结合来自残差块的上采样特征。与 SalsaNet 相比，我们引入了一个新的上下文模块，将 ResNet 编码器块替换为具有逐渐增加的感受野的新残差扩张卷积堆栈，并在解码器中添加像素混洗层。此外，我们从步幅卷积切换到平均池化，并且还应用了中央 dropout 处理。为了直接优化 Jaccard 指数，我们进一步结合了加权交叉熵损失和 Lovasz-Softmax 损失 [4]。我们最后注入贝叶斯处理来计算云中每个点的认知不确定性和任意不确定性。我们对 Semantic-KITTI 数据集 [3] 进行了全面的定量评估，这表明所提出的 SalsaNext 优于其他已发表的语义分割网络，并且比以前的最先进方法提高了 3.6% 的准确性。我们还发布了我们的源代码 (https://github.com/TiagoCortinhal/SalsaNext)。
PointGroup：用于 3D 实例分割的双设定点分组,实例分割是场景理解的一项重要任务。与完全开发的 2D 相比，点云的 3D 实例分割还有很大的改进空间。在本文中，我们介绍了 PointGroup，一种新的端到端自下而上架构，特别专注于通过探索对象之间的空隙空间来更好地对点进行分组。我们设计了一个双分支网络来提取点特征并预测语义标签和偏移量，以将每个点移向其各自的实例质心。遵循聚类组件以利用原始点坐标集和偏移偏移点坐标集，利用它们的互补优势。此外，我们制定了 ScoreNet 来评估候选实例，然后使用非最大抑制 (NMS) 来删除重复项。我们在两个具有挑战性的数据集 ScanNet v2 和 S3DIS 上进行了广泛的实验，在这两个数据集上，我们的方法实现了最高性能，分别为 63.6% 和 64.0%，而之前的最佳解决方案在 IoU 阈值为 0.5 的 mAP 方面实现了 54.9% 和 54.4%。
用于语义分割的门控完全融合,语义分割通过密集预测每个像素的类别来生成对场景的全面理解。来自深度卷积神经网络的高级特征已经证明了它们在语义分割任务中的有效性，但是高级特征的粗分辨率通常会导致细节信息很重要的小/薄对象的结果较差。考虑导入低级特征来弥补高级特征中丢失的详细信息是很自然的。不幸的是，简单地组合多级特征会受到它们之间的语义差距的影响。在本文中，我们提出了一种名为 Gated Fully Fusion (GFF) 的新架构，以完全连接的方式使用门选择性地融合来自多个级别的特征。具体来说，每个级别的特征都通过具有更强语义的高级特征和具有更多细节的低级特征来增强，并且使用门来控制有用信息的传播，从而显着降低融合过程中的噪声。我们在四个具有挑战性的场景解析数据集上实现了最先进的结果，包括 Cityscapes、Pascal Context、COCO-stuff 和 ADE20K。
