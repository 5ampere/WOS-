文章标题,抽象的
学习用于图分类的无回溯对齐空间图卷积网络,在本文中，我们开发了一种新颖的无回溯对齐空间图卷积网络（BASGCN）模型来学习图分类的有效特征。我们的想法是将任意大小的图转换为固定大小的无回溯对齐网格结构，并定义与网格结构相关的新空间图卷积操作。我们表明，所提出的 BASGCN 模型不仅减少了现有基于空间的图卷积网络 (GCN) 模型中出现的信息丢失和信息表示不精确的问题，而且弥合了传统卷积神经网络 (CNN) 模型与空间模型之间的理论鸿沟。 - 基于 GCN 模型。此外，所提出的 BASGCN 模型既可以在卷积过程中自适应地区分指定顶点之间的重要性，又可以减少与 Weisfeiler-Lehman 算法相关的现有基于空间的 GCN 的臭名昭著的摇摆问题，从而解释了所提出模型的有效性。标准图数据集的实验证明了所提出模型的有效性。
YOLACT plus plus 更好的实时实例分割,我们提出了一个简单的、完全卷积的实时（> 30 fps）实例分割模型，该模型在单个 Titan Xp 上评估的 MS COCO 上取得了具有竞争力的结果，这比以前任何最先进的方法都要快得多。此外，我们只在一个 GPU 上训练后获得了这个结果。我们通过将实例分割分解为两个并行的子任务来实现这一点：（1）生成一组原型掩码和（2）预测每个实例的掩码系数。然后我们通过将原型与掩码系数线性组合来生成实例掩码。我们发现，因为这个过程不依赖于 repooling，所以这种方法可以产生非常高质量的掩码，并免费表现出时间稳定性。此外，我们分析了原型的紧急行为，并表明它们学会了以翻译变体的方式自行定位实例，尽管它们是完全卷积的。我们还提出了 Fast NMS，它是标准 NMS 的快速替代品，速度快 12 毫秒，但性能损失很小。最后，通过在主干网络中加入可变形卷积，使用更好的锚尺度和纵横比优化预测头，并添加新的快速掩码重新评分分支，我们的 YOLACT++ 模型可以在 MS COCO 上以 33.5 fps 的速度实现 34.1 mAP，即非常接近最先进的方法，同时仍然实时运行。
ManifoldNet：具有应用程序的流形值数据的深度神经网络,几何深度学习是一个相对新生的领域，在过去几年中引起了极大的关注。这部分是由于从非欧几里得域获取的数据或从驻留在平滑流形上的欧几里得空间数据中提取的特征的可用性。例如，计算机视觉中常见的姿态数据位于李群中，而在许多领域中普遍存在的协方差矩阵和医学成像领域中遇到的扩散张量则位于对称正定矩阵的流形上。这些数据中的大部分自然表示为多值数据网格。在本文中，我们提出了一种新的理论框架，用于开发深度神经网络以应对这些多值数据输入网格。我们还提出了一种新颖的架构来实现这一理论，并将其称为 ManifoldNet。类似于向量空间，其中卷积等同于计算加权和，可以使用加权 Frechet Mean (wFM) 定义流形值数据“卷积”。 （这需要赋予流形一个黎曼结构，如果它还没有提供的话。） ManifoldNet 的隐藏层计算其输入的 wFM，其中要学习权重。这意味着数据在通过隐藏层传播时保持多值。为了降低计算复杂度，我们提出了一种可证明收敛的递归算法来计算 wFM。此外，我们证明了在非恒定截面曲率流形上，每个 wFM 层都是一个收缩映射，并为其分层堆叠时的不可塌陷性提供建设性证据。这捕获了深层网络层的两个基本属性。类似于欧几里得空间中卷积与平移的等变，我们证明了 wFM 与数据所在的黎曼流形所承认的一组等距的作用等变。为了展示 ManifoldNet 的性能，我们展示了几个使用计算机视觉和医学成像数据集的实验。
P-CNN：用于细粒度视觉分类的基于部分的卷积神经网络,本文提出了一种端到端的细粒度视觉分类系统，称为基于部分的卷积神经网络（P-CNN），它由三个模块组成。第一个模块是 Squeeze-and-Excitation (SE) 模块，它通过强调信息通道和抑制不太有用的通道来学习重新校准通道方面的特征响应。第二个模块是一个零件定位网络（PLN），用于定位不同的对象部分，通过它学习一组卷积滤波器作为区分部分检测器。因此，可以通过将特征图与每个部分检测器进行卷积来发现一组信息量大的部分。第三个模块是具有两个流的零件分类网络 (PCN)。第一个流将每个单独的对象部分分类为图像级类别。第二个流将部分特征和全局特征连接成一个联合特征，用于最终分类。为了学习强大的零件特征并提高联合特征能力，我们提出了一种用于度量学习和零件分类的 Duplex Focal Loss，其重点是训练困难的例子。我们进一步将 PLN 和 PCN 合并到一个统一的网络中，通过一种简单的训练技术进行端到端的训练过程。在三个基准数据集上进行的综合实验和与最先进方法的比较证明了我们提出的方法的有效性。
用于人员重新识别的姿势引导表示学习,人物图像表现出的大姿态变化和错位误差显着增加了人物重新识别（ReID）的难度。现有的工作通常应用额外的操作，如姿势估计、部分分割等，以缓解这些问题并提高行人表示的鲁棒性。在提高 ReID 准确性的同时，这些操作会引入相当大的计算开销，并使深度模型变得复杂且难以调整。为了追求更有效的解决方案，我们提出了一种由姿势不变特征（PIF）和局部描述特征（LDF）组成的部分引导表示（PGR）。我们称 PGR Part-Guided 是因为它是由本地部分线索训练和监督的。具体来说，PIF 近似于通过姿态估计和姿态归一化推断出的姿态不变表示。 LDF 通过近似通过身体区域分割学习的表示来关注有区别的身体部位。这样，额外的姿态提取仅在训练阶段引入以监督 PGR 的学习，而在测试阶段不需要进行特征提取。与最近在五个广泛使用的数据集上的工作进行的广泛比较证明了 PGR 具有竞争力的准确性和效率。
使用条件 Wasserstein 生成对抗网络在 Hilbert 超球面上生成动态面部表情,在这项工作中，我们提出了一种新颖的方法，用于在给定中性人脸图像的情况下生成六种基本面部表情的视频。我们建议通过将面部标志运动建模为编码为超球面上的点的曲线来利用面部几何形状。通过提出用于超球面运动生成的流形值 Wasserstein 生成对抗网络 (GAN) 的条件版本，我们学习了不同类别的面部表情动态分布，从中我们合成了新的面部表情动作。通过使用另一个条件生成对抗网络编辑纹理信息，可以将生成的运动转换为标志序列，然后转换为图像序列。据我们所知，这是第一个使用 GAN 探索多值表示以解决动态面部表情生成问题的工作。我们在两个公共数据集上定量和定性地评估我们提出的方法； Oulu-CASIA 和 MUG 面部表情。我们的实验结果证明了我们的方法在生成具有连续运动、逼真外观和身份保存的逼真视频方面的有效性。我们还展示了我们的动态面部表情生成、动态面部表情传输和数据增强框架的效率，以训练改进的情感识别模型。
DeFusionNET：通过递归融合和细化判别性多尺度深度特征进行散焦模糊检测,尽管在图像散焦模糊检测方面取得了巨大成功，但仍然存在一些未解决的挑战，例如背景杂波的干扰、尺度敏感性和模糊区域的边界细节缺失。为了解决这些问题，我们提出了一种深度神经网络，它可以反复融合和细化多尺度深度特征（DeFusionNet），用于散焦模糊检测。我们首先将 FCN 不同层的特征分别融合为浅层特征和语义特征。然后，融合的浅层特征被传播到深层以细化检测到的散焦模糊区域的细节，融合的语义特征被传播到浅层以帮助更好地定位模糊区域。融合和细化是反复进行的。为了缩小低级和高级特征之间的差距，我们在特征传播之前嵌入了一个特征适应模块，以利用互补信息并减少不同特征层的矛盾响应。由于不同的特征通道对检测模糊区域具有不同的辨别程度，我们设计了一个通道注意模块来选择辨别特征进行特征细化。最后，融合最后一个循环步骤的每一层的输出，得到最终结果。我们收集了一个新的数据集，其中包含各种具有挑战性的图像及其像素标注，以促进进一步的研究。对两个常用数据集和我们新收集的一个数据集进行了广泛的实验，以证明 DeFusionNet 的功效和效率。
用于组活动识别的相干约束图 LSTM,这项工作旨在通过探索人体运动特征来解决群体活动识别问题。传统方法认为，所有人的动作对群体活动的贡献是相同的，即抑制了一些相关动作对整个活动的贡献，同时夸大了一些不相关的动作。为了解决这个问题，我们提出了一个时空上下文相干性（STCC）约束和一个全局上下文相干性（GCC）约束，以分别捕获相关运动并量化它们对群体活动的贡献。基于此，我们提出了一种具有 STCC 和 GCC 的新型 Coherence Constrained Graph LSTM (CCG-LSTM)，通过对个体的相关运动进行建模，同时抑制不相关的运动，从而有效地识别群体活动。具体来说，为了捕捉相关运动，我们构建了具有时间置信门和空间置信门的 CCG-LSTM，以分别根据时间先前状态和空间相邻状态来控制记忆状态更新。此外，通过在每个时间步测量其自身与整个活动之间的一致性，采用注意力机制来量化某个运动的贡献。最后，我们在两个广泛使用的数据集上进行了实验，以说明所提出的 CCG-LSTM 与最先进的方法相比的有效性。
用于少镜头分割的先验引导特征富集网络,最先进的语义分割方法需要足够的标记数据才能获得良好的结果，并且在没有微调的情况下很难在看不见的类上工作。因此，为了解决这个问题，提出了少镜头分割，方法是学习一个模型，该模型可以快速适应具有少量标记支持样本的新类别。由于训练类的高级语义信息使用不当以及查询和支持目标之间的空间不一致，这些框架仍然面临着对看不见的类的泛化能力降低的挑战。为了缓解这些问题，我们提出了先验引导特征丰富网络（PFENet）。它由以下新颖设计组成：(1) 一种无需训练的先验掩码生成方法，不仅保留了泛化能力，还提高了模型性能；(2) 特征丰富模块 (FEM)，通过使用支持特征自适应丰富查询特征来克服空间不一致性和以前的面具。在 PASCAL-5(i) 和 COCO 上的大量实验证明，所提出的先验生成方法和 FEM 都显着改进了基线方法。我们的 PFENet 在没有效率损失的情况下也大大优于最先进的方法。令人惊讶的是，我们的模型甚至可以推广到没有标记支持样本的情况。
Softmax 嵌入的增强不变量和实例扩展特征,深度嵌入学习在学习判别特征表示中起着关键作用，在低维嵌入空间中，视觉上相似的样本被拉得更近，不相似的样本被推开。本文通过在不使用任何类别标签的情况下学习这种表示来研究无监督嵌入学习问题。这项任务面临两个主要挑战：从高度相似的细粒度类中挖掘可靠的正监督，以及推广到看不见的测试类别。为了近似类别监督学习中的正集中和负分离属性，我们使用实例监督引入了数据增强不变量和实例扩展特征。我们还设计了两种新的与领域无关的增强策略，以进一步扩展特征空间中的监督，使用小批量和增强特征来模拟大批量训练。为了学习这种表示，我们提出了一种新的实例方式的 softmax 嵌入，它直接使用二进制鉴别 softmax 编码对增强的实例特征进行优化。在可见和不可见的测试类别下，它以比现有方法更高的准确度显着加快了学习速度。即使没有对来自细粒度类别的样本进行预训练的网络，无监督嵌入也表现良好。我们还开发了一种使用分类监督的变体，即分类softmax嵌入，它在不使用任何辅助信息或限制样本挖掘的情况下实现了与现有技术相比具有竞争力的性能。
用于细粒度图像识别的分层深度点击特征预测,图像的点击特征，定义为图像在预定义词汇表上的点击频率向量，已知可有效减少细粒度图像识别的语义差距。不幸的是，用户点击频率数据在实践中通常是不存在的。从视觉特征预测点击特征仍然具有挑战性，因为图像的用户点击频率向量总是嘈杂且稀疏的。在本文中，我们通过集成稀疏约束和改进的 RELU 算子设计了一个分层深度词嵌入 (HDWE) 模型，以解决来自视觉特征的点击特征预测。 HDWE 是一种从粗到细的点击特征预测器，它是在包含点击信息的辅助图像数据集的帮助下学习的。因此，它可以发现单词语义的层次结构。我们在三只狗和一只鸟的图像数据集上评估 HDWE，其中 Clickture-Dog 和 Clickture-Bird 分别用作辅助数据集来提供点击数据。我们的实证研究表明，HDWE 具有 1) 更高的识别准确率，2) 更大的压缩比，以及 3) 良好的一次性学习能力和对未见类别的可扩展性。
用于细粒度图像描述的上下文感知视觉策略网络,随着视觉检测技术的成熟，我们更加雄心勃勃地用开放词汇、细粒度和自由形式的语言描述视觉内容，即图像字幕的任务。特别是，我们对生成更长、更丰富、更细粒度的句子和段落作为图像描述感兴趣。图像字幕可以转化为给定视觉内容的顺序语言预测任务，其中输出序列形成具有合理语法的自然语言描述。然而，现有的图像描述方法只关注语言策略而不是视觉策略，因此无法捕捉对组合推理至关重要的视觉上下文，例如对象关系（例如，人骑马）和视觉比较（例如，small(er)猫）。当生成较长的序列（例如段落）时，这个问题尤其严重。为了填补这一空白，我们提出了一个上下文感知视觉策略网络 (CAVP)，用于细粒度的图像到语言生成：图像句子字幕和图像段落字幕。在字幕过程中，CAVP 明确地将先前的视觉注意力视为上下文，并在给定当前视觉注意力的情况下决定上下文是否用于当前的单词/句子生成。与在每一步仅固定单个视觉区域的传统视觉注意机制相比，CAVP 可以随着时间的推移注意复杂的视觉组合。整个图像字幕模型——CAVP 及其后续的语言策略网络——可以通过使用 actor-critic 策略梯度方法进行有效的端到端优化。我们通过在 MS-COCO 和斯坦福字幕数据集上的最新性能，使用各种指标和定性视觉上下文的合理可视化，证明了 CAVP 的有效性。
使用点相关的动态环境中的 RGB-D SLAM,在本文中，提出了一种消除动态环境中运动物体影响的同时定位和建图（SLAM）方法。该方法利用地图点之间的相关性将属于静态场景的点和属于不同移动对象的点分成不同的组。首先使用 Delaunay 三角剖分从所有地图点创建稀疏图。在这个图中，顶点代表地图点，每条边代表相邻点之间的相关性。如果两点之间的相对位置随着时间的推移保持一致，则它们之间存在相关性，并且它们被认为是刚性地一起移动。如果不是，则认为它们没有相关性并位于不同的组中。在点相关优化过程中去除不相关点之间的边之后，剩余的图将运动对象的地图点与静态场景的地图点分开。假设最大的一组是可靠的静态地图点组。最后，仅使用这些点执行运动估计。所提出的方法针对 RGB-D 传感器实施，使用公共 RGB-D 基准进行评估，并在几个其他具有挑战性的环境中进行了测试。实验结果表明，所提出的 SLAM 方法可以在轻微和高度动态环境中实现鲁棒和准确的性能。与其他最先进的方法相比，所提出的方法可以提供具有竞争力的准确性和良好的实时性。
联合相机光谱响应选择和高光谱图像恢复,从单个 RGB 图像恢复高光谱图像 (HSI) 引起了很多关注，其性能最近被证明对相机光谱响应 (CSR) 很敏感。在本文中，我们提出了一种有效的基于卷积神经网络 (CNN) 的方法，该方法可以从候选数据集中联合选择最佳 CSR，并学习映射以从多芯片下使用该算法选择的相机捕获的单个 RGB 图像中恢复 HSI或单芯片设置。给定一个特定的 CSR，我们首先提出了一个 HSI 恢复网络，它解释了 HSI 的基本特征，包括光谱非线性映射和空间相似性。之后，我们将 CSR 选择层附加到恢复网络上，因此可以根据非负稀疏约束下的网络权重自动确定多芯片和单芯片设置下的最佳 CSR。三个高光谱数据集和两个相机光谱响应数据集的实验结果表明，我们的 HSI 恢复网络在定量指标和感知质量方面都优于最先进的方法，并且选择层始终返回与最佳一致的 CSR通过详尽的搜索确定。最后，我们证明了我们的方法在真实捕获系统中也能表现良好，并收集了一个高光谱花卉数据集来评估 HSI 恢复对分类问题的影响。
基于事件的愿景：调查,事件相机是仿生传感器，不同于传统帧相机：它们不是以固定速率捕获图像，而是异步测量每个像素的亮度变化，并输出对亮度变化的时间、位置和符号进行编码的事件流.与传统相机相比，事件相机具有吸引人的特性：高时间分辨率（大约为 μs）、非常高的动态范围（140 dB 对 60 dB）、低功耗和高像素带宽（大约 kHz）减少运动模糊。因此，事件相机在机器人和计算机视觉方面具有巨大的潜力，可以应对传统相机的挑战性场景，例如低延迟、高速和高动态范围。然而，需要新的方法来处理这些传感器的非常规输出，以释放它们的潜力。本文全面概述了新兴的基于事件的视觉领域，重点介绍了为解锁事件相机的突出特性而开发的应用程序和算法。我们从它们的工作原理、可用的实际传感器以及它们已用于的任务中介绍事件相机，从低级视觉（特征检测和跟踪、光流等）到高级视觉（重建、分割、识别）。我们还讨论了为处理事件而开发的技术，包括基于学习的技术，以及用于这些新型传感器的专用处理器，例如脉冲神经网络。此外，我们强调了仍有待解决的挑战以及在寻找一种更有效的、受生物启发的方式让机器感知世界并与世界互动的过程中所面临的机遇。
BDCN：用于感知边缘检测的双向级联网络,利用多尺度表示对于改进不同尺度对象的边缘检测至关重要。为了在显着不同的尺度上提取边缘，我们提出了一种双向级联网络 (BDCN) 架构，其中单个层由其特定尺度的标记边缘进行监督，而不是直接将相同的监督应用于不同的层。此外，为了丰富 BDCN 每一层学习的多尺度表示，我们引入了尺度增强模块 (SEM)，它利用扩张卷积来生成多尺度特征，而不是使用更深的 CNN。这些新方法鼓励学习不同层中的多尺度表示，并检测由它们的尺度很好地描绘的边缘。学习规模专用层还导致具有一小部分参数的紧凑网络。我们在三个数据集上评估我们的方法，即 BSDS500、NYUDv2 和 Multicue，并实现了 0.832 的 ODS F-measure，比 BSDS500 数据集上的当前最先进水平高 2.7%。我们还将边缘检测结果应用于其他视觉任务。实验结果表明，我们的方法进一步提高了图像分割、光流估计和目标建议生成的性能。
AlignSeg：特征对齐的分割网络,根据不同的卷积块或上下文嵌入来聚合特征已被证明是增强语义分割的特征表示的有效方法。然而，目前大多数流行的网络架构往往会忽略逐步下采样操作和不加选择的上下文信息融合导致的特征聚合过程中的错位问题。在本文中，我们探讨了解决此类特征错位问题的原理，并创造性地提出了特征对齐分割网络（AlignSeg）。 AlignSeg 由两个主要模块组成，即对齐特征聚合（AlignFA）模块和对齐上下文建模（AlignCM）模块。首先，AlignFA采用简单的可学习插值策略来学习像素的变换偏移量，可以有效缓解多分辨率特征聚合带来的特征错位问题。其次，有了上下文嵌入，AlignCM 使每个像素能够自适应地选择私有自定义上下文信息，从而使上下文嵌入更好地对齐。我们通过在 Cityscapes 和 ADE20K 上的广泛实验验证了我们的 AlignSeg 网络的有效性，分别实现了 82.6% 和 45.95% 的新的最先进的 mIoU 分数。
SimVODIS：同步视觉里程计、对象检测和实例分割,智能代理需要了解周围环境，才能为人类提供有意义的服务或与人类进行智能交互。代理应该感知环境中固有的几何特征和语义实体。现代方法通常一次只提供一种关于环境的信息，因此难以执行高级任务。此外，运行两种类型的方法并将两种结果信息关联起来需要大量计算并使软件架构复杂化。为了克服这些限制，我们提出了一种在单个线程中同时执行几何和语义任务的神经架构：同时视觉里程计、对象检测和实例分割 (SimVODIS)。 SimVODIS 建立在以监督方式训练的 Mask-RCNN 之上。训练 SimVODIS 的姿势和深度分支需要未标记的视频序列，并且输入图像帧之间的光度一致性会产生自监督信号。 SimVODIS 的性能在姿态估计、深度图预测、对象检测和实例分割任务中优于或匹配最先进的性能，同时在单个线程中完成所有任务。我们期望 SimVODIS 能够增强智能代理的自主性，让代理为人类提供有效的服务。
多视图聚类：一种可扩展且无参数的二部图融合方法,多视图聚类根据数据的异构特征将数据划分为不同的组。由于各种正则化项触发的难以处理的超参数，大多数现有方法会降低模型的适用性。此外，传统的基于谱的方法总是遇到昂贵的时间开销，并且无法从图中探索显式集群。在本文中，我们提出了一种用于多视图聚类的可扩展且无参数的图融合框架，以自监督加权方式寻求跨多个视图兼容的联合图。我们的公式直接合并多个视图图，并交互式地学习权重和联合图，这可以主动地将模型从任何与权重相关的超参数中释放出来。同时，我们通过连接约束来操纵联合图，使得连接的组件直接指示集群。所设计的算法与初始化无关且时间经济，获得了稳定的性能并且可以很好地适应数据大小。对玩具数据和真实数据集进行了大量实验，验证了所提出的方法与现有技术相比在聚类性能和时间消耗方面的优越性。
从未标记的视频中学习面部动作的表示,面部动作通常被编码为基于解剖学的动作单元（AU），其标签需要专业知识，因此既耗时又昂贵。为了减轻标记需求，我们建议通过提出双周期自动编码器（TAE）来利用大量未标记的视频来学习面部动作的判别表示。 TAE 受到以下事实的启发：面部动作嵌入在视频中两个连续的面部图像（以下称为源和目标）之间的像素位移中。因此，学习面部动作的表示可以通过学习位移的表示来实现。然而，面部动作引起的位移与头部运动引起的位移纠缠在一起。因此，通过在面部动作或头部姿势发生变化时评估合成图像的质量，TAE 被训练以解开这两种运动，旨在重建目标图像。 AU 检测实验表明，TAE 可以达到与其他现有 AU 检测方法（包括一些监督方法）相当的精度，从而验证了 TAE 学习到的表示的判别能力。通过可视化生成的图像并定性和定量地分析面部图像检索结果，也验证了 TAE 将动作诱导和姿势诱导运动解耦的能力。
索引网络,我们展示了卷积网络中现有的上采样算子可以使用索引函数的概念来统一。这个概念的灵感来自于在深度图像抠图解码过程中的观察，其中索引引导的反池化通常可以比其他上采样算子（例如双线性插值）更好地恢复边界细节。通过将索引视为特征图的函数，我们引入了“学习索引”的概念，并提出了一种新颖的索引引导编码器-解码器框架，其中索引从数据中自适应地学习并用于指导下采样和上采样阶段，无需额外的培训监督。该框架的核心是一个新的可学习模块，称为索引网络 (IndexNet)，它根据特征图动态生成索引。 IndexNet 可以作为插件使用，适用于几乎所有具有耦合下采样和上采样阶段的卷积网络，使网络能够动态捕获局部模式的变化。特别是，我们实例化并研究了 IndexNet 的五个系列。我们通过对合成数据的实验强调了它们在提供空间信息方面优于其他上采样算子的优势，并证明了它们在四个密集预测任务上的有效性，包括图像抠图、图像去噪、语义分割和单目深度估计。代码和模型可在 https://git.io/IndexNet
MRA-Net：通过多模态关系注意网络改进 VQA,视觉问答（VQA）是一项回答与视觉图像内容相关的自然语言问题的任务。大多数最近的 VQA 方法通常应用注意力机制来关注相关的视觉对象和/或通过视觉关系推理中的现成方法考虑对象之间的关系。然而，它们仍然存在一些缺点。首先，他们大多对对象之间的简单关系进行建模，这导致许多复杂的问题由于未能提供足够的知识而无法正确回答。其次，他们很少利用视觉外观特征和关系特征的和谐合作。为了解决这些问题，我们提出了一种新颖的端到端 VQA 模型，称为多模态关系注意网络 (MRA-Net)。所提出的模型探索文本和视觉关系以提高性能和可解释性。具体来说，我们设计了 1）一种自我引导的词关系注意方案，它探索了词之间的潜在语义关系； 2）两个自适应问题的视觉关系注意模块，不仅可以提取对象之间细粒度和精确的二元关系，还可以提取更复杂的三元关系。两种与问题相关的视觉关系都提供了更多、更深层次的视觉语义，从而提高了问答的视觉推理能力。此外，该模型还将外观特征与关系特征相结合，有效地协调了这两种类型的特征。在五个大型基准数据集 VQA-1.0、VQA-2.0、COCO-QA、VQA-CP v2 和 TDIUC 上进行的大量实验表明，我们提出的模型优于最先进的方法。
用于数据聚类的鲁棒双随机图正则化矩阵分解,"数据聚类，即将给定的数据划分为不同的组，引起了很多关注。最近已经开发了各种有效的算法来解决该任务。在这些方法中，非负矩阵分解（NMF）已被证明是一种强大的工具。但是，仍然存在一些问题。首先，标准 NMF 对噪声和异常值很敏感。虽然基于 l(2,1) 范数的 NMF 提高了鲁棒性，但它仍然容易受到大噪声的影响。其次，对于大多数图正则化 NMF，性能高度依赖于初始相似度图。第三，许多基于图的 NMF 模型分两个独立的步骤执行图构建和矩阵分解。因此，学习到的图结构可能不是最优的。为了克服上述缺点，我们提出了一种用于数据聚类的鲁棒双随机图正则化矩阵分解（RBSMF）框架。具体来说，我们提出了一个通用的损失函数，它比常用的 L-2 和 L-1 函数更健壮。此外，我们不是保持图形固定，而是学习自适应相似度图。此外，图更新和矩阵分解是同时处理的，这可以使学习到的图更适合聚类。大量实验表明，所提出的 RBSMF 优于其他最先进的方法。"
Ball k-Means：无边界快速自适应聚类,本文提出了一种新的加速精确k-means，称为Ball k-means，通过使用球来描述每个集群，其重点是减少点-质心距离计算。 Ball k-means 可以准确地找到每个集群的相邻集群，从而仅计算一个点与其相邻集群的质心而不是所有质心之间的距离计算。更重要的是，每个簇可以分为稳定区和活动区，后者又进一步划分为一些精确的环形区。稳定区域内的点分配不变，而每个环形区域内的点将在几个相邻簇内进行调整。整个过程没有上限或下限。此外，球 k-means 使用球簇和邻居搜索以及多种新策略来减少质心距离计算。与当前最先进的加速精确有界方法、阴阳算法和指数算法以及其他基于树和有界的顶级方法相比，球 k-means 获得了更高的性能并执行较少的距离计算，尤其是对于大 k 问题。 Ball k-means更快的速度，没有额外的参数和更简单的设计，使其成为naive k-means的全面替代品。
U2Fusion：一个统一的无监督图像融合网络,本研究提出了一种新颖的统一且无监督的端到端图像融合网络，称为 U2Fusion，能够解决不同的融合问题，包括多模态、多曝光和多焦点情况。通过特征提取和信息测量，U2Fusion 自动估计相应源图像的重要性并得出自适应信息保存度。因此，不同的融合任务统一在同一个框架中。基于自适应度，训练网络以保持融合结果与源图像之间的自适应相似性。因此，将深度学习应用于图像融合的绊脚石，例如对真实数据和专门设计的指标的要求，得到了极大的缓解。通过避免在顺序训练不同任务的单个模型时丢失先前的融合能力，我们获得了适用于多个融合任务的统一模型。此外，还发布了一个新的对齐红外和可见图像数据集 RoadScene（可在 https://github.com/hanna-xu/RoadScene 获得），为基准评估提供了一个新选项。在三个典型图像融合任务上的定性和定量实验结果验证了 U2Fusion 的有效性和普遍性。我们的代码在 https://github.com/hanna-xu/U2Fusion 上公开可用。
用于基于骨架的动作识别的反馈图卷积网络,基于骨架的动作识别已经引起了相当大的关注，因为骨架数据比其他模态更能适应动态环境和复杂的背景。最近，许多研究人员使用图卷积网络（GCN）通过端到端优化来模拟骨架序列的时空特征。然而，传统的 GCN 是前馈网络，因此较浅的层无法访问高层的语义信息。在本文中，我们提出了一种新颖的网络，称为反馈图卷积网络（FGCN）。这是第一个将反馈机制引入 GCN 以进行动作识别的工作。与传统的 GCN 相比，FGCN 具有以下优点：（1）设计了多阶段的时间采样策略，以从粗到细的过程中提取动作识别的时空特征； (2) 提出了一种反馈图卷积块 (FGCB)，将密集的反馈连接引入 GCN。它将高级语义特征传输到较浅层，并逐步传达时间信息，以对视频级时空特征进行建模以进行动作识别； (3) FGCN 模型提供即时预测。在早期，它的预测比较粗略。这些粗略的预测被视为先验，以指导后期的特征学习，以获得更准确的预测。在三个数据集 NTU-RGB+D、NTU-RGB+D120 和 Northwestern-UCLA 上的广泛实验表明，所提出的 FGCN 对动作识别是有效的。它在所有三个数据集上都达到了最先进的性能。
迈向年龄不变的人脸识别,尽管人脸识别相关技术取得了显着进步，但可靠地识别跨年龄的人脸仍然是一个巨大的挑战。随着时间的推移，人脸的外观会发生很大变化，从而导致显着的类内变化。与当前的年龄不变人脸识别技术相反，后者要么直接提取年龄不变特征进行识别，要么在特征提取之前首先合成与目标年龄相匹配的人脸，我们认为更可取的是联合执行这两项任务，以便他们可以互相利用。为此，我们提出了一种深度的年龄不变模型（AIM），用于野外人脸识别，具有三个不同的新颖性。首先，AIM 提出了一种新颖的统一深度架构，以相互促进的方式联合进行跨年龄的人脸合成和识别。其次，AIM 实现了持续的面部年轻化/老化，具有显着的逼真和身份保持特性，避免了配对数据的要求和测试样本的真实年龄。第三，为整个深度架构的端到端学习开发了有效且新颖的训练策略，该策略生成了强大的年龄不变的人脸表示，明确地摆脱了年龄变化。此外，我们构建了一个新的大规模跨年龄人脸识别 (CAFR) 基准数据集，以促进现有工作并推动年龄不变人脸识别研究的前沿。在我们的 CAFR 数据集和其他几个跨年龄数据集（MORPH、CACD 和 FG-NET）上进行的广泛实验证明了所提出的 AIM 模型优于最先进的模型。在流行的无约束人脸识别数据集 YTF 和 IJB-C 上对我们的模型进行基准测试，还验证了其在野外识别人脸方面有前景的泛化能力。
用于半监督少镜头视频分类的标签独立记忆,在本文中，我们建议利用免费可用的未标记视频数据来促进少镜头视频分类。在这个半监督的少镜头视频分类任务中，训练期间的每一集都有数百万未标记的数据可用。这些视频可能非常不平衡，但它们具有深刻的视觉和运动动态。为了解决半监督的少镜头视频分类问题，我们做出了以下贡献。首先，我们提出了一个标签无关内存（LIM）来缓存标签相关的特征，这使得对大量视频的相似性搜索成为可能。 LIM 为小样本训练生成了一个类原型。这个原型是每个类的聚合嵌入，对嘈杂的视频特征更加鲁棒。其次，我们集成了一个多模态复合记忆网络来捕获 RGB 和流信息。我们建议将 RGB 和流表示存储在两个独立的内存网络中，但它们是通过统一损失联合优化的。通过这种方式，利用两种模式之间的相互通信来实现更好的分类性能。第三，我们对小样本 Kinetics-100、Something-Something-100 数据集进行了广泛的实验，验证了利用可访问的未标记数据进行小样本分类的有效性。
3D 点云的深度学习：调查,点云学习最近因其在计算机视觉、自动驾驶和机器人技术等许多领域的广泛应用而受到越来越多的关注。作为人工智能的主导技术，深度学习已成功用于解决各种二维视觉问题。然而，由于使用深度神经网络处理点云所面临的独特挑战，点云的深度学习仍处于起步阶段。最近，点云的深度学习变得更加蓬勃发展，提出了许多方法来解决该领域的不同问题。为了激发未来的研究，本文全面回顾了点云深度学习方法的最新进展。它涵盖了三个主要任务，包括 3D 形状分类、3D 对象检测和跟踪以及 3D 点云分割。它还展示了几个公开可用的数据集的比较结果，以及有见地的观察和启发未来的研究方向。
深度神经网络的自我监督视觉特征学习：一项调查,通常需要大规模标记数据来训练深度神经网络，以便在计算机视觉应用中从图像或视频中获得更好的视觉特征学习性能。为了避免收集和注释大规模数据集的大量成本，作为无监督学习方法的一个子集，自监督学习方法被提出来从大规模未标记数据中学习一般图像和视频特征，而不使用任何人工注释标签。本文对基于深度学习的图像或视频自监督通用视觉特征学习方法进行了广泛的回顾。首先，描述了该领域的动机、一般流程和术语。然后总结了用于自监督学习的常见深度神经网络架构。接下来，回顾了自监督学习方法的模式和评估指标，然后是图像、视频、音频和 3D 数据的常用数据集，以及现有的自监督视觉特征学习方法。最后，总结和讨论了基准数据集上审查方法的定量性能比较，用于图像和视频特征学习。最后，本文总结并列出了一组有前途的自监督视觉特征学习的未来方向。
规范化流程：当前方法的介绍和回顾,归一化流是生成模型，可产生易于处理的分布，其中采样和密度评估都可以高效且准确。这篇综述文章的目的是对有关构建和使用规范化流进行分布学习的文献进行连贯而全面的回顾。我们的目标是提供模型的背景和解释，回顾当前最先进的文献，并确定悬而未决的问题和有希望的未来方向。
域自适应的最大密度散度,无监督域适应解决了将知识从标记良好的源域转移到未标记的目标域的问题，其中两个域具有不同的数据分布。因此，域适应的本质是减轻两个域之间的分布差异。最先进的方法通过进行对抗训练或最小化定义分布差距的指标来实践这个想法。在本文中，我们提出了一种新的域适应方法，称为对抗性紧密匹配（ATM），它同时具有对抗性训练和度量学习的好处。具体来说，首先，我们提出了一种新的距离损失，称为最大密度散度 (MDD)，以量化分布散度。 MDD 最小化域间分歧（在 ATM 中匹配）并最大化类内密度（在 ATM 中紧密）。然后，为了解决对抗域适应中的平衡挑战问题，我们考虑将提出的 MDD 用于对抗域适应框架。最后，我们将提议的 MDD 定制为实际的学习损失并报告我们的 ATM。实证评估和理论分析都被报告以验证所提出方法的有效性。在经典和大规模四个基准上的实验结果表明，我们的方法能够在大多数评估中实现新的最先进的性能。
单幅图像去雨：从基于模型到数据驱动及其他,单幅图像去雨的目标是恢复因雨水条纹和雨水积累而退化的图像的无雨背景场景。早期的单图像去雨方法采用成本函数，其中开发了各种先验来表示雨层和背景层的属性。自 2017 年以来，单图像去雨方法进入深度学习时代，并利用各种类型的网络，即卷积神经网络、循环神经网络、生成对抗网络等，表现出令人印象深刻的性能。鉴于当前的快速发展，在本文中，我们对过去十年的排水方法进行了全面调查。我们总结了降雨模型，并讨论了两类去雨方法：基于模型的方法和数据驱动的方法。对于前者，我们根据其基本模型和先验组织文献。对于后者，我们讨论了与架构、约束、损失函数和训练数据集相关的开发思想。我们介绍了单图像去雨方法的里程碑，回顾了不同类别的大量先前工作，并提供了从基于模型到数据驱动方法的历史发展路线的见解。我们还定量和定性地总结了性能比较。除了讨论排水方法的技术性之外，我们还讨论了未来可能的方向。
开放集识别的最新进展：一项调查,在现实世界的识别/分类任务中，受各种客观因素的限制，在训练识别器或分类器时，通常很难收集训练样本以耗尽所有类别。更现实的场景是开放集识别（OSR），在训练时存在对世界的不完整知识，在测试期间可以将未知类提交给算法，要求分类器不仅要准确分类看到的类，还要有效处理看不见的人。本文对现有的开放集识别技术进行了全面的调查，涵盖了相关定义、模型表示、数据集、评估标准和算法比较等各个方面。此外，我们简要分析了 OSR 与其相关任务之间的关系，包括零样本、单样本（few-shot）识别/学习技术、带有拒绝选项的分类等。此外，我们还回顾了开放世界识别，它可以被视为 OSR 的自然延伸。重要的是，我们强调了现有方法的局限性，并指出了该领域一些有前途的后续研究方向。
目标检测中的不平衡问题：综述,在本文中，我们对目标检测中的不平衡问题进行了全面回顾。为了系统地分析问题，我们引入了基于问题的分类法。按照这种分类法，我们深入讨论每个问题，并对文献中的解决方案提出一个统一但批判性的观点。此外，我们确定了有关现有不平衡问题以及以前未讨论过的不平衡问题的主要未解决问题。此外，为了使我们的评论保持最新，我们提供了一个随附的网页，该网页根据我们基于问题的分类法对解决不平衡问题的论文进行了分类。研究人员可以在此网页上跟踪更新的研究，网址为：https://github.com/kemaloksuz/ObjectDetectionImbalance。
用于视觉识别的深度高分辨率表示学习,高分辨率表示对于位置敏感的视觉问题至关重要，例如人体姿态估计、语义分割和对象检测。现有的最先进的框架首先通过一个子网络将输入图像编码为低分辨率表示，该子网络通过串联连接高分辨率到低分辨率的卷积（例如，ResNet、VGGNet）形成，然后恢复高分辨率- 来自编码的低分辨率表示的分辨率表示。相反，我们提出的网络，称为高分辨率网络（HRNet），在整个过程中保持高分辨率表示。有两个关键特征：（i）并行连接从高分辨率到低分辨率的卷积流，以及（ii）跨分辨率重复交换信息。好处是生成的表示在语义上更丰富，在空间上更精确。我们展示了所提出的 HRNet 在广泛的应用中的优越性，包括人体姿态估计、语义分割和对象检测，这表明 HRNet 是计算机视觉问题的更强大的主干。所有代码都可以在 https://github.com/HRNet 上找到。
图像超分辨率的深度学习：一项调查,图像超分辨率（SR）是一类重要的图像处理技术，用于提高计算机视觉中图像和视频的分辨率。近年来，使用深度学习技术在图像超分辨率方面取得了显着进展。本文旨在对使用深度学习方法的图像超分辨率的最新进展进行全面调查。一般来说，我们可以将现有的 SR 技术研究大致分为三大类：有监督的 SR、无监督的 SR 和特定领域的 SR。此外，我们还涵盖了一些其他重要问题，例如公开可用的基准数据集和性能评估指标。最后，我们通过强调几个未来的方向和未解决的问题来结束这项调查，这些问题应该由社区在未来进一步解决。
使用 Haze-Line 和新的定量数据集的水下单图像颜色恢复,水下图像存在色彩失真和对比度低的问题，因为光在水中传播时会衰减。水下的衰减随波长而变化，这与假设衰减是光谱均匀的地面图像不同。衰减取决于水体和场景的 3D 结构，使得色彩还原变得困难。与现有的单一水下图像增强技术不同，我们的方法考虑了不同水类型的多个光谱剖面。通过仅估计两个额外的全局参数：蓝红和蓝绿颜色通道的衰减率，问题被简化为单个图像去雾，其中所有颜色通道具有相同的衰减系数。由于水的类型未知，我们从现有的水类型库中评估不同的参数。每种类型都会导致不同的恢复图像，并根据颜色分布自动选择最佳结果。我们还提供了一个包含在不同位置拍摄的 57 张图像的数据集。为了获得基本事实，我们在场景中放置了多个颜色图表，并使用立体成像计算了它的 3D 结构。该数据集首次能够对自然图像上的恢复算法进行严格的定量评估。
高效有效的正则化不完全多视图聚类,不完整多视图聚类 (IMVC) 优化组合多个预先指定的不完整视图以提高聚类性能。在各种优秀的解决方案中，最近提出的具有不完整核的多核 k-means (MKKM-IK) 形成了一个基准，它将 IMVC 重新定义为一个联合优化问题，其中聚类和核矩阵插补任务交替执行直到收敛。尽管在各种应用中展示了有希望的性能，但我们观察到 MKKM-IK 中的核矩阵插补方式会导致密集的计算和存储复杂性、过度复杂的优化和有限的聚类性能提升。在本文中，我们首先提出了一种高效且有效的不完整多视图聚类（EE-IMVC）算法来解决这些问题。 EE-IMVC 不是完成不完整的核矩阵，而是建议将不完整视图生成的每个不完整基础矩阵与学习的共识聚类矩阵进行归类。此外，我们通过结合先验知识对学习的共识聚类矩阵进行正则化，进一步改进了该算法。精心开发了两种三步迭代算法来解决具有线性计算复杂度的优化问题，并在理论上证明了它们的收敛性。之后，我们从理论上研究了所提出算法的泛化界限。此外，我们进行了综合实验，从聚类准确性、学习共识聚类矩阵的演变和收敛性方面研究所提出的算法。如前所述，我们的算法通过显着且始终如一地优于一些最先进的算法来提供其有效性。
定位、大小和计数：通过检测准确解决密集人群中的人员,我们引入了用于密集人群计数的检测框架，并消除了对流行的密度回归范式的需求。典型的计数模型预测图像的人群密度，而不是检测每个人。通常，这些回归方法对于除计数之外的大多数应用程序而言，无法足够准确地定位人员。因此，我们采用了一种架构，该架构可以定位人群中的每个人，用边界框调整发现的头部大小，然后对它们进行计数。与普通物体或人脸检测器相比，设计这种检测系统存在一些独特的挑战。其中一些是密集人群的巨大多样性以及连续预测框的需要的直接后果。我们解决了这些问题并开发了我们的 LSC-CNN 模型，该模型可以可靠地检测从稀疏人群到密集人群的人头。 LSC-CNN 采用具有自上而下特征调制的多列架构来更好地分辨人物并在多个分辨率下产生精细的预测。有趣的是，所提出的训练方案只需要点头部注释，但可以估计头部的近似大小信息。我们表明，LSC-CNN 不仅比现有的密度回归器具有更好的定位，而且在计数方面也表现出色。我们方法的代码可在 https://github.com/val-iisc/lsc-cnn 获得。
从点到部分：使用部分感知和部分聚合网络从点云进行 3D 对象检测,LiDAR 点云的 3D 对象检测是 3D 场景理解中的一个具有挑战性的问题，具有许多实际应用。在本文中，我们将我们的初步工作 PointRCNN 扩展到一个新颖且强大的基于点云的 3D 对象检测框架，即部分感知和聚合神经网络（Part-A(2) 网络）。整个框架由部分感知阶段和部分聚合阶段组成。首先，部分感知阶段首次充分利用从 3D 真实框派生的免费部分监督，同时预测高质量的 3D 提议和准确的对象内部分位置。同一提案中预测的对象内部分位置由我们新设计的 RoI 感知点云池模块分组，从而有效地表示来编码每个 3D 提案的几何特定特征。然后，部分聚合阶段通过探索池化的对象内部分位置的空间关系来学习对框进行重新评分并细化框位置。进行了广泛的实验以证明我们提出的框架的每个组件的性能改进。我们的 Part-A(2) 网络优于所有现有的 3D 检测方法，并通过仅利用 LiDAR 点云数据在 KITTI 3D 对象检测数据集上实现了新的最新技术。
深度 CNN 遇到全局协方差池：更好的表示和泛化,与现有深度卷积神经网络（CNN）中的全局平均池相比，全局协方差池可以捕获更丰富的深度特征统计信息，具有提高深度 CNN 的表示和泛化能力的潜力。然而，将全局协方差池集成到深度 CNN 中带来了两个挑战：（1）给定高维和小样本量的深度特征的稳健协方差估计； (2) 协方差几何的适当使用。为了应对这些挑战，我们提出了一个全局矩阵功率归一化协方差 (MPN-COV) 池化。我们的 MPN-COV 符合稳健的协方差估计器，非常适合高维和小样本量的场景。它也可以被视为协方差之间的幂欧几里得度量，有效地利用了它们的几何形状。此外，提出了一个全局高斯嵌入网络，将一阶统计数据纳入 MPN-COV。为了快速训练 MPN-COV 网络，我们实现了迭代矩阵平方根归一化，避免了 MPN-COV 固有的 GPU 不友好的特征分解。此外，引入了渐进式 1 x 1 卷积和组卷积来压缩协方差表示。所提出的方法是高度模块化的，很容易插入现有的深度 CNN。在大规模对象分类、场景分类、细粒度视觉识别和纹理分类方面进行了广泛的实验，表明我们的方法优于同类方法并获得了最先进的性能。
学习适应记忆中的不变性以进行人员重新识别,这项工作考虑了人员重新识别（re-ID）中的无监督域适应问题，旨在将知识从源域转移到目标域。现有方法主要用于减少域之间的域间偏移，但通常忽略目标样本之间的关系。本文研究了目标域的域内变化，并提出了一种新的适应框架，其中包含三种类型的底层不变性，即示例不变性、相机不变性和邻域不变性。具体来说，引入了一个示例内存来存储样本的特征，这可以有效且高效地对全局数据集实施不变性约束。我们进一步提出了基于图的正预测 (GPP) 方法来探索目标域的可靠邻居，该方法建立在内存之上并在源样本上进行训练。实验表明：1）三个不变性属性是互补的，对于有效的域适应是必不可少的，2）内存在实现不变性学习中起着关键作用，并在有限的额外计算成本下提高了性能，3）GPP可以促进不变性学习，因此显着改善了结果，并且 4）我们的方法在三个 re-ID 大规模基准上产生了新的最先进的自适应精度。
用于图像恢复等的基于物理的生成对抗模型,我们提出了一种算法来直接解决许多图像恢复问题（例如，图像去模糊、图像去雾和图像去雨）。这些问题是不适定的，现有方法的常见假设通常基于启发式图像先验。在本文中，我们展示了这些问题可以通过具有对抗性学习的生成模型来解决。然而，基于直接生成对抗网络 (GAN) 的直接公式在这些任务中表现不佳，并且估计图像的某些结构通常不能很好地保留。受到一个有趣的观察的启发，即估计结果应该与物理模型下观察到的输入一致，我们提出了一种算法来指导 GAN 框架内特定任务的估计过程。所提出的模型以端到端的方式进行训练，可应用于各种图像恢复和低级视觉问题。大量实验表明，所提出的方法对最先进的算法表现良好。
用于图像恢复的残差密集网络,最近，深度卷积神经网络 (CNN) 在图像恢复 (IR) 方面取得了巨大成功，同时提供了分层特征。然而，大多数基于深度 CNN 的 IR 模型并没有充分利用原始低质量图像的层次特征；因此，导致性能相对较低。在这项工作中，我们提出了一种新颖且高效的残差密集网络（RDN）来解决 IR 中的这个问题，通过在利用所有卷积层的分层特征时在效率和有效性之间做出更好的权衡。具体来说，我们提出残差密集块（RDB）通过密集连接的卷积层提取丰富的局部特征。 RDB 进一步允许从前一个 RDB 的状态直接连接到当前 RDB 的所有层，从而形成连续的内存机制。为了自适应地从先前和当前的局部特征中学习更有效的特征并稳定更广泛网络的训练，我们提出了 RDB 中的局部特征融合。在充分获得密集的局部特征后，我们使用全局特征融合来联合和自适应地学习全局层次特征。我们通过几个具有代表性的 IR 应用、单图像超分辨率、高斯图像去噪、图像压缩伪影减少和图像去模糊证明了 RDN 的有效性。对基准和真实世界数据集的实验表明，我们的 RDN 在定量和视觉上针对每个 IR 任务的最新方法实现了良好的性能。
带有事件摄像机的高速和高动态范围视频,"事件相机是一种新颖的传感器，它以异步事件流而不是强度帧的形式报告亮度变化。与传统相机相比，它们具有显着优势：高时间分辨率、高动态范围和无运动模糊。虽然事件流原则上编码完整的视觉信号，但从事件流重建强度图像在实践中是一个不适定问题。现有的重建方法基于手工制作的先验和关于成像过程的强假设以及自然图像的统计数据。在这项工作中，我们建议直接从数据中学习从事件流中重建强度图像，而不是依赖于任何手工制作的先验。我们提出了一种新颖的循环网络来从事件流中重建视频，并在大量模拟事件数据上对其进行训练。在训练期间，我们建议使用感知损失来鼓励重建遵循自然图像统计。我们进一步扩展了从颜色事件流合成彩色图像的方法。我们的定量实验表明，我们的网络在图像质量（> 20％）方面大大超过了最先进的重建方法，同时可以舒适地实时运行。我们表明，该网络能够合成高速现象（例如，子弹击中物体）的高帧率视频（> 5, 000 帧/秒），并且能够在具有挑战性的照明条件下提供高动态范围重建。作为额外的贡献，我们证明了我们的重建作为事件数据的中间表示的有效性。我们表明，现成的计算机视觉算法可以应用于我们的重建任务，例如对象分类和视觉惯性里程计，并且这种策略始终优于专门为事件数据设计的算法。我们发布了重建代码、预训练模型和数据集，以便进一步研究。"
NWPU-Crowd：人群计数和本地化的大规模基准,"在过去的十年中，人群计数和定位因其广泛的应用而引起了研究人员的广泛关注，包括人群监控、公共安全、空间设计等。许多卷积神经网络 (CNN) 都是为解决这一任务而设计的。然而，目前发布的数据集规模太小，无法满足基于监督的 CNN 算法的需求。为了解决这个问题，我们构建了一个大规模的拥挤人群计数和定位数据集 NWPU-Crowd，它由 5,109 张图像组成，共有 2,133,375 个带有点和框的带注释的头部。与其他真实世界的数据集相比，它包含各种光照场景，并且密度范围最大（0 与 20 相似；033）。此外，还开发了一个基准网站来公正地评估不同的方法，让研究人员可以提交测试集的结果。基于提出的数据集，我们进一步描述了数据特征，评估了一些主流的最先进（SOTA）方法的性能，并分析了新数据上出现的新问题。更重要的是，基准部署在 https://www.crowdbenchmark.com/，数据集/代码/模型/结果可在 https://gjy3035.github.io/ NWPU-Crowd-Sample-Code/ 获得"
Cascade R-CNN：高质量的对象检测和实例分割,在对象检测中，联合交集 (IoU) 阈值经常用于定义正/负。用于训练检测器的阈值定义了它的质量。虽然常用的阈值 0.5 会导致检测噪声（低质量），但检测性能经常会因阈值较大而降低。这种高质量检测的悖论有两个原因：1) 过度拟合，由于大阈值的正样本消失，以及 2) 检测器和测试假设之间的推理时间质量不匹配。为了解决这些问题，提出了一种多阶段目标检测架构 Cascade R-CNN，该架构由一系列经过 IoU 阈值增加训练的检测器组成。检测器按顺序进行训练，使用检测器的输出作为下一个检测器的训练集。这种重采样逐渐提高了假设的质量，保证了所有检测器的正训练集大小相等，并最大限度地减少了过拟合。在推理中应用相同的级联，以消除假设和检测器之间的质量不匹配。没有花里胡哨的 Cascade R-CNN 实现在 COCO 数据集上实现了最先进的性能，并显着提高了对通用和特定对象数据集（包括 VOC、KITTI、CityPerson 和 WiderFace）的高质量检测。最后，Cascade R-CNN 被推广到实例分割，对 Mask R-CNN 进行了重大改进。
通过跟踪中的深度强化学习进行动态超参数优化,超参数是数值预设，其值是在学习过程开始之前分配的。选择适当的超参数通常对于在许多视觉问题中获得令人满意的性能至关重要，例如基于深度学习的视觉对象跟踪。但是，通常很难确定它们的最佳值，尤其是当它们特定于每个视频输入时。大多数超参数优化算法倾向于搜索一个通用范围并且盲目地强加于所有序列。在本文中，我们提出了一种新颖的动态超参数优化方法，该方法使用基于连续深度 Q 学习的动作预测网络自适应地优化给定序列的超参数。由于目标跟踪的观察空间比传统控制问题的观察空间要复杂得多，因此现有的连续深度 Q 学习算法不能直接应用。为了克服这一挑战，我们引入了一种有效的启发式策略来处理高维状态空间，同时还加速了收敛行为。所提出的算法用于改进两个具有代表性的跟踪器，一个基于 Siamese 的跟踪器和一个基于相关滤波器的跟踪器，以评估其泛化性。清楚地证明了它们在几个流行的基准测试中的卓越性能。我们的源代码可在 https://github.com/shenjianbing/dqltracking 获得。
基于图像的 3D 对象重建：深度学习时代的最新技术和趋势,3D 重建是一个长期存在的不适定问题，计算机视觉、计算机图形学和机器学习社区已经探索了几十年。自 2015 年以来，使用卷积神经网络 (CNN) 的基于图像的 3D 重建引起了越来越多的兴趣并展示了令人印象深刻的性能。鉴于这个快速发展的新时代，本文对该领域的最新发展进行了全面调查。我们专注于使用深度学习技术从单个或多个 RGB 图像估计通用对象的 3D 形状的工作。我们根据形状表示、网络架构和它们使用的训练机制来组织文献。虽然这项调查旨在用于重建通用对象的方法，但我们还回顾了一些最近的工作，这些工作侧重于特定对象类别，例如人体形状和面部。我们对一些关键论文的表现进行了分析和比较，总结了该领域的一些开放问题，并讨论了未来研究的有希望的方向。
GOT-10k：野外通用对象跟踪的大型高多样性基准,"我们在这里介绍一个大型跟踪数据库，该数据库提供了前所未有的广泛覆盖范围内的常见运动物体，称为 GOT-10k。具体来说，GOT-10k 建立在 WordNet 结构 [1] 的主干之上，它填充了超过 560 类移动物体和 87 种运动模式中的大多数，其幅度比最近的类似规模的对应物要宽 [19]、[20] ，[23]，[26]。通过发布大型高多样性数据库，我们旨在为与类别无关的通用短期跟踪器的开发提供统一的培训和评估平台。 GOT-10k 的特点和本文的贡献总结如下。 (1) GOT-10k 提供超过 10,000 个视频片段和超过 150 万个手动标记的边界框，实现深度跟踪器的统一训练和稳定评估。 (2) GOT-10k 是迄今为止第一个使用 WordNet 的语义层次来引导类种群的视频轨迹数据集，它确保了对各种运动物体的全面且相对无偏的覆盖。 (3) GOT-10k 首次引入了用于跟踪器评估的 one-shot 协议，其中训练和测试类是零重叠的。该协议避免了对熟悉对象的有偏见的评估结果，并促进了跟踪器开发的泛化。 (4) GOT-10k 提供额外的标签，例如运动类别和对象可见比率，促进运动感知和遮挡感知跟踪器的开发。 (5) 我们在 GOT-10k 上对 39 种典型的跟踪算法及其变体进行了广泛的跟踪实验，并在本文中分析了它们的结果。 (6) 最后，我们为跟踪社区开发了一个综合平台，提供功能齐全的评估工具包、在线评估服务器和响应式排行榜。 GOT-10k 测试数据的注释是保密的，以避免在其上调整参数。"
具有高级和低级一致性的半监督语义分割,从有限的标记数据中理解视觉信息的能力是机器学习的一个重要方面。虽然图像级分类已在半监督环境中得到广泛研究，但数据有限的密集像素级分类最近才引起关注。在这项工作中，我们提出了一种半监督语义分割方法，该方法从有限的像素级注释样本中学习，同时利用额外的无注释图像。所提出的方法依赖于具有特征匹配损失的对抗性训练来从未标记的图像中学习。它使用两个网络分支，将半监督分类与包括自我训练的半监督分割联系起来。双分支方法减少了使用少量标签进行训练时典型的低级和高级工件。与现有方法相比，该方法取得了显着改进，尤其是在使用极少标记样本进行训练时。在几个标准基准——PASCAL VOC 2012、PASCAL-Context 和 Cityscapes——上，该方法实现了半监督学习的最新技术。
用于多方向目标检测的水平边界框上的滑动顶点,对象检测最近取得了实质性进展。然而，广泛采用的水平边界框表示不适用于无处不在的定向对象，例如航拍图像和场景文本中的对象。在本文中，我们提出了一个简单而有效的框架来检测多向对象。我们不是直接回归四个顶点，而是在每个对应边上滑动水平边界框的顶点，以准确描述一个多方向的对象。具体来说，我们回归了四个长度比，这些长度比表征了每个对应侧的相对滑动偏移量。这可以促进偏移学习并避免定向对象的顺序标签点的混淆问题。为了进一步解决近水平物体的混淆问题，我们还引入了一个基于物体与其水平边界框面积比的倾角因子，指导每个物体选择水平或定向检测。我们将这五个额外的目标变量添加到更快的 R-CNN 的回归头中，这需要可忽略的额外计算时间。大量的实验结果表明，所提出的方法在不花哨的情况下，在包括航空图像中的目标检测、场景文本检测、鱼眼图像中的行人检测在内的多个多方向目标检测基准上取得了优异的性能。
用于图像检索的深度多视图增强散列,哈希是一种在大规模数据空间中进行最近邻搜索的有效方法，它通过将高维特征描述符嵌入到具有相似性的低维汉明空间中。但是，通过二进制代码进行的大规模高速检索与传统检索方法相比，在检索精度上有一定程度的降低。我们注意到多视图方法可以很好地保留数据的多样性特征。因此，我们尝试将多视图深度神经网络引入哈希学习领域，设计出高效创新的检索模型，取得了检索性能的显着提升。在本文中，我们提出了一种有监督的多视图哈希模型，可以通过神经网络增强多视图信息。这是一种结合了多视图和深度学习方法的全新哈希学习方法。该方法利用有效的视图稳定性评估方法，积极探索视图之间的关系，这将影响整个网络的优化方向。我们还在汉明空间设计了多种多数据融合方法，以保留卷积和多视图的优势。为了避免检索过程中增强过程的计算资源过多，我们建立了一个单独的结构，称为记忆网络，共同参与训练。所提出的方法在 CIFAR-10、NUS-WIDE 和 MS-COCO 数据集上进行了系统评估，结果表明我们的方法明显优于最先进的单视图和多视图散列方法。
知识提炼：一项调查,近年来，深度神经网络在工业界和学术界都取得了成功，尤其是在计算机视觉任务方面。深度学习的巨大成功主要归功于其可扩展性来编码大规模数据和操纵数十亿模型参数。然而，将这些繁琐的深度模型部署在资源有限的设备上是一个挑战，例如移动电话和嵌入式设备，不仅因为计算复杂度高，而且存储需求大。为此，已经开发了多种模型压缩和加速技术。作为模型压缩和加速的代表类型，知识蒸馏有效地从大型教师模型中学习小型学生模型。它迅速受到社会各界的关注。本文从知识类别、培训方案、师生架构、蒸馏算法、性能比较和应用等方面对知识蒸馏进行了全面的综述。此外，还简要回顾了知识提炼中的挑战，并讨论和转发了对未来研究的评论。
MEMC-Net：用于视频插值和增强的运动估计和运动补偿驱动的神经网络,在过去的几十年中，运动估计 (ME) 和运动补偿 (MC) 已广泛用于经典视频帧插值系统。最近，已经提出了许多基于卷积神经网络的数据驱动的帧插值方法。然而，现有的基于学习的方法通常估计流量或补偿内核，从而限制了计算效率和插值精度的性能。在这项工作中，我们提出了一种用于视频帧插值的运动估计和补偿驱动的神经网络。开发了一种新的自适应变形层来集成光流和插值内核来合成目标帧像素。该层是完全可微的，因此流和核估计网络都可以联合优化。所提出的模型受益于运动估计和补偿方法的优势，而无需使用手工制作的特征。与现有方法相比，我们的方法计算效率高，并且能够产生更具视觉吸引力的结果。此外，所提出的 MEMC-Net 架构可以无缝地适应多个视频增强任务，例如超分辨率、去噪和去块。广泛的定量和定性评估表明，所提出的方法在广泛的数据集上优于最先进的视频帧插值和增强算法。
MFQE 2.0：压缩视频多帧质量增强的新方法,过去几年在应用深度学习来提高压缩图像/视频的质量方面取得了巨大成功。现有方法主要侧重于提高单帧的质量，没有考虑连续帧之间的相似性。由于本文研究的压缩视频帧之间存在很大的波动，因此可以利用帧相似性来提高低质量帧的质量，因为它们具有相邻的高质量帧。此任务是多帧质量增强 (MFQE)。因此，本文提出了一种用于压缩视频的 MFQE 方法，作为该方向的第一次尝试。在我们的方法中，我们首先开发了一种基于双向长短期记忆 (BiLSTM) 的检测器来定位压缩视频中的峰值质量帧 (PQF)。然后，设计了一种新颖的多帧卷积神经网络（MF-CNN）来提高压缩视频的质量，其中非 PQF 及其最近的两个 PQF 作为输入。在 MF-CNN 中，非 PQF 和 PQF 之间的运动由运动补偿子网进行补偿。随后，质量增强子网融合非 PQF 和补偿 PQF，然后减少非 PQF 的压缩伪影。此外，PQF 质量也以同样的方式得到提高。最后，实验验证了我们的 MFQE 方法在推进压缩视频的最新质量增强方面的有效性和泛化能力。
无目标标签的域适应综述,领域适应已经成为机器学习及相关领域的一个突出问题设置。这篇评论提出了一个问题：分类器如何从源域中学习并泛化到目标域？我们提出了方法的分类，分为我们所说的基于样本、基于特征和基于推理的方法。基于样本的方法侧重于在训练期间根据个体观察对目标域的重要性对它们进行加权。基于特征的方法围绕映射、投影和表示特征，以便源分类器在目标域上表现良好，而基于推理的方法将自适应纳入参数估计过程，例如通过对优化过程的约束。此外，我们回顾了一些允许制定跨域泛化误差界限的条件。我们的分类突出了反复出现的想法，并提出了对进一步研究很重要的问题。
MTFH：用于高效跨模态检索的矩阵三因子散列框架,哈希算法由于其低存储成本和高查询速度，最近在跨模态检索领域引发了一场巨大的革命。最近的跨模态散列方法经常学习统一或等长的散列码来表示多模态数据并使它们直观地具有可比性。然而，这种统一或等长的哈希表示可能会固有地牺牲其表示的可扩展性，因为来自不同模态的数据可能没有一一对应的关系，并且可以通过不同长度的不同哈希码更有效地编码。为了缓解这些问题，本文利用了一个相关且相对未探索的问题：对具有不同哈希长度的异构数据进行编码，并在各种具有挑战性的场景中泛化跨模态检索。为此，提出了一种通用且灵活的跨模态散列框架，称为矩阵三因子散列 (MTFH)，可在各种设置中无缝工作，包括成对或不成对的多模态数据，以及相等或变化的散列长度编码场景。更具体地说，MTFH 利用有效的目标函数来灵活地学习具有不同长度设置的特定于模态的哈希码，同时同步学习两个语义相关矩阵，以在语义上关联异构数据的不同哈希表示。因此，对于各种具有挑战性的跨模态检索任务，派生的哈希码在语义上更有意义。在公共基准数据集上评估的大量实验突出了 MTFH 在各种检索场景下的优势，并展示了其与最先进技术的竞争性能。
具有稀疏编码启发的深度神经网络的视频异常检测,本文提出了一种基于稀疏编码启发的深度神经网络 (DNN) 的异常检测方法。具体来说，鉴于基于稀疏编码的异常检测的成功，我们提出了一种时间相干稀疏编码（TSC），其中时间相干项用于保持两个相似帧之间的相似性。使用顺序迭代软阈值算法 (SIATA) 对 TSC 中的稀疏系数进行优化等效于特殊的堆叠递归神经网络 (sRNN) 架构。此外，为了降低在 TSC 优化中交替更新字典和稀疏系数的计算成本并减轻 TSC 中的超参数选择，我们在受 TSC 启发的 sRNN 之上再堆叠一层以重建输入，并得到一个 sRNN- AE。我们在以下方面进一步改进了 sRNN-AE：i）我们建议在 sRNN-AE 中学习相邻帧之间的数据相关相似性测量，以使其更适合异常检测，而不是使用两个帧之间的预定义相似性测量； ii) 为了降低推理阶段的计算成本，我们减少了 sRNN-AE 中 sRNN 的深度，因此，我们的框架实现了实时异常检测； iii）为了提高计算效率，我们对几个连续帧的外观特征进行时间池化以在时间上总结信息，然后我们将外观特征和时间总结的特征输入到单独的 sRNN-AE 中，以进行更稳健的异常检测。为了便于异常检测评估，我们还构建了一个大规模的异常检测数据集，该数据集在数据量和场景多样性方面甚至大于所有现有异常检测数据集的总和。在受控设置下的玩具数据集和真实数据集上进行的大量实验表明，我们的方法明显优于现有方法，这验证了我们的 sRNN-AE 方法在异常检测方面的有效性。代码和数据已在 https://github.com/StevenLiuWen/sRNN_TSC_Anomaly_Detection 发布。
用于光场重建的高维密集残差卷积神经网络,我们考虑了高维光场重建的问题，并开发了一个基于学习的空间和角度超分辨率框架。许多当前的方法要么需要视差线索，要么分别恢复空间和角度细节。这种方法对非朗伯曲面或遮挡有困难。相比之下，我们将光场超分辨率 (LFSR) 表述为张量恢复，并开发了一个基于具有 4 维 (4D) 卷积的两阶段恢复的学习框架。这使我们的模型能够学习捕获在多个相邻视图中编码的几何信息的特征。这样的几何特征在遮挡区域附近变化并指示前景对象边界。为了训练一个可行的网络，我们提出了一种基于特征图中的一组视图的新的归一化操作，设计了一个阶段损失函数，并开发了多范围训练策略以进一步提高性能。对许多光场数据集进行评估，包括真实场景、合成数据和显微镜光场。与其他最先进的方案相比，所提出的方法实现了卓越的性能和更少的执行时间。
用于人类交互识别的分层长短期并发记忆,在这项工作中，我们旨在通过探索多人之间的长期相互关联的动态来解决视频中的人机交互识别问题。最近，长短期记忆 (LSTM) 已成为一种流行的选择，因为它能够捕获一定范围内的时间运动信息，从而对单人动作识别的个体动态进行建模。然而，大多数现有的基于 LSTM 的方法只专注于通过简单地组合个体的所有动态或将它们建模为一个整体来捕捉人类交互的动态。这些方法忽略了人类互动如何随时间变化的相互关联的动态。为此，我们提出了一种新颖的分层长期短期并发记忆（H-LSTCM）来模拟一组人之间的长期相互关联的动态，以识别人类互动。具体来说，我们首先将每个人的静态特征输入到 Single-Person LSTM 中，以对单人动态进行建模。随后，在一个时间步，所有 Single-Person LSTM 单元的输出被馈送到一个新颖的并发 LSTM (Co-LSTM) 单元，该单元主要由多个子记忆单元、一个新的单元门和一个新的 co-LSTM 单元组成。记忆细胞。在 Co-LSTM 单元中，每个子记忆单元存储单独的运动信息，而这个 Co-LSTM 单元通过单元门和共同记忆选择性地整合和存储来自多个子记忆单元的多个交互人之间的相互关联的运动信息细胞，分别。通过与基线和最先进的方法进行比较，对几个公共数据集的广泛实验验证了所提出的 H-LSTCM 的有效性。
学习基于部分的卷积特征进行人员重新识别,部分级特征为行人图像描述提供了精细的粒度。在本文中，我们通常旨在学习用于人员重新识别的有区别的部分知情特征。我们的贡献是双重的。首先，我们介绍一种通用的部件级特征学习方法，称为基于部件的卷积基线（PCB）。给定一个图像输入，它输出一个由几个部分级特征组成的卷积描述符。 PCB 是通用的，因为它能够适应多种零件分割策略，包括姿势估计、人体解析和统一零件分割。在实验中，我们表明学习的描述符比全局描述符具有显着更高的判别能力。其次，基于PCB，我们提出了精炼零件池（RPP），它可以更精确地定位零件。我们的想法是，位置良好的部分内的像素应该彼此相似，而与其他部分的像素不同。我们称之为零件内一致性。当一个部分中的像素级特征向量与其他部分更相似时，它就是一个异常值，表示不适当的分区。 RPP 将这些异常值重新分配给它们最接近的零件，从而产生具有增强的零件内一致性的精细零件。 RPP 不需要零件标签，并且以弱监督的方式进行训练。实验证实，RPP 让 PCB 获得了又一轮的性能提升。例如，在 Market-1501 数据集上，我们实现了 (77.4+4.2)% 的 mAP 和 (92.3+1.5)% 的 rank-1 准确度，与最先进的技术相比具有竞争力的性能。
深度学习时代的显着性预测：成功与局限,近年来，由于深度学习和大规模注释数据的进步，视觉显着性模型的性能有了很大的飞跃。然而，尽管付出了巨大的努力和巨大的突破，但模型在达到人类水平的准确性方面仍然存在不足。在这项工作中，我探索了该领域的前景，重点是新的深度显着性模型、基准和数据集。在两个图像基准和两个大规模视频数据集上审查和比较了大量的图像和视频显着性模型。此外，我确定了导致模型和人类之间差距的因素，并讨论了构建下一代更强大的显着性模型需要解决的剩余问题。解决的一些具体问题包括：当前模型以何种方式失败，如何补救，从注意力的认知研究中可以学到什么，明确的显着性判断如何与注视相关，如何进行公平的模型比较，以及新兴的显着性模型的应用。
Res2Net：一种新的多尺度骨干架构,在多个尺度上表示特征对于众多视觉任务非常重要。骨干卷积神经网络 (CNN) 的最新进展不断展示出更强的多尺度表示能力，从而在广泛的应用中实现一致的性能提升。然而，大多数现有方法以分层方式表示多尺度特征。在本文中，我们提出了一种新的 CNN 构建块，即 Res2Net，通过在单个残差块内构建分层的残差状连接。 Res2Net 在粒度级别表示多尺度特征，并增加每个网络层的感受野范围。提出的 Res2Net 块可以插入最先进的主干 CNN 模型，例如 ResNet、ResNeXt 和 DLA。我们在所有这些模型上评估 Res2Net 块，并在广泛使用的数据集（例如 CIFAR-100 和 ImageNet）上展示了与基线模型相比的一致性能提升。对代表性计算机视觉任务（即对象检测、类激活映射和显着对象检测）的进一步消融研究和实验结果，进一步验证了 Res2Net 相对于最先进的基线方法的优越性。源代码和训练模型可在 https://mmcheng.net/res2net/ 上获得。
Mask TextSpotter：一种端到端的可训练神经网络，用于发现具有任意形状的文本,以端到端的训练方式统一文本检测和文本识别已成为野外阅读文本的新趋势，因为这两个任务具有高度相关性和互补性。在本文中，我们研究了场景文本定位问题，旨在同时检测和识别自然图像中的文本。提出了一种名为 Mask TextSpotter 的端到端可训练神经网络。与之前的文本检测器遵循由提议生成网络和序列到序列识别网络组成的管道，Mask TextSpotter 享有简单流畅的端到端学习过程，其中可以实现检测和识别通过语义分割直接从二维空间。此外，提出了一个空间注意模块来提高性能和通用性。受益于所提出的检测和识别二维表示，它可以轻松处理不规则形状的文本实例，例如弯曲文本。我们在四个英语数据集和一个多语言数据集上对其进行评估，在检测和端到端文本识别任务中实现了始终优于最先进方法的性能。此外，我们进一步研究了我们方法的识别模块，它在常规和不规则文本数据集上的场景文本识别显着优于最先进的方法。
用于千兆像素组织病理学图像分析的神经图像压缩,我们提出了神经图像压缩 (NIC)，这是一种仅使用弱图像级标签构建用于千兆像素图像分析的卷积神经网络的两步方法。首先，使用以无监督方式训练的神经网络对千兆像素图像进行压缩，在保留高级信息的同时抑制像素级噪声。其次，卷积神经网络 (CNN) 在这些压缩图像表示上进行训练以预测图像级标签，从而避免了对细粒度手动注释的需要。我们比较了几种编码策略，即重建误差最小化、对比训练和对抗性特征学习，并在合成任务和两个公共组织病理学数据集上评估了 NIC。我们发现 NIC 可以成功地利用与图像级标签相关的视觉线索，整合全局和局部视觉信息。此外，我们可视化了 CNN 处理的输入千兆像素图像的区域，并确认它们与人类专家的注释重叠。
OpenPose：使用部分亲和场的实时多人 2D 姿势估计,实时多人 2D 姿势估计是使机器能够理解图像和视频中的人的关键组成部分。在这项工作中，我们提出了一种实时方法来检测图像中多人的 2D 姿势。所提出的方法使用非参数表示，我们将其称为部分亲和场 (PAF)，以学习将身体部位与图像中的个体相关联。无论图像中有多少人，这种自下而上的系统都能实现高精度和实时性能。在以前的工作中，PAF 和身体部位位置估计在训练阶段同时进行了改进。我们证明了仅 PAF 的细化而不是 PAF 和身体部位位置的细化导致运行时性能和准确性的显着提高。我们还展示了第一个组合的身体和足部关键点检测器，基于我们公开发布的内部带注释的足部数据集。我们表明，与顺序运行它们相比，组合检测器不仅减少了推理时间，而且还单独保持了每个组件的准确性。这项工作在 Open Pose 的发布中达到高潮，这是第一个用于多人 2D 姿势检测的开源实时系统，包括身体、脚、手和面部关键点。
DPANet：用于 RGB-D 显着目标检测的深度潜能感知门控注意网络,RGB-D显着目标检测有两个主要问题：（1）如何有效整合跨模态RGB-D数据的互补性； (2)如何防止不可靠深度图的污染效应。事实上，这两个问题是联系在一起的，相互交织，但之前的方法往往只关注第一个问题，而忽略了对深度图质量的考虑，这可能会使模型陷入次优状态。在本文中，我们在一个整体模型中协同解决这两个问题，并提出了一个名为 DPANet 的新型网络，以明确建模深度图的潜力并有效整合跨模态互补性。通过引入深度潜能感知，网络可以基于学习的方式感知深度信息的潜能，引导两种模态数据的融合过程，防止污染的发生。融合过程中的门控多模态注意模块利用门控控制器的注意机制从跨模态的角度捕获远程依赖关系。在 8 个数据集上与 16 种最先进的方法进行比较的实验结果在数量和质量上证明了所提出方法的有效性。 https://github.com/JosephChenHub/DPANet
EnlightenGAN：无需配对监督的深度光增强,基于深度学习的方法在图像恢复和增强方面取得了显着的成功，但在缺乏配对训练数据的情况下，它们仍然具有竞争力吗？作为一个这样的例子，本文探讨了低光图像增强问题，在实践中，同时拍摄同一视觉场景的低光和正常光照片极具挑战性。我们提出了一个高效的无监督生成对抗网络，称为 EnlightenGAN，可以在没有低光/正常光图像对的情况下进行训练，但证明可以很好地概括各种真实世界的测试图像。我们建议使用从输入本身提取的信息来规范非配对训练，而不是使用地面实况数据监督学习，并对低光图像增强问题的一系列创新进行基准测试，包括全局-局部鉴别器结构、自正则化感知损失融合，以及注意力机制。通过广泛的实验，我们提出的方法在视觉质量和主观用户研究方面的各种指标下都优于最近的方法。由于非配对训练带来的巨大灵活性，EnlightenGAN 被证明可以轻松适应增强来自各个领域的真实世界图像。我们的代码和预训练模型可在以下网址获得：https://github.com/VITA-Group/EnlightenGAN。
用于高度不平衡数据分类的多集特征学习,随着数据的扩展，越来越多的不平衡数据出现。当数据的不平衡率（IR）很高时，大多数现有的不平衡学习方法的分类性能会严重下降。在本文中，我们系统地研究了高度不平衡的数据分类问题，并为此提出了一种不相关的成本敏感多集学习（UCML）方法。具体来说，UCML首先通过随机分区构造多个平衡子集，然后使用多集特征学习（MFL）从构造的多集中学习判别特征。为了增强每个子集的可用性并处理每个子集中存在的非线性问题，我们进一步提出了一种基于深度度量的 UCML (DM-UCML) 方法。 DM-UCML 将生成对抗网络技术引入到多集构建过程中，使得每个子集可以拥有与原始数据集相似的分布。为了应对非线性问题，DM-UCML 将深度度量学习与 MFL 相结合，从而可以获得更有利的性能。此外，DM-UCML 设计了一个新的判别项来增强学习度量的可判别性。对八个传统高度不平衡数据集和两个大规模数据集的实验表明：所提出的方法优于最先进的高度不平衡学习方法，并且对高 IR 更稳健。
深度 SAR 成像和运动补偿,压缩感知 (CS) 和矩阵感知 (MS) 技术已应用于合成孔径雷达 (SAR) 成像问题，以利用稀疏或低秩先验信息减少 SAR 回波的采样量。为了进一步利用冗余并提高采样效率，我们采用了不同的方法，其中提出了深度 SAR 成像算法。主要思想是利用自动编码器结构利用后向散射系数的冗余，其中自动编码器中的隐藏潜在层比后向散射系数层具有更低的维度和更少的参数。基于自编码器模型，通过优化与下采样SAR回波相关的重构损失，同时估计自编码器结构的参数和后向散射系数。此外，为满足实际应用需求，提出了一种深度SAR运动补偿算法，以消除运动误差对成像结果的影响。在模拟和真实 SAR 数据上验证了所提出算法的有效性。
图像恢复的同时保真和正则化学习,大多数现有的非盲恢复方法都基于已知精确退化模型的假设。由于退化过程只能部分了解或建模不准确，因此图像可能无法很好地恢复。雨纹去除和带有不准确模糊核的图像反卷积是此类任务的两个代表性示例。对于雨纹去除，虽然可以将输入图像分解为场景层和雨纹层，但是对于雨纹的建模以及与场景层的组合，没有明确的公式。对于盲反卷积，由于通常会引入模糊核的估计误差，因此后续的非盲反卷积过程并不能很好地恢复潜像。在本文中，我们在最大后验框架内提出了一种原则性算法，以使用部分已知或不准确的退化模型来解决图像恢复问题。具体而言，由部分已知或不准确的退化模型引起的残差在空间上是相关的并且分布复杂。通过一组退化和真实图像对的训练集，我们以任务驱动的方式参数化和学习退化模型的保真度项。此外，正则化项也可以与保真度项一起学习，从而形成保真度和正则化同时学习的模型。广泛的实验结果证明了所提出的模型对于具有不准确模糊核的图像反卷积、具有多次退化的反卷积和雨条纹去除的有效性。
一种用于高光谱图像分类的监督分割网络,最近，深度学习在高光谱图像（HSI）分类任务中引起了广泛关注。许多工作都集中在精心设计各种光谱空间网络，其中卷积神经网络（CNN）是最流行的结构之一。为了探索用于 HSI 分类的空间信息，通常直接从高光谱数据中裁剪像素及其相邻像素，以在基于 CNN 的方法中形成 HSI 立方体。然而，裁剪后的 HSI 立方体的空间土地覆盖分布通常很复杂。裁剪后的 HSI 立方体的土地覆盖标签不能简单地由其中心像素确定。此外，裁剪后的 HSI 立方体的空间土地覆盖分布是固定的，具有较少的多样性。对于基于 CNN 的方法，使用裁剪的 HSI 立方体进行训练将导致对空间土地覆盖分布变化的泛化能力较差。在本文中，提出了一种端到端的完全卷积分割网络（FCSN）来同时识别 HSI 立方体中所有像素的土地覆盖标签。首先，进行了几个实验来证明最近基于 CNN 的方法显示出较弱的泛化能力。其次，提出了一种精细的标签样式来标记 HSI 立方体的所有像素，以提供 HSI 立方体的详细空间土地覆盖分布。第三，提出了一种HSI立方体生成方法，生成大量带有精细标签的HSI立方体，以提高空间土地覆盖分布的多样性。最后，提出了一个 FCSN 来探索来自精细标记的 HSI 立方体的光谱空间特征，用于 HSI 分类。实验结果表明，FCSN对空间土地覆盖分布的变化具有优越的泛化能力。
用于多对象跟踪的深度亲和网络,多目标跟踪 (MOT) 在解决视频分析和计算机视觉中的许多基本问题方面发挥着重要作用。大多数 MOT 方法采用两个步骤：对象检测和数据关联。第一步在视频的每一帧中检测感兴趣的对象，第二步在不同帧中建立检测到的对象之间的对应关系以获得它们的轨迹。由于深度学习，目标检测在过去几年中取得了巨大的进步。然而，用于跟踪的数据关联仍然依赖于手工制作的约束，例如外观、运动、空间接近度、分组等，以计算不同帧中对象之间的亲和力。在本文中，我们通过以端到端的方式联合建模对象外观及其在不同帧之间的相似性，利用深度学习的数据关联进行跟踪。所提出的深度亲和网络 (DAN) 在多个抽象级别上学习预检测对象的紧凑而全面的特征，并在任何两帧中对这些特征执行详尽的配对排列以推断对象亲和性。 DAN 还考虑了视频帧之间出现和消失的多个对象。我们利用由此产生的高效亲和力计算将当前帧中的对象与先前帧深入关联，以实现可靠的在线跟踪。我们的技术在流行的多目标跟踪挑战 MOT15、MOT17 和 UA-DETRAC 上进行了评估。十二个评估指标下的综合基准测试表明，我们的方法是应对这些挑战的领先技术之一。我们工作的开源实现可在 https://github.com/shijieS/SST.git 获得。
重新审视深度学习时代的视频显着性预测,预测人们在静态场景中的位置，也就是视觉显着性，最近受到了广泛的研究兴趣。然而，在理解和建模动态场景的视觉注意力方面花费的精力相对较少。这项工作对视频显着性研究做出了三项贡献。首先，我们引入了一个新的基准，称为 DHF1K（Dynamic Human Fixation 1K），用于预测动态场景自由观看期间的注视，这是该领域的长期需求。 DHF1K 由 1K 精心挑选的高质量视频序列组成，由 17 名观察者使用眼动仪设备进行注释。这些视频涵盖了广泛的场景、动作、对象类型和背景。其次，我们提出了一种新颖的视频显着性模型，称为 ACLNet（Attentive CNN-LSTM 网络），它通过监督注意机制增强了 CNN-LSTM 架构，以实现快速的端到端显着性学习。注意机制明确编码静态显着性信息，从而允许 LSTM 专注于学习跨连续帧的更灵活的时间显着性表示。这样的设计充分利用了现有的大规模静态固定数据集，避免了过拟合，显着提高了训练效率和测试性能。第三，我们在三个数据集上对最先进的显着性模型进行了广泛的评估：DHF1K、Hollywood-2 和 UCF 体育。还提出了对先前显着性模型和跨数据集泛化的基于属性的分析。超过 1.2K 包含 400K 帧的测试视频的实验结果表明，ACLNet 优于其他竞争者并且具有快速的处理速度（使用单个 GPU 为 40 fps）。我们的代码和所有结果都可以在 https://github.com/wenguanwang/DHF1K 获得。
CGNet：用于语义分割的轻量级上下文引导网络,在移动设备上应用语义分割模型的需求一直在快速增长。当前最先进的网络具有大量参数，因此不适合移动设备，而其他小内存占用模型遵循分类网络的精神，忽略了语义分割的固有特征。为了解决这个问题，我们提出了一种新颖的上下文引导网络（CGNet），它是一种用于语义分割的轻量级高效网络。我们首先提出了上下文引导（CG）块，它有效地学习了局部特征和周围上下文的联合特征，并进一步改进了与全局上下文的联合特征。基于 CG 块，我们开发了 CGNet，它在网络的所有阶段捕获上下文信息。 CGNet 是专门为利用语义分割的固有属性和提高分割精度而量身定制的。此外，CGNet 经过精心设计，可减少参数数量并节省内存占用。在相同数量的参数下，所提出的 CGNet 显着优于现有的轻量级分割网络。在 Cityscapes 和 CamVid 数据集上的大量实验验证了所提出方法的有效性。具体来说，在没有任何后处理和多尺度测试的情况下，所提出的 CGNet 在 Cityscapes 上实现了 64.8% 的平均 IoU，且参数少于 0.5 M。
JCS：通过联合分类和分割的可解释 COVID-19 诊断系统,"最近，2019 年冠状病毒病 (COVID-19) 已在 200 多个国家/地区引起大流行病，影响了数十亿人。要控制感染，识别和隔离感染者是最关键的一步。主要的诊断工具是逆转录聚合酶链反应 (RT-PCR) 测试。尽管如此，RT-PCR检测的灵敏度还不够高，无法有效预防大流行。胸部CT扫描测试为RT-PCR测试提供了有价值的补充工具，它可以对早期患者进行高灵敏度的识别。然而，胸部CT扫描测试通常很耗时，每个病例大约需要21.5分钟。本文开发了一种新颖的联合分类和分割 (JCS) 系统来执行实时和可解释的 COVID-19 胸部 CT 诊断。为了训练我们的 JCS 系统，我们构建了一个大规模的 COVID-19 分类和分割 (COVID-CS) 数据集，其中包含 400 名 COVID-19 患者和 350 名未感染病例的 144,167 张胸部 CT 图像。 200 名患者的 3,855 幅胸部 CT 图像使用细粒度的像素级混浊标记进行注释，这增加了肺实质的衰减。我们还标注了病灶计数、混浊区域和位置，从而有利于各个诊断方面。大量实验表明，所提出的 JCS 诊断系统对于 COVID-19 分类和分割非常有效。它在分类测试集上获得了 95.0% 的平均灵敏度和 93.0% 的特异性，在我们的 COVID-CS 数据集的分割测试集上获得了 78.5% 的 Dice 分数。 COVID-CS 数据集和代码可在 https://github.com/yuhuan-wu/JCS 获得。"
高光谱图像超分辨率的空间光谱结构稀疏低秩表示,融合高分辨率多光谱图像（HR-MSI）和低分辨率高光谱图像（LR-HSI）的高光谱图像超分辨率旨在重建场景的高分辨率空间光谱信息。现有的主要基于光谱分解和稀疏表示的方法通常是从低级视觉任务的角度开发的，它们不能充分利用更高层次分析中可用的空间和光谱先验。针对这个问题，本文提出了一种新颖的 HSI 超分辨率方法，该方法充分考虑了可用 HR-MSI/LR-HSI 和潜在 HSI 之间的空间/光谱子空间低秩关系。具体来说，它依赖于一种名为结构化稀疏低秩表示（SSLRR）的新子空间聚类方法，将数据样本表示为给定字典中碱基的线性组合，其中稀疏结构是由低秩分解引起的亲和矩阵。然后我们利用所提出的 SSLRR 模型从 MSI/HSI 输入中沿空间/光谱域学习 SSLRR。通过使用学习到的空间和光谱低秩结构，我们将提出的 HSI 超分辨率模型表述为变分优化问题，可以通过 ADMM 算法轻松解决。与最先进的高光谱超分辨率方法相比，该方法在视觉和定量评估方面在三个基准数据集上表现出更好的性能。
自监督深度相关跟踪,特征提取网络的训练通常需要大量手动注释的训练样本，这使得这个过程既耗时又昂贵。因此，我们在深度相关框架（名为：self-SDCT）中提出了一种有效的基于自我监督学习的跟踪器。受稳健跟踪器的前后跟踪一致性的启发，我们提出了多周期一致性损失作为自监督信息，用于从相邻视频帧中学习特征提取网络。在训练阶段，我们在 Siamese 相关跟踪框架下通过前向后向预测生成连续视频帧的伪标签，并利用所提出的多周期一致性损失来学习特征提取网络。此外，我们提出了一种相似性丢弃策略，以使一些低质量的训练样本对被丢弃，并在每个样本对中采用循环轨迹一致性损失来改进训练损失函数。在跟踪阶段，我们使用预训练的特征提取网络来提取特征，并利用 Siamese 相关跟踪框架单独使用前向跟踪来定位目标。大量实验结果表明，与标准评估基准上最先进的监督和无监督跟踪方法相比，所提出的自监督深度相关跟踪器（self-SDCT）实现了有竞争力的跟踪性能。
用于光学遥感图像显着目标检测的密集注意力流体网络,"尽管自然场景图像 (NSI) 的视觉显着性分析取得了显着进展，但光学遥感图像 (RSI) 的显着性目标检测 (SOD) 仍然是一个开放且具有挑战性的问题。在本文中，我们提出了一种用于光学 RSI 中 SOD 的端到端密集注意力流体网络 (DAFNet)。提出了一个全局上下文感知注意力 (GCA) 模块来自适应地捕获远程语义上下文关系，并进一步嵌入到密集注意力流体 (DAF) 结构中，使浅层注意力线索流入深层以指导生成高级特征注意力图。具体来说，GCA 模块由两个关键组件组成，其中全局特征聚合模块实现了来自任意两个空间位置的显着特征嵌入的相互增强，级联金字塔注意模块通过构建级联金字塔框架来解决尺度变化问题以从粗到细的方式逐步细化注意力图。此外，我们为 SOD 构建了一个新的且具有挑战性的光学 RSI 数据集，其中包含 2,000 个具有像素级显着性注释的图像，这是目前最大的公开可用基准。大量实验表明，我们提出的 DAFNet 显着优于现有最先进的 SOD 竞争对手。 https://github.com/rmcong/DAFNet_TIP20"
具有校正和对齐的鲁棒低阶张量恢复,存在稀疏但任意错误的低秩张量恢复是许多实际应用中的一个重要问题。在这项工作中，我们提出了一个恢复低秩张量的通用框架，其中数据可以被一些未知的变换变形并被任意稀疏错误破坏。我们给出了基于代理的公式的统一表示，该公式同时包含了校正和对齐的特征，并建立了恢复张量的最坏情况误差范围。在这种情况下，最先进的方法“RASL”和“TILT”可以被视为我们工作的两个特例，但每个都只执行我们方法的部分功能。随后，我们通过推导两种算法详细研究了该问题的优化方面，一种基于乘法器交替方向法（ADMM），另一种基于近端梯度。我们为后一种算法提供收敛保证，并通过深入的模拟证明了前者的性能。最后，我们在公共数据集上展示了广泛的实验结果，以证明所提出的框架和算法的有效性和效率。
